@article{Fua86,
author  = "P. Fua",
title   = {{Using Probability Density  Functions  in the Framework of Evidential Reasoning}},
journal = "Uncertainty  in Knowledge-Based Systems, Lectures Notes in Computer science",
publisher= "Springer Verlag",
volume  = 286,
pages   = "243--252",
year    = 1986}

@article{Fua87a,
author  = "P. Fua and A.J. Hanson",
title   = {{Resegmentation  Using  Generic  Shape: Locating General  Cultural Objects}},
journal = "Pattern  Recognition Letters",
volume  = 5,
pages   = "243--252",
year    = 1987}

@inproceedings{Fua87b,
author   = "P. Fua and A.J. Hanson",
title    = {{Using  Generic   Geometric  Models  for Intelligent  Shape   Extraction}},
booktitle= AAAI,
address  = "Seattle, WA",
pages   =  "706--711",
year     = 1987}

@INPROCEEDINGS {  Fua88a ,
author         = "P. Fua and A.J. Hanson" ,
title          = {{Extracting Generic Shapes Using Model-Driven Optimization}},
booktitle      =  IU ,
year           = "1988",
pages          = "994--1004" ,
address        = "Cambridge, Massachusetts" ,
month          = "April"
}

@INPROCEEDINGS {  Fua88b ,
author         = "P. Fua and Y. G. Leclerc" ,
title          = {{Model Driven Edge Detection}},
booktitle      =  IU ,
year           = "1988",
pages          = "1016-1021" ,
address        = "Cambridge, Massachusetts" ,
month          = "April" ,
}

@article{Fua90,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Model Driven Edge Detection}}, 
journal  = MVA ,
volume   = 3,
pages    = "45--56",
year     = 1990,
abstract = 
"Standard edge detectors  fail to  find most relevant edges, finding either
too  many or  too  few, because they lack  a geometric model to guide their
search.   We  present a  technique  that  integrates  both photometric  and
geometric models with an initial estimate of the boundary.  The strength of
this approach  lies  in the ability of  the  geometric  model  to  overcome
various photometric  anomalies,  thereby finding boundaries that could  not
otherwise  be  found.  Furthermore,  edges can  be  scored  based on  their
goodness  of  fit to the model,  thus  allowing one  to use semantic  model
information to accept or reject the edges."  }

@inproceedings{Fua89a,
author   = "P. Fua", 
title    = {{Object Delineation as an Optimization Problem}},
booktitle= "International Conference on Supercomputing",
address  = "Santa Clara, CA",
pages    = "476--484",
month   =  "May",
year     = 1989}

@inproceedings{Fua89b,
author   = "P. Fua  and  A.J. Hanson", 
title    = {{Objective  Functions  for Feature Discrimination}},
booktitle= IJCAI,
address  = "Detroit, Michigan",
month   =  "August",
year     = 1989}

@inproceedings{Fua89c,
author   = "P. Fua", 
title    = {{An Optimization Approach for Object Delineation}},
booktitle= "Asilomar Conference on Signals, Sytems \& Computers",
pages    = "526--531",
address  = "Pacific Grove, CA",
month    = "October",
year     = 1989}

@inproceedings{Fua89d,
author   = "P. Fua  and  A.J. Hanson", 
title    = {{Objective  Functions  for Feature Discrimination: Applications to Semiautomated and Automated Feature Extraction }},
booktitle= IU,
address  = "Palo Alto, CA",
month    = "May",
year     = 1989,
pages    = "676--690"}

@inproceedings{Fua89e,
author   = "P. Fua  and  A.J. Hanson", 
title    = {{Objectiv  Functions  for Feature Discrimination: Theory }},
booktitle= IU,
address  = "Palo Alto, CA",
month    = "May",
year     = 1989,
pages    = "443--460"}

@article{FuaHanson,
author   = "P. Fua and  A.J. Hanson",
title    = {{An  Optimization  Framework  for Feature Extraction}},
journal  = MVA ,
year     = 1991,
month    = "Spring",
volume   = 4,
number   = 2,
pages    = "59--87",
abstract = 
"In this paper, we propose  a  unified optimization  framework for  feature
extraction that lets  us  simultaneously  take  into account image data and
semantic knowledge: We model objects using a language  that specifies  both
photometric and geometric constraints and define  an  information-theoretic
objective function that measures the fit  of the  models to the  data.   We
then treat the  problem of finding objects as one of generating the optimal
description of the image in terms of this language.

We  have validated our framework  by performing  extensive  experiments  on
detecting  objects  in   aerial  imagery  described  by  simple   geometric
constraints,  and  have developed  two  algorithms for  generating  optimal
descriptions.   The  first starts with a rough sketch of a polygonal object
and deforms the  initial contour  to  maximize the objective function, thus
finding  object  outlines.   The  second   automatically  extracts  complex
rectilinear buildings from complex aerial images."
}

@phdthesis     {FuaPhD ,
author         = "P. Fua" ,
title          = {{Une Approche Variationnelle pour la Reconnaissance d'Objets}},
school         = "Universit\'e d'Orsay, France",
year           = "1989" ,
month          = "September"
}

@inproceedings{Fua91a,
author   = "P. Fua",
title    =  {{Combining  Stereo and  Monocular  Information to  Compute Dense Depth Maps that Preserve Depth  Discontinuities}},
address  = "Sydney, Australia",
booktitle= IJCAI,
month    = "August",
year     = 1991,
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-ijcai91.ps.gz",
abstract =
"In  this paper,  we  show  how  simple  and  parallel  techniques  can  be
efficiently  combined  to  compute  dense depth  maps  and  preserve  depth
discontinuities in complex real world scenes.
<p>
Our algorithm relies on correlation followed  by interpolation.  During the
correlation   phase  the two images   play a symmetric  role and  we use  a
validity criterion for the matches that eliminates  gross errors: at places
where the images cannot be correlated reliably, due to  lack of  texture or
occlusions for example, the algorithm does not produce  wrong matches but a
very sparse disparity map as opposed to a dense one when the correlation is
successful. To generate dense depth map, the information is then propagated
across the  featureless areas,  but  not   across discontinuities,   by  an
interpolation scheme that takes image grey levels into  account to preserve
image features.
<p>
We show that our algorithm  performs very well on  difficult images such as
faces  and   cluttered  ground  level scenes.  Because   all the algorithms
described here are parallel and very  regular  they could be implemented in
hardware and lead to extremely fast stereo systems."
}

@article{Fua91b,
author   = "P. Fua",
title    = {{A Parallel Stereo Algorithm that Produces Dense Depth Maps and Preserves Image Features}},
journal  = MVA ,	
year     = 1993,
volume   = 6,
number   = 1,
month    = "Winter",
pages    = "35--49",
annote   = "Available as INRIA research report 1369"
}

@inproceedings{Fua91c,
author   = "P. Fua and P. Sander",
title    = {{From Points to Surfaces}},
address  = "San Diego, California",
booktitle= "SPIE Workshop on Geometric Methods in Computer Vision",
month    = "July",
year     = 1991
}

@inproceedings{Fua92a,
author   = "P. Fua and P. Sander",
title    = {{Reconstructing Surfaces from Unstructured 3D Points}},
address  = "San Diego, California",
booktitle= IU,
month    = "January",
year     = 1992,
abstract = 
"Most active and  passive range  finding techniques yield unstructured  and
generally noisy 3D points.  In order to build useful world representations,
one  must be able to remove spurious  data points and group  the  remaining
into meaningful surfaces.

In  this paper, we  propose  an approach based  on fitting local  surfaces.
Differential properties of these  surfaces  are  first  used iteratively to
smooth the points, and then to group them  into more  global surfaces while
eliminating errors.

We present results on complex indoor and outdoor  scenes using  stereo data
as our source of 3D information.",  
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-sander-iu92.ps.gz",
}

@inproceedings{Fua92b,
author   = "P. Fua and P. Sander",
title    = {{Segmenting Unstructured 3D Points  into Surfaces}},
address  = "Genoa, Italy",
booktitle=  ECCV,
month    = "April",
year     = 1992
}

@inproceedings{Fua92c,
author   = "P. Fua and B. Hotz and O. Faugeras",
title    = {{Using local Surfaces to Build Terrain Models from Ground Level Stereo}},
address  = "Washington, D.C.",
booktitle=  IROS,
month    = "July",
year     = 1992
}

@inproceedings{Fua93b,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Combining Stereo,  Shading  and Geometric Constraints  for Surface Reconstruction from  Multiple Views.}},
address  = "San Diego, CA",
booktitle= "SPIE Workshop on Geometric Methods in Computer Vision",
month    = "July",
year     = 1993
}

@inproceedings{Fua93c,
author   = "B. Hotz and Z. Zhang and P. Fua ",
title    = {{Incremental construction of local D.E.M for an autonomous planetary rover}},
address  = "Antibes, France",
booktitle= "Workshop on Computer Vision for Space Applications",
month    = "September",
year     = 1993
}

@inproceedings{Fua94a,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Using 3--Dimensional Meshes To Combine Image-Based and Geometry-Based Constraints}},
booktitle= ECCV,
address  = "Stockholm, Sweden",
month    = "May",
year     = 1994,
pages    ="281--291",
abstract = 
"To recover complicated surfaces,  single information sources  often  prove
insufficient. In  this paper, we present a unified framework for 3--D shape
reconstruction  that allows us to combine image-based constraints, such  as
those  deriving  from  stereo and shape-from-shading,  with  geometry-based
ones,  provided here in the  form of 3--D  points,  3--D  features or  2--D
silhouettes.
<p>
Our approach to shape recovery is to deform a generic object-centered  3--D
representation of  the surface so  as  to minimize  an objective  function.
This objective  function  is  a weighted sum of  the  contributions  of the
various information sources.  We describe these various terms individually,
our  weighting  scheme  and our optimization method.  Finally,  we  present
results on  a number of difficult images of real scenes  for which a single
source of information would have proved insufficient.",
annote   = "Also available as Tech Note 536, Artificial Intelligence Center, SRI International",
url      = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-536.ps.gz"
}

@inproceedings{Fua94b,
author      = "P. Fua and Y. G. Leclerc",
title       = {{Registration Without Correspondences}},
booktitle   = CVPR,
address     = "Seattle, WA",
month       = "June",
year        = 1994,
pages       = "121--128",
abstract = 
"In this  paper, we present a method for registering images of complex 3--D
surfaces that  does  not require explicit correspondences between  features
across the images. Our method relies on the use of a full 3--D model of the
surface to adjust the position and orientation  of the camera by minimizing
an objective  function  based  on the projections  of the  images onto  the
model.  This approach constrains the  camera parameters  strongly enough so
that the  models  do not need,  initially, to  be  accurate to  yield  good
results.  When registration  has been achieved, the  models  can be refined
and the fine details recovered.
<p>
Our method is applicable to the calibration  of stereo imagery, the precise
registration of  new images  of a  scene  and the  tracking  of  deformable
objects. It can therefore lead to important applications in fields such  as
augmented reality in a medical context or data compression for transmission
purposes.  We demonstrate its applicability by using both  synthetic images
and real images of faces and of terrain.",
keywords      = "Registration, Calibration, Surface reconstruction, Stereo, Deformable surfaces",
annote        = "Also available as Tech Note 537, Artificial Intelligence Center, SRI International",
url      =  "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-537.ps.gz"
}

@article{Fua94c,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Object-Centered Surface Reconstruction: Combining Multi-Image Stereo and Shading}},
journal  =  IJCV,
year     = 1995,
month    = "September",
volume   = 16,
pages    = "35--56",
annote     = "Also available as Tech Note 535, Artificial Intelligence Center, SRI International",
abstract = 
"Our  goal is to  reconstruct  both the shape and reflectance properties of
surfaces   from   multiple  images.   We  argue   that  an  object-centered
representation  is most appropriate  for this purpose because it  naturally
accommodates multiple  sources  of  data, multiple images (including motion
sequences of  a  rigid object), and  self-occlusions.   We then  present  a
specific object-centered reconstruction method and its implementation.  The
method begins  with  an initial  estimate  of surface  shape  provided, for
example, by triangulating the  result of  conventional stereo.  The surface
shape and reflectance properties are then iteratively  adjusted to minimize
an objective function that combines information from multiple input images.
The objective function is a weighted sum of stereo, shading, and smoothness
components,  where the  weight varies  over  the surface.  For example, the
stereo component is weighted more strongly where the surface  projects onto
highly textured areas  in the images,  and less strongly  otherwise.  Thus,
each component has its greatest  influence  where its accuracy is likely to
be greatest.  Experimental  results on both  synthetic and real images  are
presented.",
keywords = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-leclerc-ijcv93.ps.gz"
}

@inproceedings{Fua94e,
author      = "P. Fua and Y. G. Leclerc",
title       = {{A Unified Framework to  Recover 3--D Surfaces by Combining Image-Based and Externally-Supplied Constraints}},
booktitle   =  IU,
address     = "Monterey, CA",
month       = "November",
year        =  1994,
windexkey   = "sri aic paper papers"
}

@inproceedings{Fua94f,
author      = "P. Fua and Y. G. Leclerc",
title       = {{Image Registration without Explicit Point Correspondences}},
booktitle   =  IU,
address     = "Monterey, CA",
month       = "November",
year        =  1994,
windexkey   = "sri aic paper papers"
}

@inproceedings{Fua95a,
author      = "P. Fua",
title       = {{Surface Reconstruction Using 3--D Meshes And Particle Systems}},
booktitle   = "Third International Workshop on High Precision Navigation",
address     = "Stuttgart, Germany",
month       = "April",
year        = 1995,
publisher   = {{D\"ummler-Verlag}},
url         = "ftp://ftp.ai.sri.com/pub/papers/fua-navigation95.ps.gz"
}

@inproceedings{Fua95b,
author      = "P. Fua",
title       = {{Reconstructing Complex Surfaces  from Multiple Stereo Views}},
booktitle   =  ICCV,
address     = "Cambridge, MA",
month       = "June",
year        =  1995,
annote        = "Also available as Tech Note 550, Artificial Intelligence Center, SRI International",
abstract    =
"We present a framework for 3--D surface reconstruction that can be used to
model fully 3--Dimensional scenes from an arbitrary  number of stereo views
taken   from   vastly different  viewpoints.   This  is  a key  step toward
producing 3--D  world-descriptions of complex  scenes using stereo and is a
very challenging problem:  real-world   scenes tend to  contain  many  3--D
objects, they do not  usually conform  to the  2-1/2--D assumption  made by
traditional algorithms,  and  one cannot   take  it for granted  that   the
computed 3--D     points can easily  be   clustered   into separate groups.
Furthermore, stereo data is often incomplete and sometimes erroneous, which
makes the problem even more difficult.
<p>
By combining  a    particle-based  representation,  robust   fitting,   and
optimization of  an image-based objective   function, we have been able  to
reconstruct surfaces without any {\em a priori} knowledge of their topology
and in spite of the noisiness of the stereo data.
<p>
Our current implementation goes through three steps---initializing a set of
particles from the input 3--D data,  optimizing their location, and finally
grouping  them   into   global surfaces.    Using  several  complex  scenes
containing multiple  objects, we demonstrate its  competence and ability to
merge information and thus to go beyond what can  be done with conventional
stereo alone.",
keywords    = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
url         = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-550.ps.gz"
}

@article{Fua95c,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Taking Advantage of Image-Based and Geometry-Based Constraints to Recover 3--D Surfaces}},
journal  = CVGIP:IU,
year     = 1995,
annote     = "Accepted for publication, available as Tech Note 536, Artificial Intelligence Center, SRI International",
abstract = 
"To recover complicated surfaces,  single information sources  often  prove
insufficient. In  this paper, we present a unified framework for 3--D shape
reconstruction  that allows us to combine image-based constraints, such  as
those  deriving  from  stereo and shape-from-shading,  with  geometry-based
ones,  provided here in the  form of 3--D  points,  3--D  features or  2--D
silhouettes.
<p>
Our approach to shape recovery is to deform a generic object-centered  3--D
representation of  the surface so  as  to minimize  an objective  function.
This objective  function  is  a weighted sum of  the  contributions  of the
various information sources.  We describe these various terms individually,
our  weighting  scheme  and our optimization method.  Finally,  we  present
results on  a number of difficult images of real scenes  for which a single
source of information would have proved insufficient.",
url      = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-536.ps.gz"
}

@article{Fua95d,
author   = "P. Fua",
title    = {{From Multiple Stereo Views to Multiple 3--D Surfaces}},
journal  = IJCV,
year     = 1996,
annote     = "Accepted for publication, available as Tech Note 550, Artificial Intelligence Center, SRI International",
keywords = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
abstract =
"We present a framework for 3--D surface reconstruction that can be used to
model fully 3--Dimensional scenes from an arbitrary  number of stereo views
taken   from   vastly different  viewpoints.   This  is  a key  step toward
producing 3--D  world-descriptions of complex  scenes using stereo and is a
very challenging problem:  real-world   scenes tend to  contain  many  3--D
objects, they do not  usually conform  to the  2-1/2--D assumption  made by
traditional algorithms,  and  one cannot   take  it for granted  that   the
computed 3--D     points can easily  be   clustered   into separate groups.
Furthermore, stereo data is often incomplete and sometimes erroneous, which
makes the problem even more difficult.
<p>
By combining  a    particle-based  representation,  robust   fitting,   and
optimization of  an image-based objective   function, we have been able  to
reconstruct surfaces without any {\em a priori} knowledge of their topology
and in spite of the noisiness of the stereo data.
<p>
Our current implementation goes through three steps---initializing a set of
particles from the input 3--D data, optimizing  their location, and finally
grouping them into   global  surfaces.    Using several   complex    scenes
containing multiple objects, we  demonstrate its competence and  ability to
merge information and thus to go beyond  what can be done with conventional
stereo alone.",
url      = "ftp://ftp.ai.sri.com/pub/tech-notes/1994/aic-tn-550.ps.gz"
}

@inproceedings{Fua95e,
author   = "P. Fua",
title    = {{Parametric Models are Versatile:  The Case of Model Based Optimization}},
address	 = "Stockholm, Sweden",
booktitle= "ISPRS WG III/2 Joint Workshop",
month    = "September",
year     = 1995,
abstract = 
"Model-Based  Optimization  (MBO)   is a paradigm  in   which  an objective
function is used  to express both  geometric and photometric constraints on
features of interest.   A parametric model of a  feature (such as a road, a
building, or coastline)  is extracted from one or  more images by adjusting
the model's state variables until a minimum value of the objective function
is  obtained.   The  optimization  procedure   yields a   description  that
simultaneously satisfies  (or nearly satisfies)  all constraints, and, as a
result, is likely to be a good model of the feature.",
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-isprs95.ps.gz"
}

@inproceedings{Waneu94a,
author      = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title       = {{Initializing Snakes}},
booktitle   = CVPR,
address     = "Seattle, WA",
month       = "June",
year        = 1994,
pages       = "658--663"
}

@inproceedings{Waneu94b,
author   = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title    = {{Making Snakes Converge from Minimal Initialization}},
address  = "Jerusalem, Israel",
booktitle= ICPR,
month	 = "October",
pages    = "658--663",
year     = 1994
}

@inproceedings{Waneu94c,
author    = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title     = {{Making Snakes Converge from Minimal Initialization}},
booktitle = IU,
address     = "Monterey, CA",
month       = "November",
year        =  1994
}

@article{Waneu94d,
author    = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title     = {{Ziplock Snakes}},
journal   = IJCV,
year      =  1994,
annote      = "Submitted for publication, available as Tech Note 548, Artificial Intelligence Center, SRI International",
abstract = 
"We  propose  a snake-based approach  that  lets  a user specify  only  the
distant  endpoints  of the curve  he wishes to delineate without  having to
supply an almost complete polygonal approximation.  We greatly simplify the
initialization process and achieve much better  convergence properties than
those of traditional snakes  by  using the  image  information around these
endpoints to provide boundary conditions and by introducing an optimization
schedule that allows a snake to take image  information into account  first
only near its extremities and then, progressively, toward its  center.   In
effect,  the  snakes are  clamped  onto  the  image  contour  in  a  manner
reminiscent of a ziplock being closed.
<p>
These  snakes  can  be   used  to  alleviate   the  often  repetitive  task
practitioners face  when segmenting images by abolishing the need to sketch
a feature of interest  in its entirety, that is, to  perform a painstaking,
almost complete, manual segmentation.",
keywords =  "Snakes, Deformable models, Interactive initialization, Boundary conditions.",
url      =  "ftp://ftp.ai.sri.com/pub/tech-notes/1994/aic-tn-548.ps.gz"
}

@inproceedings{Waneu95a,
author      = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title       = {{Velcro Surfaces}},
booktitle   =  ICCV,
address     = "Cambridge, MA",
month       = "June",
year        =  1995
}
