
@INPROCEEDINGS{Chaudhri-Theory-95,
         AUTHOR="Vinay K. Chaudhri and Vassos Hadzilacos",
         TITLE="{Safe Locking Policies for Dynamic Databases}",
         BOOKTITLE="{14TH ACM Symposium on Principles of Database Systems}",
         MONTH="May",
         NOTE="To Appear",
         YEAR=1995,

         ABSTRACT="It was shown by Yannakakis that a locking policy is
not safe if and only if there exists a canonical non-serializable
schedule of transactions running according to the rules of the policy
in which all the transactions except one are executed serially
\cite{Yannakakis-JACM-82}.  In the present paper, we study the
generalization of this result to a dynamic database, that is, a
database that may undergo insertions and deletions of entities.  We
illustrate the utility of this generalization by applying it to obtain
correctness proofs of three locking policies that handle dynamic
databases."
}

@TECHREPORT{Chaudhri-phl-95,
         AUTHOR = {Vinay K. Chaudhri and John Mylopoulos},
         TITLE= "{Efficient Algorithms and Performance Results for 
                  Multi-user Knowledge Bases}",
         INSTITUTION = "{University of Toronto}",
         NUMBER = "",
         DEPARTMENT = "Department of Computer Science",
         MONTH="January",
         YEAR = 1995,
         ABSTRACT="The paper describes research efforts to develop efficient
implementation techniques for large, shared knowledge bases, focusing
on efficient concurrent access of large knowledge bases by multiple
users.

We present an algorithm, called the Dynamic Directed Graph policy,
originally proposed in \cite{Chaudhri-KR-92} which allows efficient
interleaved execution of transactions against a large knowledge base
with the intent of optimizing transaction throughput. The
implementation of the policy and experimental evaluation results are
also presented and discussed. The paper concludes with discussion on
lessons learnt from this research."
                         }


@PHDTHESIS{Chaudhri-TH-95,
         AUTHOR="Vinay K Chaudhri",
         TITLE="{Transaction Synchronization in Knowledge Bases: Concepts,
                 Realization and Quantitative Evaluation}",
         SCHOOL="University of Toronto",
         ADDRESS="Toronto",
         MONTH="January",
         YEAR = 1995,

ABSTRACT="Large knowledge bases that are intended for applications such as CAD,
corporate repositories or process control will have to be shared by
multiple users.  For these systems to scale up, to give acceptable
performance and to exhibit consistent behavior, it is mandatory to
synchronize user transactions using a concurrency control algorithm.
The transactions in knowledge bases often access a large number of
entities and perform complex inferences that may last for a long period
of time. In such a situation, using conventional concurrency control
methods, which require a transaction to hold its locks until it has
acquired all the locks it will ever need, do not lead to good
performance.  This thesis examines the problem of concurrency control
for such long transactions in a knowledge base setting.

Using a directed graph as a general model of a knowledge base, we
develop an algorithm, called the Dynamic Directed Graph (DDG)  policy,
that allows release of locks by a transaction before it has acquired
all the locks that it will ever need.  Furthermore, it deals with a
knowledge base whose graph may contain cycles and may receive insertions
and deletions of nodes and edges.  We develop a theory of correctness for
schedules in such databases and use it to prove the correctness of the
DDG policy and two other locking policies.  In addition, we analyze the
well-structured-ness and the deadlock-freedom of the DDG policy. The
thesis also includes the design of a prototype implementation of the
DDG policy and performance results for three real knowledge bases.
These results show that the DDG policy can be implemented without
unacceptably high overhead, and  for the workloads found in
``real-world'' knowledge bases, the proposed algorithm can indeed
perform better than the conventional methods, such as two-phase
locking."
                       }

@INPROCEEDINGS{Chaudhri-CIKM-94,
         AUTHOR="Vinay K Chaudhri and Vassos Hadzilacos and John Mylopoulos
and Ken Sevcik",
        TITLE="{Quantitative Evaluation of a Transaction Facility for a
Knowledge Base Management System}",
         BOOKTITLE="Proceedings of the Third International Conference on
                    Knowledge Management",
         ADDRESS="Gaithersberg, MD",
         PAGES={122-131},
         YEAR=1994,
         ABSTRACT="Large knowledge bases that are intended for applications such as CAD,
corporate repositories or process control will have to be shared by
multiple users.  For these systems to scale up, to give acceptable
performance and to exhibit consistent behavior, it is mandatory to
synchronize user transactions using a concurrency control algorithm.
In this paper, we examine a novel concurrency control policy called
Dynamic Directed Graph (or DDG) policy that effectively exploits the
rich semantic structure of a knowledge base.

Our analysis is carried out in the context of a real knowledge based
system application from which knowledge base structure  and
workload parameters are computed.  These  serve as a basis
for studying the implementation alternatives that arise as a result of
knowledge base characteristics.  The implementation alternatives that
we consider include selection of portions of the knowledge base
structure to be exploited for concurrency control, and also the
dependence of concurrency on the traversal strategy used to search
through the knowledge base. We analyze the effects of various workload
parameters and conclude that the DDG policy improves substantially the
response time for short transactions when there is heavy data
contention."
                        }

@INPROCEEDINGS{Mylopoulos-92,     
         AUTHOR="John Mylopoulos and Vinay K Chaudhri and Dimitiris Plexousakis and Thodoros Topaloglou", 
        TITLE="{A Performance-Oriented Approach to Knowledge Base Management}",
         BOOKTITLE="Proceedings of the First International Conference on
                    Knowledge Management",  
         ADDRESS="Baltimore, MD",
         NOTE="{Also appeared as: Adapting Database Implementation 
                Techniques to Manage Very Large Knowledge Bases, In 
                International Workshop on Building and Sharing Very 
                Large Knowledge Bases, Dec 3-4, 1993, Tokyo, 
                Japan, pages 215-226}",
         PAGES={68-75},
         YEAR=1992,
         ABSTRACT="Crafting large knowledge bases requires appropriate management
facilities which include efficient and robust implementations,
sophisticated user interfaces, version control and configuration
management. This paper examines the problem of efficiently
implementing a knowledge base management system (hereafter
KBMS) by presenting an overview of technical problems addressed in
the design of a prototype KBMS at the University of Toronto.

In particular, the paper describes the physical storage management
scheme developed for the KBMS and outlines a query processing
algorithm that has been developed, emphasizing
optimizations and access planning aspects. Concurrency control is
then examined for knowledge bases to support multi-user access.
Finally, rule and constraint management is
discussed and a comprehensive scheme for compiling  and processing
them  is presented. Throughout, the paper sketches algorithms,
presents some formally proven properties of these algorithms and
discusses preliminary performance results."
                        }

@INPROCEEDINGS{Chaudhri-KR-92,
         AUTHOR="Vinay K Chaudhri and Vassos Hadzilacos and John Mylopoulos",
         TITLE="{Concurrency Control for Knowledge Bases}",
         BOOKTITLE="Proceedings of the Third International Conference on 
                    Knowledge Representation and Reasoning",
         YEAR=1992,
         PAGES={762-773},
         ABSTRACT="As the demand for ever-larger knowledge bases
grows, knowledge base management techniques assume paramount
importance.  In this paper we show that large, multi-user knowledge
bases need concurrency control.  We discuss known techniques from
database concurrency control and explain their inadequacies in the
context of knowledge bases.  We offer a concurrency control algorithm,
called the Dynamic Directed Graph (DDG) policy that addresses the
specific needs of knowledge bases.  The DDG policy exploits the rich
structure of a knowledge base to support the interleaved, concurrent
execution of several user requests, thereby improving overall system
performance.  We give a proof of correctness of the proposed
concurrency control algorithm and an analysis of its properties.  We
demonstrate that these results from concurrency control interact in
interesting ways with knowledge base features and highlight the
importance of performance-oriented tradeoffs in the design of
knowledge-based systems."  }

@INPROCEEDINGS{Chaudhri-CSCI-92,     
         AUTHOR="Vinay K Chaudhri and Russell Greiner", 
        TITLE="{A Formal Analysis of Solution Caching}",
         BOOKTITLE="Proceedings of the Canadian AI Conference",  
         ADDRESS="Vancouver, BC",
         YEAR=1992,
         ABSTRACT="Many inference management systems
store and maintain the conclusions found during a derivation process
in a form that allows these conclusions to be used during subsequent
derivations.  As this approach, called ``solution caching'', allows
the system to avoid repeating these derivations, it can reduce the
system's overall cost for answering queries.  Unfortunately, as there
is a cost for storing these conclusions, it is not always desirable to
cache every solution found --- this depends on whether the savings
achieved by performing fewer inference steps for these future queries
exceeds the storage overhead incurred.  This paper formally
characterizes this tradeoff and presents an efficient algorithm,
\FOCL, that produces an optimal caching strategy: \ie given an
inference graph of a knowledge base, anticipated frequencies of
queries and updates of each node in this graph, and various
implementation-dependent cost parameters, \FOCL\ determines which of
these nodes should cache their solutions to produce a system whose
overall cost is minimal.  The paper also presents empirical results
that indicate that a system based on \FOCL\ can significantly
outperform one based on any of the standard % known approaches to
solution caching."  }

@Misc{Chaudhri-91,
         AUTHOR="Vinay K Chaudhri",
         TITLE="{Designing Multi-User KBMSs}",
         HOWPUBLISHED="{Depth Paper}",
	 INSTITUTION="Department of Computer Science, University of Toronto",
	 MONTH="January",
         YEAR=1991
	}

@INPROCEEDINGS{CohenCheyer94:oaa,
   AUTHOR={Philip R. Cohen and Adam J. Cheyer and Michelle Wang and Soon Choel Baeg},
   TITLE={An Open Agent Architecture},
   BOOKTITLE="AAAI Spring Symposium",
   PAGES="1--8",
   YEAR=1994,
   MONTH=mar,
   ABSTRACT="The goal of this ongoing project is to develop an open agent
   architecture and accompanying user interface for networked desktop and
   handheld machines.  The system we are building should support
   distributed execution of a user's requests, interoperability of
   multiple application subsystems, addition of new agents, and
   incorporation of existing applications. It should also be
   transparent; users should not need to know where their requests are
   being executed, nor how.
   Finally, in order to facilitate the user's delegating tasks to agents,
   the architecture will be served by a multimodal interface, including
   pen, voice, and direct manipulation. Design considerations taken to
   support this functionality will be discussed below.",
   URL="ftp://ftp.ai.sri.com/pub/papers/oaa-aaai94.ps.gz",
   WINDEXKEY="sri aic paper papers",
   KEYWORDS= "OAA, multimodal, multimedia"
}

@InProceedings{Connolly84,
  author =       "C. I. Connolly",
  title =        "Cumulative Generation of Octree Models from Range
                 Data",
  booktitle =    "Proceedings of the First International Conference on
                 Robotics and Automation",
  organization = "IEEE",
  pages =        "25",
  month =        mar,
  year =         "1984",
}

%----

@InProceedings{Connolly85,
  author =       "Christopher I. Connolly",
  title =        "The Determination of Next Best Views",
  booktitle =    "Proceedings of the 1985 Conference on Robotics and
                 Automation",
  organization = "IEEE",
  pages =        "432",
  month =        apr,
  year =         "1985",
}


@InProceedings{Stenstrom86,
  author =       "John Ross Stenstrom and Christopher Ian Connolly",
  title =        "Building Wire Frames from Multiple Views",
  booktitle =    "Proceedings of the 1986 Conference on Robotics and
                 Automation",
  organization = "IEEE",
  pages =        "615",
  month =        apr,
  year =         "1986",
}

@InProceedings{Connolly86,
  author =       "Christopher Ian Connolly and John Ross Stenstrom",
  title =        "Construction of Polyhedral Models from Multiple Range
                 Views",
  booktitle =    "Proceedings of the 8th International Conference on
                 Pattern Recognition",
  pages =        "85--87",
  year =         "1986",
  month =        oct,
}

%----

@InProceedings{Connolly87a,
  author =       "Christopher Ian Connolly and Joseph L. Mundy and John
                 Ross Stenstrom and Daniel W. Thompson",
  title =        "Matching from 3-{D} Range Models into 2-{D} Intensity
                 Scenes",
  booktitle =    "Proceedings of the First International Conference on
                 Computer Vision",
  month =        jun,
  year =         "1987",
}

@InCollection{Stenstrom88,
  author =       "J. R. Stenstrom and C. I. Connolly",
  title =        "Model Generation from Images",
  booktitle =    "Image Analysis and Processing II",
  editor =       "V. Cantoni and V. DiGesu and S. Levialdi",
  pages =        "269--276",
  publisher =    "Plenum Publishing Corporation",
  year =         "1988",
}

%----

@InProceedings{Connolly89a,
  author =       "C. I. Connolly and J. R. Stenstrom",
  title =        "{3D} Scene Reconstruction from Multiple Sensory
                 Images",
  booktitle =    "Proceedings of the IEEE Computer Society Workshop on
                 Interpretation of 3D Scenes",
  month =        nov,
  organization = "IEEE Computer Society",
  year =         "1989",
}

%----

@InProceedings{Connolly90,
  author =       "C. I. Connolly and J. B. Burns and R. Weiss",
  title =        "Path Planning Using {Laplace's Equation}",
  organization = "IEEE",
  booktitle =    "Proceedings of the 1990 IEEE International Conference on Robotics and Automation",
  year =         "1990",
  pages =        "2102--2106",
  month =        may,
}

%----

@TechReport{Connolly92a,
  author =       "C. I. Connolly and R. Grupen",
  title =        "Applications of Harmonic Functions to Robotics",
  institution =  "COINS Department, University of Massachusetts",
  year =         "1992",
  number =       "92-12",
  month =        feb,
}

@InCollection{Connolly92b,
  author =       "Christopher I. Connolly and J. Brian Burns",
  title =        "The Planning of Actions and The Basal Ganglia",
  editor =       "J. Hendler",
  booktitle =    "Artificial Intelligence Planning Systems: Proceedings
                 of the First International Conference (AIPS92)",
  publisher =    "Morgan Kaufmann",
  address =      "San Mateo, CA",
  year =         "1992",
}

@TechReport{Connolly92c,
  author =       "Christopher I. Connolly and J. Brian Burns",
  title =        "The Basal Ganglia and the Planning of Actions",
  institution =  "COINS Department, University of Massachusetts",
  year =         "1992",
  number =       "92-18",
  month =        feb,
}

@Article{Connolly92d,
  author =       "Christopher I. Connolly and Roderic A. Grupen",
  title =        "The Applications of Harmonic Functions to Robotics",
  journal =      "Journal of Robotic Systems",
  year =         "1993",
  month =        oct,
  volume =       "10",
  number =       "7",
  pages =        "931--946",
}

@InProceedings{Connolly92e,
  author =       "Christopher I. Connolly and Roderic A. Grupen",
  title =        "Harmonic Control",
  booktitle =    "The 1992 International Symposium on Intelligent
                 Control",
  year =         "1992",
  month =        aug,
  organization = "IEEE",
}

@InProceedings{Connolly92f,
  author =       "Christopher I. Connolly",
  title =        "Applications of Harmonic Functions to Robotics",
  booktitle =    "The 1992 International Symposium on Intelligent
                 Control",
  year =         "1992",
  month =        aug,
  organization = "IEEE",
}

@Article{Connolly92g,
  author =       "Christopher I. Connolly and J. Brian Burns",
  title =        "A Model for the Functioning of the Striatum",
  journal =      "Biological Cybernetics",
  year =         "1993",
  volume =       "68",
  number =       "6",
  pages =        "535--544",
}

@Article{Connolly92h,
  author =       "Christopher I. Connolly",
  title =        "A Robotics Perspective on Motor Programs and Path
                 Planning",
  journal =      "Behavioral and Brain Sciences",
  year =         "1992",
  month =        dec,
  volume =       "15",
  number =       "4",
  pages =        "728--729",
}

@Article{Stenstrom92,
  author =       "J. Ross Stenstrom and C. Ian Connolly",
  title =        "Constructing Object Models from Multiple Images",
  journal =      "International Journal of Computer Vision",
  volume =       "7",
  number =       "9",
  year =         "1992",
  month =        dec,
}

@Article{Connolly93a,
  author =       "Christopher I. Connolly and J. Brian Burns",
  title =        "A New Striatal Model and its Relationship to Basal
                 Ganglia Diseases",
  journal =      "Neuroscience Research",
  year =         "1993",
  volume =       "16",
  pages =        "271--274",
}

@InProceedings{Connolly94,
  author =       "C. I. Connolly",
  title =        "Harmonic functions and Collision Probabilities",
  organization = "IEEE",
  booktitle =    "Proceedings of the 1994 IEEE International Conference on Robotics and Automation",
  year =         "1994",
  month =        may,
  pages =        "3015--3019",
}

@InProceedings{AAAI-94,
  author =       "R. A. Grupen and J. A. Coelho and C. I. Connolly and
                 V. Gullapalli and M. Huber and K. Souccar",
  year =         "1994",
  title =        "Toward Physical Interaction and Manipulation: Screwing
                 in a Light Bulb",
  booktitle =    "AAAI 1994 Spring Symposium on Physical Interaction and
                 Manipulation",
}

@InCollection{Singh94,
  author =       "Satinder P. Singh and Andrew G. Barto and Roderic
                 Grupen and Christopher Connolly",
  title =        "Robust Reinforcement Learning in Motion Planning",
  editor =       "J. D. Cowan and G. Tesauro and J. Alspector",
  booktitle =    "Advances in Neural Information Processing Systems 6",
  publisher =    "Morgan Kaufmann Publishers",
  city =         "San Mateo, California",
  year =         "1994",
  pages =        "655--662",
}

@Article{Connolly94b,
  author =       "Mircea R. Stan and Wayne P. Burleson and Christopher
                 I. Connolly and Roderic A. Grupen",
  title =        "Analog {VLSI} for Robot Path Planning",
  journal =      "Journal of VLSI Signal Processing",
  year =         "1994",
  volume =       "8",
  number =       "1",
  pages =        "to appear",
}

@TechReport{Connolly94c,
  author =       "C. I. Connolly and R. A. Grupen",
  title =        "Nonholonomic Path Planning Using Harmonic Functions",
  institution =  "Computer Science Department, University of
                 Massachusetts",
  year =         "1994",
  number =       "94-50",
  month =        may,
}

@PhdThesis{Connolly-Thesis,
  author =       "Christopher I. Connolly",
  title =        "Harmonic Functions as a Basis for Motor Control and
                 Planning",
  school =       "University of Massachusetts",
  year =         "1994",
}

@inproceedings{Connolly95a,
  author="Christopher I. Connolly and Roderic A. Grupen and Kamal X. Souccar",
  title="A Hamiltonian Approach to Kinodynamic Planning",
  booktitle="1995 IEEE Conference on Robotics and Automation",
  pages="940",
  year="1995",
%%  URL="http://www.ai.sri.com/~connolly/kinodynamic/kinodynamic.html",
  KEYWORDS="phase space, repetitive motion, planning, robotics"
}

@article{Fua86,
author  = "P. Fua",
title   = {{Using Probability Density  Functions  in the Framework of Evidential Reasoning}},
journal = "Uncertainty  in Knowledge-Based Systems, Lectures Notes in Computer science",
publisher= "Springer Verlag",
volume  = 286,
pages   = "243--252",
year    = 1986}

@article{Fua87a,
author  = "P. Fua and A.J. Hanson",
title   = {{Resegmentation  Using  Generic  Shape: Locating General  Cultural Objects}},
journal = "Pattern  Recognition Letters",
volume  = 5,
pages   = "243--252",
year    = 1987}

@inproceedings{Fua87b,
author   = "P. Fua and A.J. Hanson",
title    = {{Using  Generic   Geometric  Models  for Intelligent  Shape   Extraction}},
booktitle= AAAI,
address  = "Seattle, WA",
pages   =  "706--711",
year     = 1987}

@INPROCEEDINGS {  Fua88a ,
author         = "P. Fua and A.J. Hanson" ,
title          = {{Extracting Generic Shapes Using Model-Driven Optimization}},
booktitle      =  IU ,
year           = "1988",
pages          = "994--1004" ,
address        = "Cambridge, Massachusetts" ,
month          = "April"
}

@INPROCEEDINGS {  Fua88b ,
author         = "P. Fua and Y. G. Leclerc" ,
title          = {{Model Driven Edge Detection}},
booktitle      =  IU ,
year           = "1988",
pages          = "1016-1021" ,
address        = "Cambridge, Massachusetts" ,
month          = "April" ,
}

@article{Fua90,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Model Driven Edge Detection}}, 
journal  = MVA ,
volume   = 3,
pages    = "45--56",
year     = 1990,
abstract = 
"Standard edge detectors  fail to  find most relevant edges, finding either
too  many or  too  few, because they lack  a geometric model to guide their
search.   We  present a  technique  that  integrates  both photometric  and
geometric models with an initial estimate of the boundary.  The strength of
this approach  lies  in the ability of  the  geometric  model  to  overcome
various photometric  anomalies,  thereby finding boundaries that could  not
otherwise  be  found.  Furthermore,  edges can  be  scored  based on  their
goodness  of  fit to the model,  thus  allowing one  to use semantic  model
information to accept or reject the edges."  }

@inproceedings{Fua89a,
author   = "P. Fua", 
title    = {{Object Delineation as an Optimization Problem}},
booktitle= "International Conference on Supercomputing",
address  = "Santa Clara, CA",
pages    = "476--484",
month   =  "May",
year     = 1989}

@inproceedings{Fua89b,
author   = "P. Fua  and  A.J. Hanson", 
title    = {{Objective  Functions  for Feature Discrimination}},
booktitle= IJCAI,
address  = "Detroit, Michigan",
month   =  "August",
year     = 1989}

@inproceedings{Fua89c,
author   = "P. Fua", 
title    = {{An Optimization Approach for Object Delineation}},
booktitle= "Asilomar Conference on Signals, Sytems \& Computers",
pages    = "526--531",
address  = "Pacific Grove, CA",
month    = "October",
year     = 1989}

@inproceedings{Fua89d,
author   = "P. Fua  and  A.J. Hanson", 
title    = {{Objective  Functions  for Feature Discrimination: Applications to Semiautomated and Automated Feature Extraction }},
booktitle= IU,
address  = "Palo Alto, CA",
month    = "May",
year     = 1989,
pages    = "676--690"}

@inproceedings{Fua89e,
author   = "P. Fua  and  A.J. Hanson", 
title    = {{Objectiv  Functions  for Feature Discrimination: Theory }},
booktitle= IU,
address  = "Palo Alto, CA",
month    = "May",
year     = 1989,
pages    = "443--460"}

@article{FuaHanson,
author   = "P. Fua and  A.J. Hanson",
title    = {{An  Optimization  Framework  for Feature Extraction}},
journal  = MVA ,
year     = 1991,
month    = "Spring",
volume   = 4,
number   = 2,
pages    = "59--87",
abstract = 
"In this paper, we propose  a  unified optimization  framework for  feature
extraction that lets  us  simultaneously  take  into account image data and
semantic knowledge: We model objects using a language  that specifies  both
photometric and geometric constraints and define  an  information-theoretic
objective function that measures the fit  of the  models to the  data.   We
then treat the  problem of finding objects as one of generating the optimal
description of the image in terms of this language.

We  have validated our framework  by performing  extensive  experiments  on
detecting  objects  in   aerial  imagery  described  by  simple   geometric
constraints,  and  have developed  two  algorithms for  generating  optimal
descriptions.   The  first starts with a rough sketch of a polygonal object
and deforms the  initial contour  to  maximize the objective function, thus
finding  object  outlines.   The  second   automatically  extracts  complex
rectilinear buildings from complex aerial images."
}

@phdthesis     {FuaPhD ,
author         = "P. Fua" ,
title          = {{Une Approche Variationnelle pour la Reconnaissance d'Objets}},
school         = "Universit\'e d'Orsay, France",
year           = "1989" ,
month          = "September"
}

@inproceedings{Fua91a,
author   = "P. Fua",
title    =  {{Combining  Stereo and  Monocular  Information to  Compute Dense Depth Maps that Preserve Depth  Discontinuities}},
address  = "Sydney, Australia",
booktitle= IJCAI,
month    = "August",
year     = 1991,
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-ijcai91.ps.gz",
abstract =
"In  this paper,  we  show  how  simple  and  parallel  techniques  can  be
efficiently  combined  to  compute  dense depth  maps  and  preserve  depth
discontinuities in complex real world scenes.
<p>
Our algorithm relies on correlation followed  by interpolation.  During the
correlation   phase  the two images   play a symmetric  role and  we use  a
validity criterion for the matches that eliminates  gross errors: at places
where the images cannot be correlated reliably, due to  lack of  texture or
occlusions for example, the algorithm does not produce  wrong matches but a
very sparse disparity map as opposed to a dense one when the correlation is
successful. To generate dense depth map, the information is then propagated
across the  featureless areas,  but  not   across discontinuities,   by  an
interpolation scheme that takes image grey levels into  account to preserve
image features.
<p>
We show that our algorithm  performs very well on  difficult images such as
faces  and   cluttered  ground  level scenes.  Because   all the algorithms
described here are parallel and very  regular  they could be implemented in
hardware and lead to extremely fast stereo systems."
}

@article{Fua91b,
author   = "P. Fua",
title    = {{A Parallel Stereo Algorithm that Produces Dense Depth Maps and Preserves Image Features}},
journal  = MVA ,	
year     = 1993,
volume   = 6,
number   = 1,
month    = "Winter",
pages    = "35--49",
annote   = "Available as INRIA research report 1369"
}

@inproceedings{Fua91c,
author   = "P. Fua and P. Sander",
title    = {{From Points to Surfaces}},
address  = "San Diego, California",
booktitle= "SPIE Workshop on Geometric Methods in Computer Vision",
month    = "July",
year     = 1991
}

@inproceedings{Fua92a,
author   = "P. Fua and P. Sander",
title    = {{Reconstructing Surfaces from Unstructured 3D Points}},
address  = "San Diego, California",
booktitle= IU,
month    = "January",
year     = 1992,
abstract = 
"Most active and  passive range  finding techniques yield unstructured  and
generally noisy 3D points.  In order to build useful world representations,
one  must be able to remove spurious  data points and group  the  remaining
into meaningful surfaces.

In  this paper, we  propose  an approach based  on fitting local  surfaces.
Differential properties of these  surfaces  are  first  used iteratively to
smooth the points, and then to group them  into more  global surfaces while
eliminating errors.

We present results on complex indoor and outdoor  scenes using  stereo data
as our source of 3D information.",  
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-sander-iu92.ps.gz",
}

@inproceedings{Fua92b,
author   = "P. Fua and P. Sander",
title    = {{Segmenting Unstructured 3D Points  into Surfaces}},
address  = "Genoa, Italy",
booktitle=  ECCV,
month    = "April",
year     = 1992
}

@inproceedings{Fua92c,
author   = "P. Fua and B. Hotz and O. Faugeras",
title    = {{Using local Surfaces to Build Terrain Models from Ground Level Stereo}},
address  = "Washington, D.C.",
booktitle=  IROS,
month    = "July",
year     = 1992
}

@inproceedings{Fua93b,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Combining Stereo,  Shading  and Geometric Constraints  for Surface Reconstruction from  Multiple Views.}},
address  = "San Diego, CA",
booktitle= "SPIE Workshop on Geometric Methods in Computer Vision",
month    = "July",
year     = 1993
}

@inproceedings{Fua93c,
author   = "B. Hotz and Z. Zhang and P. Fua ",
title    = {{Incremental construction of local D.E.M for an autonomous planetary rover}},
address  = "Antibes, France",
booktitle= "Workshop on Computer Vision for Space Applications",
month    = "September",
year     = 1993
}

@inproceedings{Fua94a,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Using 3--Dimensional Meshes To Combine Image-Based and Geometry-Based Constraints}},
booktitle= ECCV,
address  = "Stockholm, Sweden",
month    = "May",
year     = 1994,
pages    ="281--291",
abstract = 
"To recover complicated surfaces,  single information sources  often  prove
insufficient. In  this paper, we present a unified framework for 3--D shape
reconstruction  that allows us to combine image-based constraints, such  as
those  deriving  from  stereo and shape-from-shading,  with  geometry-based
ones,  provided here in the  form of 3--D  points,  3--D  features or  2--D
silhouettes.
<p>
Our approach to shape recovery is to deform a generic object-centered  3--D
representation of  the surface so  as  to minimize  an objective  function.
This objective  function  is  a weighted sum of  the  contributions  of the
various information sources.  We describe these various terms individually,
our  weighting  scheme  and our optimization method.  Finally,  we  present
results on  a number of difficult images of real scenes  for which a single
source of information would have proved insufficient.",
annote   = "Also available as Tech Note 536, Artificial Intelligence Center, SRI International",
url      = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-536.ps.gz"
}

@inproceedings{Fua94b,
author      = "P. Fua and Y. G. Leclerc",
title       = {{Registration Without Correspondences}},
booktitle   = CVPR,
address     = "Seattle, WA",
month       = "June",
year        = 1994,
pages       = "121--128",
abstract = 
"In this  paper, we present a method for registering images of complex 3--D
surfaces that  does  not require explicit correspondences between  features
across the images. Our method relies on the use of a full 3--D model of the
surface to adjust the position and orientation  of the camera by minimizing
an objective  function  based  on the projections  of the  images onto  the
model.  This approach constrains the  camera parameters  strongly enough so
that the  models  do not need,  initially, to  be  accurate to  yield  good
results.  When registration  has been achieved, the  models  can be refined
and the fine details recovered.
<p>
Our method is applicable to the calibration  of stereo imagery, the precise
registration of  new images  of a  scene  and the  tracking  of  deformable
objects. It can therefore lead to important applications in fields such  as
augmented reality in a medical context or data compression for transmission
purposes.  We demonstrate its applicability by using both  synthetic images
and real images of faces and of terrain.",
keywords      = "Registration, Calibration, Surface reconstruction, Stereo, Deformable surfaces",
annote        = "Also available as Tech Note 537, Artificial Intelligence Center, SRI International",
url      =  "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-537.ps.gz"
}

@article{Fua94c,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Object-Centered Surface Reconstruction: Combining Multi-Image Stereo and Shading}},
journal  =  IJCV,
year     = 1995,
month    = "September",
volume   = 16,
pages    = "35--56",
note     = "Also available as Tech Note 535, Artificial Intelligence Center, SRI International",
abstract = 
"Our  goal is to  reconstruct  both the shape and reflectance properties of
surfaces   from   multiple  images.   We  argue   that  an  object-centered
representation  is most appropriate  for this purpose because it  naturally
accommodates multiple  sources  of  data, multiple images (including motion
sequences of  a  rigid object), and  self-occlusions.   We then  present  a
specific object-centered reconstruction method and its implementation.  The
method begins  with  an initial  estimate  of surface  shape  provided, for
example, by triangulating the  result of  conventional stereo.  The surface
shape and reflectance properties are then iteratively  adjusted to minimize
an objective function that combines information from multiple input images.
The objective function is a weighted sum of stereo, shading, and smoothness
components,  where the  weight varies  over  the surface.  For example, the
stereo component is weighted more strongly where the surface  projects onto
highly textured areas  in the images,  and less strongly  otherwise.  Thus,
each component has its greatest  influence  where its accuracy is likely to
be greatest.  Experimental  results on both  synthetic and real images  are
presented.",
annote   = "Also available as Tech Note 535, Artificial Intelligence Center, SRI International",
keywords = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-leclerc-ijcv93.ps.gz"
}

@inproceedings{Fua94e,
author      = "P. Fua and Y. G. Leclerc",
title       = {{A Unified Framework to  Recover 3--D Surfaces by Combining Image-Based and Externally-Supplied Constraints}},
booktitle   =  IU,
address     = "Monterey, CA",
month       = "November",
year        =  1994,
windexkey   = "sri aic paper papers"
}

@inproceedings{Fua94f,
author      = "P. Fua and Y. G. Leclerc",
title       = {{Image Registration without Explicit Point Correspondences}},
booktitle   =  IU,
address     = "Monterey, CA",
month       = "November",
year        =  1994,
windexkey   = "sri aic paper papers"
}

@TechReport{Fua94g,
author =      "P. Fua",
title =       {{Reconstructing Complex Surfaces  from Multiple Stereo Views}},
institution = "Artificial Intelligence Center, SRI International",
year        = "1994",
type        = "Tech Note",
number      = "550",
month       = "November",
keywords    = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
windexkey   = "sri aic technical note notes",
url         = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-550.ps.gz"
}

@inproceedings{Fua95a,
author      = "P. Fua",
title       = {{Surface Reconstruction Using 3--D Meshes And Particle Systems}},
booktitle   = "Third International Workshop on High Precision Navigation",
address     = "Stuttgart, Germany",
month       = "April",
year        = 1995,
publisher   = {{D\"ummler-Verlag}},
url         = "ftp://ftp.ai.sri.com/pub/papers/fua-navigation95.ps.gz"
}

@inproceedings{Fua95b,
author      = "P. Fua",
title       = {{Reconstructing Complex Surfaces  from Multiple Stereo Views}},
booktitle   =  ICCV,
address     = "Cambridge, MA",
month       = "June",
year        =  1995,
note        = "Also available as Tech Note 550, Artificial Intelligence Center, SRI International",
abstract    =
"We present a framework for 3--D surface reconstruction that can be used to
model fully 3--Dimensional scenes from an arbitrary  number of stereo views
taken   from   vastly different  viewpoints.   This  is  a key  step toward
producing 3--D  world-descriptions of complex  scenes using stereo and is a
very challenging problem:  real-world   scenes tend to  contain  many  3--D
objects, they do not  usually conform  to the  2-1/2--D assumption  made by
traditional algorithms,  and  one cannot   take  it for granted  that   the
computed 3--D     points can easily  be   clustered   into separate groups.
Furthermore, stereo data is often incomplete and sometimes erroneous, which
makes the problem even more difficult.
<p>
By combining  a    particle-based  representation,  robust   fitting,   and
optimization of  an image-based objective   function, we have been able  to
reconstruct surfaces without any {\em a priori} knowledge of their topology
and in spite of the noisiness of the stereo data.
<p>
Our current implementation goes through three steps---initializing a set of
particles from the input 3--D data,  optimizing their location, and finally
grouping  them   into   global surfaces.    Using  several  complex  scenes
containing multiple  objects, we demonstrate its  competence and ability to
merge information and thus to go beyond what can  be done with conventional
stereo alone.",
keywords    = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
url         = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-550.ps.gz"
}

@article{Fua95c,
author   = "P. Fua and Y. G. Leclerc",
title    = {{Taking Advantage of Image-Based and Geometry-Based Constraints to Recover 3--D Surfaces}},
journal  = CVGIP:IU,
year     = 1995,
note     = "Accepted for publication, available as Tech Note 536, Artificial Intelligence Center, SRI International",
abstract = 
"To recover complicated surfaces,  single information sources  often  prove
insufficient. In  this paper, we present a unified framework for 3--D shape
reconstruction  that allows us to combine image-based constraints, such  as
those  deriving  from  stereo and shape-from-shading,  with  geometry-based
ones,  provided here in the  form of 3--D  points,  3--D  features or  2--D
silhouettes.
<p>
Our approach to shape recovery is to deform a generic object-centered  3--D
representation of  the surface so  as  to minimize  an objective  function.
This objective  function  is  a weighted sum of  the  contributions  of the
various information sources.  We describe these various terms individually,
our  weighting  scheme  and our optimization method.  Finally,  we  present
results on  a number of difficult images of real scenes  for which a single
source of information would have proved insufficient.",
url      = "ftp://ftp.ai.sri.com/pub/tech-notes/1993/aic-tn-536.ps.gz"
}

@article{Fua95d,
author   = "P. Fua",
title    = {{From Multiple Stereo Views to Multiple 3--D Surfaces}},
journal  = IJCV,
year     = 1996,
note     = "Accepted for publication, available as Tech Note 550, Artificial Intelligence Center, SRI International",
keywords = "stereo, shape from shading, multiple images, data fusion, object-centered representations, surface reconstruction",
abstract =
"We present a framework for 3--D surface reconstruction that can be used to
model fully 3--Dimensional scenes from an arbitrary  number of stereo views
taken   from   vastly different  viewpoints.   This  is  a key  step toward
producing 3--D  world-descriptions of complex  scenes using stereo and is a
very challenging problem:  real-world   scenes tend to  contain  many  3--D
objects, they do not  usually conform  to the  2-1/2--D assumption  made by
traditional algorithms,  and  one cannot   take  it for granted  that   the
computed 3--D     points can easily  be   clustered   into separate groups.
Furthermore, stereo data is often incomplete and sometimes erroneous, which
makes the problem even more difficult.
<p>
By combining  a    particle-based  representation,  robust   fitting,   and
optimization of  an image-based objective   function, we have been able  to
reconstruct surfaces without any {\em a priori} knowledge of their topology
and in spite of the noisiness of the stereo data.
<p>
Our current implementation goes through three steps---initializing a set of
particles from the input 3--D data, optimizing  their location, and finally
grouping them into   global  surfaces.    Using several   complex    scenes
containing multiple objects, we  demonstrate its competence and  ability to
merge information and thus to go beyond  what can be done with conventional
stereo alone.",
url      = "ftp://ftp.ai.sri.com/pub/tech-notes/1994/aic-tn-550.ps.gz"
}

@inproceedings{Fua95e,
author   = "P. Fua",
title    = {{Parametric Models are Versatile:  The Case of Model Based Optimization}},
address	 = "Stockholm, Sweden",
booktitle= "ISPRS WG III/2 Joint Workshop",
month    = "September",
year     = 1995,
abstract = 
"Model-Based  Optimization  (MBO)   is a paradigm  in   which  an objective
function is used  to express both  geometric and photometric constraints on
features of interest.   A parametric model of a  feature (such as a road, a
building, or coastline)  is extracted from one or  more images by adjusting
the model's state variables until a minimum value of the objective function
is  obtained.   The  optimization  procedure   yields a   description  that
simultaneously satisfies  (or nearly satisfies)  all constraints, and, as a
result, is likely to be a good model of the feature.",
url      = "ftp://ftp.ai.sri.com/pub/papers/fua-isprs95.ps.gz"
}

@TechReport{Fua95f,
author =      "P. Fua and C. Brechbuehler",
title =       {{Imposing Hard Constraints on Soft Snakes}},
institution = "Artificial Intelligence Center, SRI International",
year        = "1995",
type        = "Tech Note",
number      = "553",
month       = "October",
keywords    = "snakes, deformable models, constrained optimization, consistency",
windexkey   = "sri aic technical note notes",
url         = "ftp://ftp.ai.sri.com/pub/tech-notes/1995/aic-tn-553.ps.gz"
}

@inproceedings{Waneu94a,
author      = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title       = {{Initializing Snakes}},
booktitle   = CVPR,
address     = "Seattle, WA",
month       = "June",
year        = 1994,
pages       = "658--663"
}

@inproceedings{Waneu94b,
author   = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title    = {{Making Snakes Converge from Minimal Initialization}},
address  = "Jerusalem, Israel",
booktitle= ICPR,
month	 = "October",
pages    = "658--663",
year     = 1994
}

@inproceedings{Waneu94c,
author    = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title     = {{Making Snakes Converge from Minimal Initialization}},
booktitle = IU,
address     = "Monterey, CA",
month       = "November",
year        =  1994
}

@article{Waneu94d,
author    = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title     = {{Ziplock Snakes}},
journal   = IJCV,
year      =  1994,
note      = "Submitted for publication, available as Tech Note 548, Artificial Intelligence Center, SRI International",
abstract = 
"We  propose  a snake-based approach  that  lets  a user specify  only  the
distant  endpoints  of the curve  he wishes to delineate without  having to
supply an almost complete polygonal approximation.  We greatly simplify the
initialization process and achieve much better  convergence properties than
those of traditional snakes  by  using the  image  information around these
endpoints to provide boundary conditions and by introducing an optimization
schedule that allows a snake to take image  information into account  first
only near its extremities and then, progressively, toward its  center.   In
effect,  the  snakes are  clamped  onto  the  image  contour  in  a  manner
reminiscent of a ziplock being closed.
<p>
These  snakes  can  be   used  to  alleviate   the  often  repetitive  task
practitioners face  when segmenting images by abolishing the need to sketch
a feature of interest  in its entirety, that is, to  perform a painstaking,
almost complete, manual segmentation.",
annote   =  "Submitted for publication, also available as Tech Note 548, Artificial Intelligence Center, SRI International",
keywords =  "Snakes, Deformable models, Interactive initialization, Boundary conditions.",
url      =  "ftp://ftp.ai.sri.com/pub/tech-notes/1994/aic-tn-548.ps.gz"
}

@inproceedings{Waneu95a,
author      = "W. Neuenschwander and P. Fua and G. Sz\'ekely and O. Kubler",
title       = {{Velcro Surfaces}},
booktitle   =  ICCV,
address     = "Cambridge, MA",
month       = "June",
year        =  1995
}
@INPROCEEDINGS{Israel93h,
AUTHOR="Israel, D. J.",
TITLE="The Very Idea of Dynamic Semantics",
BOOKTITLE="Proceedings of the Ninth Amsterdam Colloquium",
YEAR="1993",
ADDRESS="Amsterdam",
MONTH="December",
URL="ftp://ftp.ai.sri.com/pub/papers/amsterdam_illc.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INCOLLECTION{Israel89a,
AUTHOR="Israel, D. J.",
TITLE="Concepts of Information: Comparative Axiomatics",
BOOKTITLE="Philosophical Logic and Artificial Intelligence",
EDITOR="Thomason, R.",
PUBLISHER="Kluwer Academic Publishers",
ADDRESS="Dordrecht",
YEAR="1989",
NOTE="Also published as SRI Technical Note 469, June, 1989",
URL="ftp://ftp.ai.sri.com/pub/papers/conceptsofinformation.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INCOLLECTION{Israel91a,
AUTHOR="Israel, D. J. and J. R. Perry",
TITLE="Fodor and Psychological Explanations",
BOOKTITLE="Meaning in Mind",
EDITOR="Loewer, B. and G. Rey",
PUBLISHER="Basil Blackwell",
ADDRESS="Oxford",
YEAR="1991",
NOTE="Also published as CSLI Report No. CSLI-91-146, January, 1991",
URL="ftp://ftp.ai.sri.com/pub/papers/fodor_finalversion.ps.gz",
WINDEXKEY="sri aic paper papers"
}


@ARTICLE{IsrPerTut93f,
AUTHOR="Israel, D. J. and J. R. Perry and S. Tutiya",
TITLE="Executions, Motivations, and Accomplishments",
JOURNAL="Philosophical Review",
YEAR="1993",
VOLUME="102",
NUMBER="4",
MONTH="October",
URL="ftp://ftp.ai.sri.com/pub/papers/finalphilrev.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INCOLLECTION{Israel93b,
AUTHOR="Israel, D. J.",
TITLE="The Role(s) of Logic in Artificial Intelligence",
BOOKTITLE="The Handbook of Logic in Artificial Intelligence and Logic
Programming, Volume I",
EDITOR="Gabbay, D. M. and  Hogger, C. J.  and Robinson, J. A.",
PUBLISHER="Oxford University Press",
YEAR="1993",  
URL="ftp://ftp.ai.sri.com/pub/papers/handbook_pubstyle.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{IsrPerTut91c,
AUTHOR="Israel, D. J. and J. R. Perry and S. Tutiya",
TITLE="Actions and Movements",
BOOKTITLE="Proceedings of IJCAI-91",
ADDRESS="Sydney, Australia",
YEAR="1991",
MONTH="August",
URL="ftp://ftp.ai.sri.com/pub/papers/ijcai91_final.ps.gz",
WINDEXKEY="sri aic paper papers"
}


@INCOLLECTION{IsrPer91d,
AUTHOR="Israel, D. J. and J. R. Perry",
TITLE="Information and Architecture",
BOOKTITLE="Situation Theory and its Applications, Volume II",
EDITOR="J. Barwise and J. M. Gawron and G. Plotkin and S. Tutiya",
YEAR="1991",
PUBLISHER="University of Chicago Press/CSLI Lecture Notes",
ADDRESS="Stanford",
URL="ftp://ftp.ai.sri.com/pub/papers/scotland_final.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Israel93e,
AUTHOR="Israel, D. J.",
TITLE="Review of Language in Action: Categories, Lambdas, and Dynamic
Logic, by J. van Benthem",
JOURNAL="Artificial Intelligence Journal",
YEAR="1993",
VOLUME="63", 
NUMBER="1-2",
MONTH="October",
URL="ftp://ftp.ai.sri.com/pub/papers/vanBenthem_aij.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INCOLLECTION{IsrPer90a,
AUTHOR="Israel, D. J. and J. R. Perry",
TITLE="What is Information?",
BOOKTITLE="Information, Language and Cognition: Vancouver Studies in
Cognitive Science, Vol. I",
EDITOR="P. Hanson",
PUBLISHER="University of British Columbia Press",
YEAR="1990",
NOTE="Also published as CSLI Report No. CSLI-91-145, January, 1991",
URL="ftp://ftp.ai.sri.com/pub/papers/whatisinfo.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INCOLLECTION{Isra9406:Where,
AUTHOR="Israel, D. J. and J. R. Perry",
TITLE="Where Monsters Dwell",
BOOKTITLE="Proceedings of the Conference on Information-Oriented
Approaches to Language, Logic and Computation",
EDITOR="D. Westerstahl and E. Engdahl and J. Etchemendy and J. Seligman and  H. Sirai",
PUBLISHER="CSLI/University of Chicago Press",
YEAR="1994",
ADDRESS="Moraga CA",
URL="ftp://ftp.ai.sri.com/pub/papers/kaplan_monsters.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Brat88:Plans,
AUTHOR="Bratman, M. E. and D. J. Israel and M. E. Pollack",
TITLE="Plans and {Resource-Bounded} Practical Reasoning",
JOURNAL="CIJ",
VOLUME=4,
NUMBER=4,
PAGES="349-355",
YEAR=1988,
URL="ftp://ftp.ai.sri.com/pub/papers/compint.ps.gz",
WINDEXKEY="sri aic paper papers"
}


@INPROCEEDINGS{Appe9309:FASTUS,
AUTHOR="Appelt, D. and J. Hobbs and J. Bear and D. J. Israel and M. Tyson",
TITLE="FASTUS: A Finite-State Processor for Information Extraction
from Real-World Text",
BOOKTITLE="Proceedings of IJCAI-93",
ADDRESS="Chambery, France",
MONTH="September",
YEAR="1993",
URL="ftp://ftp.ai.sri.com/pub/papers/ijcai_fastus.ps.gz",
WINDEXKEY="sri aic paper papers"
}


@ARTICLE{Isra88:Bogd,
AUTHOR="Israel, D. J.",
TITLE="A Commentary on Bogdan's `Information and Semantic Cognition'",
JOURNAL="Mind and Language",
VOLUME="3",
NUMBER="2",
YEAR="1988",
URL="ftp://ftp.ai.sri.com/pub/israel/bogdan.dvi.gz",
WINDEXKEY="sri aic papers israel"
}

@ARTICLE{Isra88a:Chee,
AUTHOR="Israel, D. J.",
TITLE="On Cheeseman: A response to Peter Cheeseman's `An
Inquiry into Computer Understanding'",
JOURNAL="Computational Intelligence", 
VOLUME="4",
NUMBER= "1",
MONTH="February", 
YEAR="1988",
URL="ftp://ftp.ai.sri.com/pub/israel/cheeseman.dvi.gz",
WINDEXKEY="sri aic papers israel"
}

@ARTICLE{Isra87a:Cress,
AUTHOR="Israel, D. J.",
TITLE="Review of `Structured Meanings: The Semantics of
Propositional Attitudes'",
JOURNAL="Journal of Symbolic Logic",
VOLUME="52", 
NUMBER="3",
MONTH="September",
YEAR="1987",
URL="ftp://ftp.ai.sri.com/pub/israel/cresswelljsl.dvi.gz",
WINDEXKEY="sri aic papers israel"
}

@ARTICLE{Isra87b:Revi,
AUTHOR="Israel, D. J.",
TITLE="Review of `Structured Meanings: The Semantics of
Propositional Attitudes'",
JOURNAL="Computational Linguistics",
VOLUME="13", 
NUMBER="3-4",
MONTH="December",
YEAR="1987",
URL="ftp://ftp.ai.sri.com/pub/israel/cresswellreview.dvi.gz",
WINDEXKEY="sri aic papers israel"
}


@ARTICLE{Isra87:Mcde,
AUTHOR="Israel, D. J.",
TITLE="On McDermott's First Critique",
JOURNAL="Computational Intelligence", 
VOLUME="3", 
NUMBER="3", 
MONTH="August", 
YEAR="1987",
URL="ftp://ftp.ai.sri.com/pub/israel/drew2.dvi.gz",
WINDEXKEY="sri aic papers israel"
}

@ARTICLE{Isra91g:Katz,
AUTHOR="Israel, D. J.",
TITLE="Katz and Postal on Realism in Linguistics",
JOURNAL="Linguistics and Philosophy", 
VOLUME="14",
NUMBER="5", 
MONTH="October", 
YEAR="1991",
URL="ftp://ftp.ai.sri.com/pub/israel/kp.dvi.gz",
WINDEXKEY="sri aic papers israel"
}
 
@ARTICLE{Isra94a:Kybu,
AUTHOR="Israel, D. J.",
TITLE="Commentary on Kyburg",
JOURNAL="Computational Intelligence",
VOLUME="10",
NUMBER="1",
MONTH="February", 
YEAR="1994",
URL="ftp://ftp.ai.sri.com/pub/israel/kyburg_ci.dvi.gz",
WINDEXKEY="sri aic papers israel"
}


@INPROCEEDINGS{Isra92a:Luci,
AUTHOR="Israel, D. J.",
TITLE="Lucid and Intensional Logic",
BOOKTITLE="Proceedings of the Fifth International Symposium on Lucid
and Intensional Programming  Languages,"
ADDRESS="Menlo Park",
MONTH="April",
YEAR="1992",
URL="ftp://ftp.ai.sri.com/pub/israel/lucid_2.ps.gz",
WINDEXKEY="sri aic paper israel"
}


@INPROCEEDINGS{Isra80:What,
AUTHOR="Israel, D. J.",
TITLE="What's Wrong with Non-Monotonic Logic",
BOOKTITLE="Proceedings of the First Annual Conference of the American
Association for Artificial Intelligence", 
ADDRESS="Stanford University",
MONTH="August",
YEAR="1980"
NOTE="Reprinted in `Readings in Nonmonotonic Reasoning' edited by M.
Ginsberg, Morgan Kaufmann, 1987."
}

@INPROCEEDINGS{BraIsr81:Dist, 
AUTHOR="Brachman, R.J. and D. J. Israel", 
TITLE="Distinctions and Confusions: A Catalogue Raisonne",
BOOKTITLE="Proceedings of the Seventh International Joint Conference
on Artificial Intelligence", 
ADDRESS="Vancouver, B.C.",
MONTH="August", 
YEAR="1981", 
NOTE="Reprinted in `Context-Directed Pattern Recognition and Machine
Intelligence Techniques for Information Processing", edited by Y. Pao
and G. Ernst, IEEE Computer Society Press, 1982."
}

@INPROCEEDINGS{IsrSid81:Reco,
AUTHOR="Israel, D. J. and C. L. Sidner", 
TITLE="Recognizing Intended Meaning and Speakers' Plans",
BOOKTITLE="Proceedings of the Seventh International Joint Conference
on Artificial Intelligence",
ADDRESS="Vancouver, B.C.",
MONTH="August", 
YEAR="1981"
}

@INCOLLECTION{BraIsr84:Some,
AUTHOR="Brachman, R. J. and D. J. Israel", 
TITLE="Some Remarks on the Semantics of Representation Languages",
BOOKTITLE="On Conceptual Modelling: Perspectives from  Artificial
Intelligence, Databases and Programming Languages",
EDITOR="Brodie, M. and  Mylopoulos, J. and J. Schmidt",
PUBLISHER="Springer Verlag",
ADDRESS="New York",
YEAR="1984"
}

@ARTICLE{Isra83:Inte,
AUTHOR="Israel, D. J.",
TITLE="Interpreting Network Formalisms",
JOURNAL="International Journal of Computers and Mathematics",
VOLUME="9",
NUMBER="1",
YEAR="1983", 
NOTE="Issue was reprinted by Pergamon Press, Oxford, 1983.  A
version of this material has been published with a Technical Appendix
"Taxonomies of Natural Kinds," as a BBN technical report, `On
Interpreting Semantic Network Formalisms', Report No. 5117,
September 1982."
}

@INCOLLECTION{Isra83a:Pref,
AUTHOR="Israel, D. J.",
TITLE="Preface",
BOOKTITLE="Computational Models of Discourse",
EDITOR="M. Brady and  R. Berwick",
PUBLISHER="MIT Press",
ADDRESS="Cambridge",
YEAR="1983"
}

@INPROCEEDINGS{Isra83b:Prol,
AUTHOR="Israel, D. J.",
TITLE="A Prolegomenon to Situation Semantics",
BOOKTITLE="Proceedings of the Conference of the Association for Computational
Linguistics", 
ADDRESS="Cambridge",
MONTH="June",
YEAR="1983"
}

@ARTICLE{Isra83c:Rema,
AUTHOR="Israel, D. J.",
TITLE="Some Remarks on the Place of Logic in Knowledge Representation",
JOURNAL="IEEE Computer", 
VOLUME="16",
NUMBER="10",
MONTH="October",
YEAR="1983",
NOTE="Reprinted in `The Knowledge Frontier: Essays in the
Representation of Knowledge', edited by N. Cercone and G.McCalla,
Springer-Verlag, New York, 1987."
}


@INCOLLECTION{Isra85:Shor,
AUTHOR="Israel, D. J.",
TITLE="A Short Companion to the Naive Physics Manifesto",
BOOKTITLE="Formal Theories of the Common Sense World",
EDITOR="Hobbs, J. R. and R. C. Moore",
PUBLISHER="Ablex Publishing",
ADDRESS="Norwood, NJ",
YEAR="1985"
}

@INPROCEEDINGS{Isra83d:Sema,
AUTHOR="Israel, D. J.",
TITLE="Semantics and the Lexicon",
BOOKTITLE="Proceedings of the Second International Colloquium on the
Semantics of  Natural Language",
ADDRESS="Nijmegen",
MONTH="September",
YEAR="1983",
NOTE="Proceedings were also published as a special issue of the
Journal of Semantics, 1986"
}
  
@TECHREPORT{Isra85a:Weak,
AUTHOR="Israel, D. J.",
TITLE="A Weak Logic of Knowledge and Belief: Epistemic and Doxastic
Logic for the  Yuppie Generation",
TYPE="Technical Note",
NUMBER="359",
INSTITUTION="SRI",
ADDRESS="Menlo Park",
MONTH="September",
YEAR="1985",
NOTE="Also published as a CSLI Informal Note, No. IN-CSLI-85-3."
}

@INCOLLECTION{Isra86:Aikn,
AUTHOR="Israel, D. J.",
TITLE="AI Knowledge Bases and Databases",
BOOKTITLE="On Knowledge Base Management Systems: Integrating
Artificial Intelligence and Database Techniques",
EDITOR="Brodie, M. L. and J. Mylopoulos",
PUBLISHER="Springer-Verlag",
ADDRESS="NY",
YEAR="1986"
}

@INCOLLECTION{Isra86a:Note,
AUTHOR="Israel, D. J.",
TITLE="Notes on Inference: A Somewhat Skewed Survey",
BOOKTITLE="On Knowledge Base Management Systems: Integrating
Artificial Intelligence and Database Techniques",
EDITOR="Brodie, M. L. and J. Mylopoulos",
PUBLISHER="Springer-Verlag",
ADDRESS="NY",
YEAR="1986"
}

@ARTICLE{Isra85b:Nels,
AUTHOR="Israel, D. J.",
TITLE="Review of `The Logic of Mind'",
JOURNAL="Computational Linguistics",
VOLUME="11", 
NUMBER="1", 
MONTH="March",
YEAR="1985"
}

@TECHREPORT{Isra87d:Role,
AUTHOR="Israel, D. J.",
TITLE="The Role of Propositional Objects of Belief in Action",
TYPE="Technical Report",
INSTITUTION="CSLI",
NUMBER="CSLI-87-72",
MONTH="April",
YEAR="1987"
}

@INPROCEEDINGS{Isra89b:Very,
AUTHOR="Israel, D. J.",
TITLE="Very Brief Reflections: Critical issues in Nonmonotonic
Reasoning",
BOOKTITLE="Proceedings of the First International Conference on
Principles of Knowledge Representation and Reasoning",
EDITOR="Brachman, R. and   Levesque, H.  and R. Reiter",
PUBLISHER="Morgan Kaufmann",
YEAR="1989"
}

@ARTICLE{Isra89c:Logi,
AUTHOR="Israel, D. J.",
TITLE="Review of `Logical Foundations for Belief Representation'",
JOURNAL="Journal of Symbolic Logic",
VOLUME="54", 
NUMBER="2", 
MONTH="June",
YEAR="1989"
}

@INCOLLECTION{Isra90b:Form,
AUTHOR="Israel, D. J.",
TITLE="On Formal versus Commonsense Semantics",
BOOKTITLE="Theoretical Issues in Natural Language Processing",
EDITOR="Wilks, Y.",
PUBLISHER="Lawrence Erlbaum Associates",
ADDRESS="Hillsdale, NJ",
YEAR="1990"
}

@INCOLLECTION{Isra91b:Mcca,
AUTHOR="Israel, D. J.",
TITLE="A Sketch of the Life and Career of John McCarthy",
BOOKTITLE="Artificial Intelligence and Mathematical Theory of Computation:
Papers in Honor of John McCarthy",
EDITOR="Lifschitz, V.",
PUBLISHER="Academic Press",
ADDRESS="San Diego, CA", 
YEAR="1991",
NOTE="An earlier version of this note was published in the Notices of
the American Mathematical Society, Volume 38, Number 4, April, 1991."
}

@ARTICLE{Isra92b:Howto,
AUTHOR="Israel, D. J.",
TITLE="Review of `How to Build a Person'",
JOURNAL="Philosophical Review",
VOLUME="101",
NUMBER="4", 
MONTH="October",
YEAR="1992"
}

@TECHREPORT{IsrNak92c:Arch,
AUTHOR="Israel, D. J.  and Y. Nakatani",
TITLE="An Architecture for Tuning Rules by Cases",
TYPE="Technical Report",
INSTITUTION="CSLI",
NUMBER="CSLI-92-173", 
ADDRESS="Stanford",
YEAR="1992"
}

@INPROCEEDINGS{IsrNak93i:Tuni,
AUTHOR="Israel, D. J.  and Y. Nakatani",
TITLE="Tuning Rules by Cases",
BOOKTITLE="Proceedings of the First European Workshop on Case-Based
Reasoning", 
EDITOR="Richter, M. M. and S. Wess and  K. D. Althoff and F. Maurer",
ADDRESS="Kaiserslautern, Germany",
MONTH="November", 
YEAR="1993"
}



@misc{Isr95a:Proc,
AUTHOR="Israel, D. J.",
TITLE="Process Logics of Action",
Note="Draft",
Year="1995",
URL="ftp://ftp.ai.sri.com/pub/papers/process_logics.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Cava8505:Shadow,
AUTHOR="Cavanagh, P. and Leclerc, Y. G.",
TITLE="Shadow constraints",
BOOKTITLE="Meeting of the Association for Research in Vision and
Opthamology (ARVO)",
YEAR=1985,
ADDRESS="Sarasota, Florida",
MONTH="May 6--10",
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Cava89-3:Shape,
AUTHOR="Cavanagh, P. and Leclerc, Y. G.",
TITLE="Shape from shadows",
JOURNAL="Journal of Experimental Psychology: Human Perception and
Performance",
YEAR=1989,
VOLUME=15,
NUMBER=1,
PAGES="3-27",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Fisc9201:Recovering,
AUTHOR="Fischler, M. A. and Leclerc, Y. G.",
TITLE="Recovering {3-D} wire frames from line drawings",
BOOKTITLE=IU,
YEAR=1992,
ADDRESS="San Diego, California",
MONTH=jan,
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Kay85-574:Osteoclast,
AUTHOR="Kay, M. and Zucker, S. W. and Leclerc, Y. G. and Prichard, S.
and Hodsman, A. B. and Barr\'e, D. E.",
TITLE="Osteoclast Enlargment in {End-Stage} Renal Disease",
JOURNAL="Kidney International",
YEAR=1985,
VOLUME=27,
PAGES="574-581",
WINDEXKEY="sri aic paper papers"
}

@TECHREPORT{Lecl8101:Browsing,
AUTHOR="Leclerc, Y. G. and Zucker, S. W. and Leclerc, D.",
TITLE="A browsing approach to documenting documentation",
INSTITUTION="McGill University",
YEAR=1981,
TYPE="Technical Report",
NUMBER="TR-81-1R",
ADDRESS="Montr\'eal, Qu\'ebec",
MONTH=jan,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8106:Browsing,
AUTHOR="Leclerc, Y. G. and Zucker, S. W. and Leclerc, D.",
TITLE="A Browsing Approach to Documenting Documentation",
BOOKTITLE="Proceedings of the $7^{th}$ Canadian Man-Computer
Communications Conference",
YEAR=1981,
ADDRESS="Waterloo, Ontario",
MONTH=jun,
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Lecl8206-46:Browsing,
AUTHOR="Leclerc, Y. G. and Zucker, S. W. and Leclerc, D.",
TITLE="A Browsing Approach to Documentation",
JOURNAL="IEEE Computer Magazine",
YEAR=1982,
VOLUME=16,
NUMBER=6,
PAGES="46-49",
MONTH=jun,
WINDEXKEY="sri aic paper papers"
}

@TECHREPORT{Lecl8404:TechRep,
AUTHOR="Leclerc, Y. G. and Zucker, S. W.",
TITLE="{TechRep---TeX82} macros for writing papers and {CVaRL} technical
reports",
INSTITUTION="McGill University",
YEAR=1984,
TYPE="Technical Report",
NUMBER="TR-84-7R",
ADDRESS="Montr\'eal, Qu\'ebec",
MONTH=apr,
WINDEXKEY="sri aic paper papers"
}

@TECHREPORT{Lecl8405:Local,
AUTHOR="Leclerc, Y. G. and Zucker, S. W.",
TITLE="The local structure of image discontinuities in one dimension",
INSTITUTION="McGill University",
YEAR=1984,
TYPE="Technical Report",
NUMBER="TR-83-19R",
ADDRESS="Montr\'eal, Qu\'ebec",
MONTH=may,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8408:Local,
AUTHOR="Leclerc, Y. G. and Zucker, S. W.",
TITLE="The Local Structure of Image Discontinuities in One Dimension",
BOOKTITLE="Proceedings of the $7^{th}$ International Conference on
Pattern Recognition",
YEAR=1984,
ADDRESS="Montr\'eal, Qu\'ebec",
MONTH=aug,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8411:Local,
AUTHOR="Leclerc, Y. G. and Zucker, S. W.",
TITLE="The Local Structure of Image Discontinuities",
BOOKTITLE="Technical Program of the 1984 Annual Meeting of the Optical
Society of America",
YEAR=1984,
ADDRESS="San Diego, California",
MONTH=nov,
NOTE="Abstract also in {\em Optics News}, Vol.~10(5), September/October,
1984.",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8505:Local,
AUTHOR="Leclerc, Y. G.",
TITLE="The local structure of image discontinuities: Their form and
function",
BOOKTITLE="Programme of the Rank Prize Funds Mini-Symposium on
Representation and Control in Visual Processing",
YEAR=1985,
ADDRESS="Great Malvern, England",
MONTH=may,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8506-34:Capturing,
AUTHOR="Leclerc, Y. G.",
TITLE="Capturing the Local Structure of Image Discontinuities in Two
Dimensions",
BOOKTITLE="Proceedings of the IEEE Computer Society Conference on
Computer Vision and Pattern Recognition",
YEAR=1985,
PAGES="34--38",
ADDRESS="San Francisco, California",
MONTH=jun,
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Lecl87-341:Local,
AUTHOR="Leclerc, Y. G. and Zucker, S. W.",
TITLE="The Local Structure of Image Discontinuities in One Dimension",
JOURNAL="IEEE Transactions on Pattern Analysis and Machine Intelligence",
YEAR=1987,
VOLUME=9,
NUMBER=3,
PAGES="341--355",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8702-888:Finding,
AUTHOR="Leclerc, Y. G. and Fua, P.",
TITLE="Finding object boundaries using guided gradient ascent",
BOOKTITLE=IU,
YEAR=1987,
PAGES="888-891",
ADDRESS="Los Angeles, California",
MONTH=feb,
NOTE="Also in the {\em Proceedings of the Topical Meeting on Machine
Vision of the Optical Society of America}, pages 168-171, Incline
Village, Nevada, March 1987",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8804-365:Constructing,
AUTHOR="Leclerc, Y. G.",
TITLE="Constructing Simple Stable Descriptions for Image Partitioning",
BOOKTITLE=IU,
YEAR=1988,
PAGES="365-382",
ADDRESS="Cambridge, Massachusetts",
MONTH=apr,
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Lecl89-73:Constructing,
AUTHOR="Leclerc, Y. G.",
TITLE="Constructing Simple Stable Descriptions for Image Partitioning",
JOURNAL=IJCV,
YEAR=1989,
VOLUME=3,
NUMBER=1,
PAGES="73-102",
ABSTRACT="A new formulation of the image partitioning problem is
presented: construct a complete and stable description of an image, in
terms of a specified descriptive language, that is simplest in the sense
of being shortest. We show that a descriptive language limited to a
low-order polynomial description of the intensity variation within each
region and a chain-code-like description of the region boundaries yields
intuitively satisfying partitions for a wide class of images. <p> The
advantage of this formulation is that it can be extended to deal with
subsequent steps of the image-understanding problem (or to deal with
other image attributes, such as texture) in a natural way by augmenting
the descriptive language. Experiments performed on a variety of both
real and synthetic images demonstrate the superior performance of this
approach over partitioning techniques based on clustering vectors of
local image attributes and standard edge-detection techniques.",
KEYWORDS="image partitioning, minimum-length encoding, maximum
a-posteriori strategy, edge detection, adaptive smoothing",
URL="ftp://ftp.ai.sri.com/pub/papers/leclerc-ijcv89.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8904:Segmentation,
AUTHOR="Leclerc, Y. G.",
TITLE="Segmentation via {Minimal-Length} Encoding on the Connection
Machine",
BOOKTITLE="Proceedings of the Fourth International Conference on
Supercomputing and Third World Supercomputer Exhibition",
YEAR=1989,
ADDRESS="Santa Clara, California",
MONTH="April-May",
NOTE="Also in SRI Technical Note 458: ``The Vision Problem: Exploiting
Parallel Computation'', Fischler et al.",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8905:Image,
AUTHOR="Leclerc, Y. G.",
TITLE="Image and Boundary Segmentation via {Minimal-Length} Encoding on
the Connection Machine",
BOOKTITLE=IU,
YEAR=1989,
ADDRESS="Palo Alto, California",
MONTH=may,
WINDEXKEY="sri aic paper papers"
}

@PHDTHESIS{Lecl8905:Local,
AUTHOR="Leclerc, Y. G.",
TITLE="The Local Structure of Image Intensity Discontinuities",
SCHOOL="McGill University",
YEAR=1989,
ADDRESS="Montr\'eal, Qu\'ebec, Canada",
MONTH=may,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl8909:Image,
AUTHOR="Leclerc, Y. G.",
TITLE="Image Segmentation via {Minimal-Length} Encoding",
BOOKTITLE="Proceedings of the Sixth Multidimensional Signal Processing
Workshop",
YEAR=1989,
ORGANIZATION="IEEE Acoustics, Speech, and Signal Processing Society",
ADDRESS="Asilomar, Pacific Grove, California",
MONTH=sep,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl9003:Simplicity,
AUTHOR="Leclerc, Y. G.",
TITLE="Simplicity of Description as the Basis for Visual Interpretation",
BOOKTITLE="Working Notes of the AAAI Spring Symposion on The Theory and
Application of Minimal-Length Encoding",
YEAR=1990,
ORGANIZATION="American Association for Artificial Intelligence",
ADDRESS="Stanford University, Palo Alto, California",
MONTH=mar,
KEYWORDS="image partitioning, minimum-length encoding, maximum
a-posteriori strategy, edge detection, adaptive smoothing, mdl",
URL="ftp://ftp.ai.sri.com/pub/papers/leclerc-aaai90.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl9009:Region,
AUTHOR="Leclerc, Y. G.",
TITLE="Region Grouping Using the {Minimum-Description-Length} Principle",
BOOKTITLE=IU,
YEAR=1990,
ADDRESS="Pittsburgh, Pennsylvania",
MONTH=sep,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl9106:Direct,
AUTHOR="Leclerc, Y. G. and Bobick, A. F.",
TITLE="The direct computation of height from shading",
BOOKTITLE=CVPR,
YEAR=1991,
ADDRESS="Lahaina, Maui, Hawaii",
MONTH=jun,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Lecl9201:Direct,
AUTHOR="Leclerc, Y. G. and Bobick, A. F.",
TITLE="The direct computation of height from shading",
BOOKTITLE=IU,
YEAR=1992,
ADDRESS="San Diego, California",
MONTH=jan,
ABSTRACT="We present a method of recovering shape from shading that
solves directly for the surface height. By using a discrete formulation
of the problem, we are able to achieve good convergence behavior by
employing numerical solution techniques more powerful than gradient
descent methods derived from variational calculus. Because we directly
solve for height, we avoid the problem of finding an integrable surface
maximally consistent with surface orientation. Furthermore, since we do
not need additional constraints to make the problem well posed, we use a
smoothness constraint only to drive the system towards a good solution;
the weight of the smoothness term is eventually reduced to near zero.
Also, by solving directly for height, we can use stereo processing to
provide initial and boundary conditions. Our shape from shading
technique, as well as its relation to stereo, is demonstrated on both
synthetic and real imagery.",
KEYWORDS="shape from shading, direct methods, continuation methods,
height from shading",
URL="ftp://ftp.ai.sri.com/pub/papers/leclerc-bobick-iu92.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Lecl9211-113:Optimization,
AUTHOR="Leclerc, Y. G. and Fischler, M. A.",
TITLE="An {Optimization-Based} Approach to the Interpretation of Single
Line Drawings as {3-D} Wire Frames",
JOURNAL="International Journal of Computer Vision",
YEAR=1992,
VOLUME=9,
NUMBER=2,
PAGES="113-136",
MONTH=nov,
ABSTRACT="Line drawings provide an effective means of communication
about the geometry of 3-D objects. An understanding of how to duplicate
the way humans interpret line drawings is extremely important in
enabling man-machine communication with respect to images, diagrams, and
spatial constructs. In particular, such an understanding could be used
to provide the human with the capability to create a line-drawing sketch
of a polyhedral object that the machine can automatically convert into
the intended 3-D model. <p> A recently published paper \cite{Marill91}
presented a simple optimization procedure supposedly able to duplicate
human judgment in recovering the 3-D ``wire frame'' geometry of objects
depicted in line drawings. Marill provided some impressive examples, but
no theoretical justification for his approach. In this paper we
introduce our own work by first critically examining Marill's algorithm.",
ANNOTE="We provide an explanation for why Marill's algorithm was able to
perform as well as it did on the examples he presented, discuss its
weaknesses, and show very simple examples where it fails. We then
provide an algorithm that improves on Marill's results. In particular,
we show that an effective objective function must favor both symmetry
and planarity---Marill deals only with the symmetry issue. By modifying
Marill's objective function to explicitly favor planar-faced solutions,
and by using a more competent optimization technique, we were able to
demonstrate significantly improved performance in all of the examples
Marill provided and those additional ones we constructed ourselves.
Finally, we examine some questions relevant to the implications of this
work for understanding the human ability to interpret line drawings.",
KEYWORDS="computer vision, human vision, line drawings, line drawing
interpretation, man-machine communication, wire frames",
URL="ftp://ftp.ai.sri.com/pub/papers/leclerc-fischler-ijcv92.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@MastersThesis{Leclerc80,
  author = 	 "Leclerc, Y. G.",
  title = 	 "Relaxation Labeling and Maxima Selection",
  school = 	 "McGill University",
  year = 	 "1980",
  ADDRESS="Montr\'eal, Qu\'ebec, Canada",
  OPTmonth = 	 {January},
  WINDEXKEY="sri aic paper papers",
}

@INPROCEEDINGS{Zuck7804:Intensity,
AUTHOR="Zucker, S. W. and Leclerc, Y. G.",
TITLE="Intensity Clustering by Relaxation",
BOOKTITLE="Proceedings of the Workshop on Pattern Recognition and
Artificial Intelligence",
YEAR=1978,
ADDRESS="Princeton, New Jersey",
MONTH=apr,
WINDEXKEY="sri aic paper papers"
}

@TECHREPORT{Zuck7812:Continuous,
AUTHOR="Zucker, S. W. and Leclerc, Y. G. and Mohammed, J. L.",
TITLE="Continuous Relaxation and Local Maxima Selection: Conditions for
Equivalence",
INSTITUTION="McGill University",
YEAR=1978,
TYPE="Technical Report",
NUMBER="TR-78-15R",
ADDRESS="Montr\'eal, Qu\'ebec",
MONTH=dec,
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Zuck7908:Continuous,
AUTHOR="Zucker, S. W. and Leclerc, Y. G. and Mohammed, J. L.",
TITLE="Continuous Relaxation and Local Maxima Selection: Conditions for
Equivalence",
BOOKTITLE="Proceedings of the $6^{th}$ International Joint Conference on
Artificial Intelligence",
YEAR=1979,
ADDRESS="Tokyo, Japan",
MONTH=aug,
WINDEXKEY="sri aic paper papers"
}

@ARTICLE{Zuck8103-117:Continuous,
AUTHOR="Zucker, S. W. and Leclerc, Y. G. and Mohammed, J. L.",
TITLE="Continuous Relaxation and Local Maxima Selection: Conditions for
Equivalence",
JOURNAL=PAMI,
YEAR=1981,
VOLUME=3,
NUMBER=2,
MONTH=mar,
PAGES="117-127",
WINDEXKEY="sri aic paper papers"
}

@article{PROJECT-MONITORING,
        author = "Per R. Stokke and Thomas A. Boyce and John D. Lowrance and
		 William K. Ralston, Jr.",
        title = "Industrial Project Monitoring with Evidential Reasoning",
        journal = "Nordic Advanced Information Technology Magazine",
        year = 	"1994",
        volume = "8",
        number = "1",
        pages = "18-27",
        month = "July",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="Current project management systems share a common
weakness. Although all provide ample information about the current
status of a project, none provide meaningful information about the
likely outcome of that project. Integrating information about the wide
range of factors that affect project success and using that
information to monitor and take early corrective action form the bases
of the Project Early Warning System (PEWS). The system identifies
problems and developments that might lead to deviations from planned
project outcomes and does so at such an early stage that effective
corrective action can still be taken. PEWS combines a proven project
reporting methodology with the latest artificial intelligence
techniques such as evidential reasoning. Together, they ensure the
successful outcome of large projects.  The system encourages objective
assessment and reporting by project leaders, while providing upper
management with a clear and concise report that pinpoints aspects of
projects in the company's portfolio."}

@article{EARLY-WARNING,
        author = "Per R. Stokke and Thomas A. Boyce and John D. Lowrance and
		 William K. Ralston, Jr.",
        title = "Evidential Reasoning and Project Early Warning Systems",
        journal = "Research and Technology Management",
        year = "1994",
        WINDEXKEY="sri aic paper papers", 
ABSTRACT="Current project management systems share a common
weakness. Although all provide ample information about the current
status of a project, none provide meaningful information about the
likely outcome of that project. Integrating information about the wide
range of factors that affect project success and using that
information to monitor and take early corrective action form the bases
of the Project Early Warning System (PEWS). The system identifies
problems and developments that might lead to deviations from planned
project outcomes and does so at such an early stage that effective
corrective action can still be taken. PEWS combines a proven project
reporting methodology with the latest artificial intelligence
techniques such as evidential reasoning. Together, they ensure the
successful outcome of large projects.  The system encourages objective
assessment and reporting by project leaders, while providing upper
management with a clear and concise report that pinpoints aspects of
projects in the company's portfolio."}

@manual{GISTER-CL-MANUAL,
	author = "John D. Lowrance",
	title = "Evidential Reasoning with Gister-CL: A Manual",
	organization = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	month = "Febuary",
	year = "1994",
        WINDEXKEY="sri aic manual manuals",
ABSTRACT="This document is designed to serve as a self-contained introduction to
evidential reasoning and Gister-CL.  Evidential reasoning is a collection
of techniques for automated reasoning from evidence; Gister-CL is an
application independent implementation of these techniques.  As such,
Gister-CL might serve either as the foundation for application specific
implementations of evidential reasoning or as a basis for research in
uncertain reasoning.  Both evidential reasoning and Gister-CL are
undergoing further development.  Therefore, this document will be
periodically updated."}

@inproceedings{MILCOM92,
	author = "David Gaon and Ruth E. Lang and John D. Lowrance and Philip R. Cohen",
	title = "Application of Artificial Intelligence to the DOD Directory",
	booktitle = "Proceedings of MILCOM '92",
	year = "1992",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="The Department of Defense (DoD) is planning for the
implementation of a DoD Directory capability based on CCITT
Recommendations X.500-X.521, which define the Data Communication
Networks Directory.  The functional and operational requirements that
define the DoD Directory will yield a system with a significant level
of complexity. Problems and barriers which impede progress toward the
envisioned DoD Directory service exist. This paper describes these
problems and the artificial intelligence-based approach developed to
solve and reduce them in order to achieve a usable, capable, secure,
and manageable DoD Directory service."}

@techreport{DISA-FINAL92,
	author = "Ruth E. Lang and John D. Lowrance and Philip R. Cohen 
		and Teresa F. Lunt",
	title = "A Study in the Application of Artificial Intelligence Technology 
		to the DOD Directory",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Final Report",
	number = "SRI Contract 2802",
	month = "March",
	year = "1992",
        WINDEXKEY="sri aic project report reports"}

@techreport{ER-METHODOLOGY-FINAL,
	author = "John D. Lowrance and Thomas M. Strat and Leonard P. Wesley and 
		Thomas D. Garvey and Enrique H. Ruspini and David E. Wilkins",
	title = "The Theory, Implementation, and Practice of Evidential Reasoning",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Final Report",
	number = "SRI Contract 5701",
	month = "June",
	year = "1991",
ABSTRACT="Evidential Reasoning (ER) is a body of techniques for automated
reasoning from evidence that is based upon the mathematics of
Dempster-Shafer belief functions.  The emphasis of this project was
twofold: to broaden and solidify the theoretical basis of ER, and
to facilitate the transfer of the intellectual technology embodied
in ER.  As part of our theoretical effort, we established a sound
semantics for Dempster-Shafer belief functions, deriving the
Dempster-Shafer axioms based upon epistemic logic; we derived all ER
operations from these same Dempster-Shafer axioms; we established ER as
a generalization of both logical and Bayesian probabilistic reasoning;
we identified the conditions under which the computational complexity of
ER belief networks can be reduced; we developed a theoretically
justified means of propagating all information throughout an evidential
analysis, determining the global impact on all probabilistically
dependent random variables; we incorporated decision theoretic concepts
into ER, including sensitivity analysis and decision trees. To
facilitate the transfer of this technology, we developed intuitive
graphical structures for representing and manipulating evidential
knowledge, thereby, substantially reducing the time required to compile
and organize the knowledge for a new application domain, and we
developed a set of canonical ER examples covering a range of application
domains, including underwater vehicle tracking, antiair threat
identification, medical diagnosis, and robot vehicle navigation."}

@incollection{AAAI86-90,
	author = "John D. Lowrance and Thomas D. Garvey and Thomas M. Strat",
	title = "A Framework for Evidential-Reasoning Systems",
	booktitle = "Uncertain Reasoning",
	editor = "Glenn Shafer and Judea Pearl",
	publisher = "Morgan Kaufman Publishers, Inc.",
	address = "San Mateo, CA",
	year = "1990",
	pages = "611-618",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="Evidential reasoning is a body of techniques that supports automated
reasoning from evidence.  It is based upon the Dempster-Shafer theory
of belief functions.  Both the formal basis and a framework for the
implementation of automated reasoning systems based upon these
techniques are presented.  The formal and practical approaches are
divided into four parts (1) specifying a set of distinct propositional
spaces, each of which delimits a set of possible world situations (2)
specifying the interrelationships among these propositional spaces (3)
representing bodies of evidence as belief distributions over these
propositional spaces and (4) establishing paths for the bodies of
evidence to move through these propositional spaces by means of
evidential operations, eventually converging on spaces where the
target questions can be answered."}

@inproceedings{ILC88,
	author = "John D. Lowrance",
	title = "Automating Multisource Data Analysis",
	booktitle = "Proceedings of the International Lithosphere
		Project Research Conference on Advanced Data
		Integration in Mineral and Energy Resource Studies",
	address = "Sotogrande, Spain",
	month = "December",
	year = "1988",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="Over the past eight years, the Artificial Intelligence Center at SRI
International has been developing new technology to address the
problem of automated information management within real-world
contexts.  The result of this work is a body of techniques for
automated reasoning from evidence, called {\em evidential reasoning}.
These techniques emphasize the ability to reason from information that
is uncertain, incomplete, and inaccurate.

To support this line of research we developed {\em Gister}, a
domain-independent evidential-reasoning system.  Gister provides both
a formal basis and an implementation framework for automated {\em
argument construction} based upon evidential-reasoning techniques.  It
supports the construction, modification, and interrogation of lines of
reasoning that argue from multiple bodies of evidence toward
probabilistic conclusions.

We believe that the current Gister system could offer significant aid
to analysts performing a wide range of multisource data analysis
tasks.  Furthermore, Gister provides the necessary basis for
generalized argument construction, the central requirement of
real-world analysis."}

@article{JSPI88,
	author = "John D. Lowrance",
	title = "Automated Argument Construction",
	journal = "Journal of Statistical Planning and Inference",
	volume = "20",
	year = "1988",
	pages = "369-387",
        WINDEXKEY="sri aic paper papers"}

@phdthesis{WESLEY-THESIS,
	author = "Leonard P. Wesley",
	title = "Evidential-Based Control in Knowledge-Based Systems",
	school = "Department of Computer and Information Science,
		  University of Massachusetts, Amherst, MA",
	year = "1988",
        WINDEXKEY="massachusetts umass coins sri aic paper papers"}

@manual{GISTER-MANUAL,
	author = "John D. Lowrance",
	title = "Evidential Reasoning with Gister: A Manual",
	organization = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	month = "April",
	year = "1987",
        WINDEXKEY="sri aic manual manuals"}

@inproceedings{MCC87,
	author = "John D. Lowrance and Thomas D. Garvey",
	title = "Automating Argument Construction for Intelligence Analysis",
	booktitle = "Proceedings of the Military Computing Conference",
	organization = "",
	address =  "Anaheim, CA",
	year = "1987",
	month = "May",
        WINDEXKEY="sri aic paper papers"}
	
@manual{GRASPER-II-MANUAL,
	author = "John D. Lowrance",
	title = "Grasper II Reference Manual",
	organization = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	month = "January",
	year = "1987",
        WINDEXKEY="sri aic manual manuals"}

@techreport{TN416,
	author = "John D. Lowrance",
	title = "Automating Argument Construction",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "416",
	month = "November",
	year = "1986",
        WINDEXKEY="sri aic technical note notes",
ABSTRACT="Over the past five years the Artificial Intelligence Center at SRI has
been developing a new technology to address the problem of automated
information management within real-world contexts.  The result of this
work is a body of techniques for automated reasoning from evidence
that we call {\it evidential reasoning}.  The techniques are based
upon the mathematics of belief functions developed by Dempster and
Shafer and have been successfully applied to a variety of problems
including computer vision, multisensor integration, and intelligence
analysis.

We have developed both a formal basis and a framework for
implementating automated reasoning systems based upon these
techniques.  Both the formal and practical approach can be divided
into four parts: (1) specifying a set of distinct propositional
spaces, (2) specifying the interrelationships among these spaces, (3)
representing bodies of evidence as belief distributions, and (4)
establishing paths for the bodies of evidence to move through these
spaces by means of evidential operations, eventually converging on
spaces where the target questions can be answered.  These steps
specify a means for arguing from multiple bodies of evidence toward a
particular (probabilistic) conclusion.  Argument construction is the
process by which such evidential analyses are constructed and is the
analogue of constructing proof trees in a logical context.

This technology features the ability to reason from uncertain,
incomplete, and occasionally inaccurate information based upon seven
evidential operations: fusion, discounting, translating, projection,
summarization, interpretation, and gisting.  These operation are
theoretically sound but have intuitive appeal as well.

In implementing this formal approach, we have found that evidential
arguments can be represented as graphs.  To support the construction,
modification, and interrogation of evidential arguments, we have
developed Gister.  Gister provides an interactive, menu-driven,
graphical interface that allows these graphical structures to be
easily manipulated.

Our goal is to provide effective automated aids to domain experts for
argument construction.  Gister represents our first attempt at such an
aid."}
	
@inproceedings{WAU86,
	author = "John D. Lowrance",
	title = "Automating Argument Construction",
	booktitle = "Proceedings of the Workshop on Assessing
			Uncertainty (November 13-14, 1986)",
	organization = "Stanford University and the Navy Center for
	  	        International Science and Technology",
	address =  "Department of Statistics, Stanford University,
			Stanford, CA",
	month = "March",
	year = "1987",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="Over the past five years the Artificial Intelligence Center at SRI has
been developing a new technology to address the problem of automated
information management within real-world contexts.  The result of this
work is a body of techniques for automated reasoning from evidence
that we call {\it evidential reasoning}.  The techniques are based
upon the mathematics of belief functions developed by Dempster and
Shafer and have been successfully applied to a variety of problems
including computer vision, multisensor integration, and intelligence
analysis.

We have developed both a formal basis and a framework for
implementating automated reasoning systems based upon these
techniques.  Both the formal and practical approach can be divided
into four parts: (1) specifying a set of distinct propositional
spaces, (2) specifying the interrelationships among these spaces, (3)
representing bodies of evidence as belief distributions, and (4)
establishing paths for the bodies of evidence to move through these
spaces by means of evidential operations, eventually converging on
spaces where the target questions can be answered.  These steps
specify a means for arguing from multiple bodies of evidence toward a
particular (probabilistic) conclusion.  Argument construction is the
process by which such evidential analyses are constructed and is the
analogue of constructing proof trees in a logical context.

This technology features the ability to reason from uncertain,
incomplete, and occasionally inaccurate information based upon seven
evidential operations: fusion, discounting, translating, projection,
summarization, interpretation, and gisting.  These operation are
theoretically sound but have intuitive appeal as well.

In implementing this formal approach, we have found that evidential
arguments can be represented as graphs.  To support the construction,
modification, and interrogation of evidential arguments, we have
developed Gister.  Gister provides an interactive, menu-driven,
graphical interface that allows these graphical structures to be
easily manipulated.

Our goal is to provide effective automated aids to domain experts for
argument construction.  Gister represents our first attempt at such an
aid."}
	
@inproceedings{AAAI86,
	author = "John D. Lowrance and Thomas D. Garvey and Thomas M. Strat",
	title = "A Framework for Evidential-Reasoning Systems",
	booktitle = "Proceedings of the National Conference on Artificial
		Intelligence",
	organization = "American Association for Artificial Intelligence",
	address =  "Menlo Park, CA",
	month = "August",
	year = "1986",
	pages = "896-903",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="Evidential reasoning is a body of techniques that supports automated
reasoning from evidence.  It is based upon the Dempster-Shafer theory
of belief functions.  Both the formal basis and a framework for the
implementation of automated reasoning systems based upon these
techniques are presented.  The formal and practical approaches are
divided into four parts (1) specifying a set of distinct propositional
spaces, each of which delimits a set of possible world situations (2)
specifying the interrelationships among these propositional spaces (3)
representing bodies of evidence as belief distributions over these
propositional spaces and (4) establishing paths for the bodies of
evidence to move through these propositional spaces by means of
evidential operations, eventually converging on spaces where the
target questions can be answered."}

@techreport{NAVINT-FINAL,
	author = "John D. Lowrance and Thomas M. Strat and Thomas D. Garvey",
	title = "Application of Artificial Intelligence Techniques to 
		Naval Intelligence Analysis",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Final Report",
	number = "SRI Contract 6486",
	month = "June",
	year = "1986",
        WINDEXKEY="sri aic project report reports",
ABSTRACT="Toward the goal of providing automated aides for intelligence analysis,
SRI, in cooperation with DARPA and NAVALEX, developed a system called
Navint. Navint is an interactive system that aids naval intelligence
analysts in estimating the location and activity of surface vessels, based
upon a variety of intelligence reports from multiple sources.  It focuses
on ship-by-ship estimates, using these as the basis for a fleet wide
summary.  The analyst interacts with the system through a set of display
windows.  The primary window is a ledger or ``timeline'' that is used to
record and organize the daily intelligence data and products for each ship.
The mode of interaction is modeled after electronic spread-sheet programs.
As the analyst fills in the (electronic) form with the available
information, Navint automatically updates related entries.  A different
view of this same information is provided through ``map'' windows.  These
display the presumed routes of individual fleet elements overlaid on maps
of the appropriate areas.  Another display tracks the flow of intelligence
information through evidential-reasoning operations (e.g., discounting,
fusing, translation, and projection).  When a new report is entered by the
analyst, a new node is created in this ``analysis'' display to represent
the newly acquired information. The application of evidential-reasoning
operations spawns new nodes related to preexisting ones.  When new nodes
are created, labeled links are created between these nodes to trace the
heritage of each resulting body of information.  Thus, explanations of
selected conclusions can be generated by tracing back along these links to
find the supporting reports and to determine their relative roles."}
	
@techreport{TN324,
	author = "Leonard P. Wesley and John D. Lowrance and Thomas D. Garvey",
	title = "Reasoning about Control: An Evidential Approach",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "324",
	month = "July",
	year = "1984",
        WINDEXKEY="sri aic technical note notes",
ABSTRACT="Expert systems that operate in complex domains are
continually confronted with the problem of deciding what to do
next. Being able to reach a decision requires, in part, having the
capacity to ``reason'' about a set of alternative actions. It has been
argued that expert systems must reason from evidential
information---i.e., uncertain, incomplete, and occasionally inaccurate
information [Lowrance 1982]. As a consequence, a model for reasoning
about control must be capable of performing several tasks: to combine
the evidential information that is generically distinct and from
disparate sources; to overcome minor inaccuracies in the evidential
information that is need to reach a decision; to reason about what
additional evidential information is required; to explain the actions
taken (based on such information) by the system. These are a few of
the formidable control problems that remain largely unsolved [Barnett
1982]. If expert systems are to improve their performance
significantly, they must utilize increasingly sophisticated and
general models fro dealing with the evidential information required for
reasoning about their behavior. Tot his end we present an alternative
evidentially-based approach to reasoning about control that has
several advantages over existing techniques. It enables us to reason
from limited and imperfect information; to partition bodies of meta-
and domain-knowledge into modular components; and to order potential
actions flexibly by allowing any number of constraints (i.e., control
strategies) to be imposed over a set of alternative
actions. Furthermore, because it can be used for reasoning about the
expenditure of additional resources to obtain the evidential
information needed as a basis for choosing among alternatives, this
approach can be employed recursively."}

@techreport{TN318,
	author = "John D. Lowrance and Thomas D. Garvey",
	title = "An AI Approach to the Integration of Information",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "318",
	month = "April",
	year = "1984",
        WINDEXKEY="sri aic technical note notes"}

@techreport{TN307,
	author = "John D. Lowrance and Thomas D. Garvey",
	title = "Evidential Reasoning: An Implementation for Multisensor
		Integration",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "307",
	month = "December",
	year = "1983",
        WINDEXKEY="sri aic technical note notes",
ABSTRACT="One common feature of most knowledge-based expert systems is
that they must draw conclusions on the basis of evidential
information. Yet there is very little agreement of how this should be
done. Here we present our view of this problem and its solution for
multisensor integration. We begin by characterizing evidence as
information that is uncertain, incomplete, and sometimes
inaccurate. On the basis of this characterization, we conclude that
evidential reasoning requires both a method for pooling multiple
bodies of evidence to arrive at a consensus and some means of drawing
the appropriate conclusions from that consensus. We contrast our
approach, which is based on a relatively new mathematical theory of
evidence, with those that have their basis in Bayesian probability
models. We believe that our method has significant advantages in its
ability to represent and reason from bounded ignorance. We describe an
implementation of these techniques by means of two kinds of memory:
long- and short-term. This implementation provides for automated
reasoning from evidential information at multiple levels of
abstraction over time and space."}
	
@techreport{WOC,
	author = "John D. Lowrance and Thomas D. Garvey",
	title = "Evidential Reasoning: An Approach to the Simulation
		of a Weapons Operation Center",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	month = "September",
	year = "1983",
        WINDEXKEY="sri aic project report reports",
ABSTRACT="This one year study defined the role of evidential reasoning
for simulating activities in a Soviet weapons operation center, and
resulted in a specification for the development of a WOC simulation,
based on AI technology."}
	
@inproceedings{IEEE82,
	author = "John D. Lowrance and Thomas D. Garvey",
	title = "Evidential Reasoning: A Developing Concept",
	booktitle = "Proceedings of the Internation Conference on 
		Cybernetics and Society",
	organization = "Institute of Electrical and Electronical 
		Engineers",
	month = "October",
	year = "1982",
	pages = "6-9",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="One common feature of most knowledge-based expert systems is
that they must draw conclusions on the basis of evidential
information. Yet there is very little agreement of how this should be
done. Here we present our current understanding of this problem and
some partial solutions. We begin by characterizing evidence as
information that is uncertain, incomplete, and sometimes
inaccurate. Based on this characterization, we conclude that
evidential reasoning requires both a method for pooling multiple
bodies of evidence to arrive at a consensus opinion and some means of
drawing the appropriate conclusions from that opinion. We contrast our
approach, based on a relatively new mathematical theory of evidence,
with those approaches bases on Bayesian probability models. We believe
that our approach has some significant advantages, particularly its
ability to represent and reason from bounded ignorance."}
	

@phdthesis{LOWRANCE-THESIS,
	author = "John D. Lowrance",
	title = "Dependency-Graph Models of Evidential Support",
	school = "Department of Computer and Information Science,
		  University of Massachusetts, Amherst, MA",
	month = "September",
	year = "1982",
        WINDEXKEY="maschusetts umass coins sri aic paper papers",
ABSTRACT="Dependency-graph models of evidential support are formal systems
capable of pooling and extending evidential information, while maintaining
internal consistency. In this formalism, the likelihood of a proposition is
represented as a subinterval of the until interval.  The lower bound
represents the degree of ``support'' provided a proposition by a body of
evidence, and the upper bound represents the extent to which it remains
``plausible.''  The smaller this interval, the more precisely the probability
of that proposition is known.
	
Evidential information, extracted from the environment by
(indivisible) sources of knowledge, enters these models in the form of
probability "mass" distributions, defined over sets of propositions common
to both them and the model.  Theses mass distributions are combined through
Dempster's rule of combination [Dempster 1967].  The result is a new mass
distribution representing their consensus.  Next, this pooled information
is extended from those propositions it directly bears upon, to those it
indirectly bears upon, and converted to the interval representation.  Prior
probabilities, frequently difficult or impossible to collect in artificial
intelligence domains, but required by most other systems of inexact
reasoning, are not needed. This form of evidential reasoning, based on
[Shafer 1976], is more general than either a Boolean or Bayesian approach,
providing for Boolean and Bayesian inferencing when the appropriate
information is available.
	
Dependency graphs are formal representations of dependency
relations. A dependency graph consists of a set of propositions (nodes), a
covering assignment of confidences (node values), and a coordinated set of
dependency relationships (connecting arcs) constraining the assignment of
confidences.  Confidences can be fully specified (a single value),
partially specified (several values), or unspecified (all values).
Similarly, a dependency graph can describe any degree of
dependence/independence among its propositions.  The freedom to express
partial information makes dependency graphs suitable for modeling the
degrees of belief one should accord a group of related propositions based
on evidential information, a suitable host for Shafer's theory."}
	
@techreport{GRASPER-DESIGN,
	author = "John D. Lowrance and Daniel D. Corkill",
	title = "The Design of Grasper 1.0: A Programming Language
		Extension for Graph Processing",
	institution = "Department of Computer and Information Science,
		  University of Massachusetts",
	address = "Amherst, MA",
	type = "COINS Technical Report",
	number = "79-6",
	month = "February",
	year = "1979",
        WINDEXKEY="massachusetts umass coins paper papers",
ABSTRACT="GRASPER 1.0 is a programming language extension. Once
appended to a host language, GRASPER 1.0 introduces graphs, diagrams
consisting of points connected by lines or arrows, as a primitive data
type. 

The primary feature of GRASPER 1.0's design is that the language, its
documentation, and its implementation all share a common
organizational structure that groups GRASPER 1.0 primitives according
to their scope of application and the underlying concepts from which
they are formed. Although this report is of a descriptive nature, a
similar approach might well be prescribed for other applications. 

GRASPER 1.0 is based on a small number of underlying concepts. GRASPER
1.0 primitives are constructed from these concepts according to a
small set of rules. The name of each GRASPER 1.0 primitive
systematically reflects its underlying concepts. This generative
nature of the language organizes a large set of primitives in a
cognitively efficient way. This makes GRASPER 1.0 easier to learn and
retain; proves an indexing system for GRASPER 1.0 documentation; and
serves as an outline for well-structured implementations.  

GRASPER 1.0 has been implemented with LISP 1.5 as the host
language. This implementation supports a software-level virtual memory
management system for graph storage. Spaces, user defined subgraphs,
are used by the virtual memory manager to group logically related
information  on the same pages, helping to reduce paging. Multiple
storage schemes allow users to optimize the way graphs are stored
based on their particular applications."}

@techreport{GRASPER-MANUAL,
	author = "John D. Lowrance",
	title = "Grasper 1.0 Reference Manual",
	institution = "Department of Computer and Information Science,
		  University of Massachusetts",
	address = "Amherst, MA",
	type = "COINS Technical Report",
	number = "78-20",
	month = "December",
	year = "1978",
        WINDEXKEY="massachusetts umass coins manual manuals"}

@techreport{MODEL-BUILDING,
	author = "Thomas D. Williams and John D. Lowrance",
	title = "Model-Building in the {VISIONS} High Level System",
	institution = "Department of Computer and Information Science,
		  University of Massachusetts",
	address = "Amherst, MA",
	type = "COINS Technical Report",
	number = "77-1",
	month = "January",
	year = "1977",
        WINDEXKEY="massachusetts umass coins technical note notes",
ABSTRACT="SYMBOLS, a general purpose model-building tool, has been
designed and implemented in order to develop and test the semantic
interpretation portion of the VISIONS system. Following the criterion
of modularity, the data, processes and search concepts of
model-building have been decomposed into units which are natural for
the understanding of digitized outdoor scenes. Multiple-leveled
structures are described for the representation of the model and
processes. The strategy surrounding the control of processes in a huge
search space is integrated into the system via a hierarchy of modular
substrategies of control."}

@article{IJMMS77,
	author = "John D. Lowrance and Daniel P. Friedman",
	title = "Hendrix's Model for Simultaneous Actions and Continuous
		 Processes: An Introduction and Implementation",
	journal = "International Journal of Man-Machine Studies",
	publisher = "",
	editor = "",
	volume = "9",
	number = "",
	month = "",
	year = "1977",
	pages = "537-581",
        WINDEXKEY="indiana iu paper papers",
        ABSTRACT = "This paper presents a self-contained introduction and
                 implementation description to a simulation system for
		 modeling simultaneous action and continuous processes
		 (Hendrix, 1973).  The essence of the system is described
		 by a portion of its abstract: ``A new methodology for the
		 construction of world models is presented.  The central
		 feature of this methodology is a mechanism which makes
		 possible the modeling of (1) simultaneous, interactive
		 processes, (2) processes characterized by a continuum of
		 gradual change, (3) involuntarily activated processes
		 (such as the growing of grass) and (4) times as a
		 continuous phenomena.'' and by a recent review, Gains
		 (1975): ``This is a fascination paper that will be of
		 interest outside the ``artificial intelligence'' (AI)
		 context in which it is written, from those concerned with
		 simulating and controlling multi-element systems to those
		 interested in operational definitions of concepts such as
		 causality.'' Three robot world models are incrementally
		 developed, each introducing a new modeling concept. World
		 models, including a robot world (with sample output),
		 electrical world, and a Turing world are also presented.
		 The interactive operating environment represented permits
		 the user to inspect and alter the run-time structure. A
		 detailed account of the implementation is presented."
		  }

%-----------------------------------------------------------------------------
% Other first authors in AIC
%-----------------------------------------------------------------------------

@incollection{FUSION95,
       	author = "Thomas D. Garvey and John D. Lowrance and 
		Martin A. Fischler",
       	title = "An Inference Technique for Integrating Knowledge from
		Disparate Sources",
       	booktitle = "Multisensor Integration and Fusion for Intelligenct
		 Machines and Systems",
       	editor = "Ren C. Luo and Michael G. Kay",
       	publisher = "Ablex Publishing Corporation.",
       	address = "Norwood, New Jersey",
       	year = "1995",
       	pages = "309-325",
       	WINDEXKEY="sri aic paper papers",
ABSTRACT="This paper introduces a formal method for integrating
knowledge derived from a variety of sources for use in ``perceptual
reasoning.'' The formalism is based on the ``evidential propositional
calculus.'' a derivative of Shafer's mathematical theory of evidence
[Shafer 1976]. It is more general than either a Boolean or Bayesian
approach, providing for Boolean and Bayesian inferencing when the
appropriate information is available. In this formalism, the likelihood
of a proposition A is represented as a subinterval, [s(A),p(A)], of
the unit interval [0,1]. The evidential support for the proposition A
is represented by s(A), while p(A) represents its degree of
plausibility; p(A) can also be interpreted as the degree to which one
fails to doubt A, p(A) being equal to one minus the evidential support
for ~A. This paper describes how evidential information, furnished by
a knowledge source in the form of a probability ``mass'' distribution,
can be converted to this interval representation; how, through a set
of inference rules for computing intervals of dependent propositions,
this information can be extrapolated from those propositions it
directly bears upon, to those it indirectly bears upon; and how
multiple bodies of evidential information can be pooled. A sample
application of this approach, modeling the operation of a collection
of sensors (a particular type of knowledge source), illustrates these
techniques."}

@article{IJAR89,
	author = "Thomas M. Strat and John D. Lowrance",
	title = "Explaining Evidential Analyses",
	journal = "International Journal of Approximate Reasoning",
	publisher = "North-Holland",
	editor = "James C. Bezdek",
	volume = "3",
	number = "4",
	month = "July",
	year = "1989",
	pages = "299-353",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="One of the most highly touted virtues of knowledge-based
expert systems is their ability to construct explanations in for their
lines of reasoning. However, there is a basic difficulty in generating
explanations in espert systems that reason under uncertainty using
numeric measures. In particular, systems based upon evidential
reasoning using the theory of belief functions have lacked all but the
most rudimentary facilities for explaining their conclusions. In this
paper we review the process whereby other expert system technologies
produce explanations, and present a methodology for augmenting an
evidential-reasoning system with a versatile explanation
facility. The method, which is based on sensitivity analysis, has been
implemented, and several examples of its use are described."}

@techreport{TN430,
	author = "Thomas M. Strat and John D. Lowrance",
	title = "Explaining Evidential Analyses",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "430",
	month = "January",
	year = "1988",
        WINDEXKEY="sri aic technical note notes",
ABSTRACT="One of the most highly touted virtues of knowledge-based
expert systems is their ability to construct explanations in for their
lines of reasoning. However, there is a basic difficulty in generating
explanations in espert systems that reason under uncertainty using
numeric measures. In particular, systems based upon evidential
reasoning using the theory of belief functions have lacked all but the
most rudimentary facilities for explaining their conclusions. In this
paper we review the process whereby other expert system technologies
produce explanations, and present a methodology for augmenting an
evidential-reasoning system with a versatile explanation
facility. The method, which is based on sensitivity analysis, has been
implemented, and several examples of its use are described."}

@incollection{IJCAI81-85,
	author = "Thomas D. Garvey and John D. Lowrance and 
		Martin A. Fischler",
	title = "An Inference Technique for Integrating Knowledge from
		Disparate Sources",
	booktitle = "Readings in Knowledge Representation",
	editor = "Ronald J. Brachman and Hector J. Levesque",
	publisher = "Morgan Kaufman Publishers, Inc.",
	Address = "San Mateo, CA",
	year = "1985",
	pages = "457-464",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="This paper introduces a formal method for integrating
knowledge derived from a variety of sources for use in ``perceptual
reasoning.'' The formalism is based on the ``evidential propositional
calculus.'' a derivative of Shafer's mathematical theory of evidence
[Shafer 1976]. It is more general than either a Boolean or Bayesian
approach, providing for Boolean and Bayesian inferencing when the
appropriate information is available. In this formalism, the likelihood
of a proposition A is represented as a subinterval, [s(A),p(A)], of
the unit interval [0,1]. The evidential support for the proposition A
is represented by s(A), while p(A) represents its degree of
plausibility; p(A) can also be interpreted as the degree to which one
fails to doubt A, p(A) being equal to one minus the evidential support
for ~A. This paper describes how evidential information, furnished by
a knowledge source in the form of a probability ``mass'' distribution,
can be converted to this interval representation; how, through a set
of inference rules for computing intervals of dependent propositions,
this information can be extrapolated from those propositions it
directly bears upon, to those it indirectly bears upon; and how
multiple bodies of evidential information can be pooled. A sample
application of this approach, modeling the operation of a collection
of sensors (a particular type of knowledge source), illustrates these
techniques."}

@techreport{NAVAL-PLANNING-FINAL,
	author = "Thomas D. Garvey and John D. Lowrance",
	title = "Issues and Approaches to Planning Under Uncertainty",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Final Report",
	number = "SRI Contract 2404",
	month = "November",
	year = "1984",
        WINDEXKEY="sri aic project report reports"}

@article{JED84,
	author = "Thomas D. Garvey and John D. Lowrance",
	title = "An AI Approach to Information Fusion",
	journal = "Journal of Electronic Defense",
	pages = "31-41",
	month = "July",
	year = "1984",
        WINDEXKEY="sri aic paper papers"}

@techreport{EW-FINAL,
	author = "Thomas D. Garvey and John D. Lowrance",
	title = "Machine Intelligence for Electronic Warfare Applications",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Final Report",
	number = "SRI Contract 1655",
	month = "November",
	year = "1983",
        WINDEXKEY="sri aic project report reports",
ABSTRACT="The primary objective of these two-year efforts was to extend the available
AI-based techniques for drawing conclusions from multisource information.
The specific problem addressed was that of integrating sensor data with
prior knowledge in order to update and maintain a current threat order of
battle for a penetrating aircraft.  The goal was to provide an automated
capability to replace the judgemental capabilities of a human operator in
interpreting the returns from his on-board sensors to best assess the
antiair threats arrayed against him. The key problems were to find a way of
representing and reasoning about the wide variety of knowledge sources a
human operator would normally invoke in performing this task.  A secondary
objective was to demonstrate the effectiveness of these techniques by
simulating the interaction of sensors such as radar warning systems and an
optical augmentation device. The results of this simulation demonstrated
that the optical augmentation device could be automatically cued by the
radar warning receiver and resulted in a decrease in the overall false
alarm rate and an increase in the number of successful detections. The work
also resulted in the development and demonstrated the utility of a new
collection of inference techniques labeled evidential reasoning. These
techniques represented a significant advance in the state of the art of
methods for reasoning with uncertain knowledge."}

@techreport{EW-INTERIM,
	author = "Thomas D. Garvey and John D. Lowrance",
	title = "Machine-Intelligence-Based Multisensor ESM System",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Interim Report",
	number = "SRI Contract 1655",
	month = "December",
	year = "1981",
        WINDEXKEY="sri aic project report reports"}

@inproceedings{IJCAI81,
	author = "Thomas D. Garvey and John D. Lowrance and 
		Martin A. Fischler",
	title = "An Inference Technique for Integrating Knowledge from
		Disparate Sources",
	booktitle = "Proceedings of the Seventh Joint Conference on Artificial
		Intelligence",
	organization = "American Association for Artificial Intelligence",
	address =  "Menlo Park, CA",
	month = "August",
	year = "1981",
	pages = "319-325",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="This paper introduces a formal method for integrating
knowledge derived from a variety of sources for use in ``perceptual
reasoning.'' The formalism is based on the ``evidential propositional
calculus.'' a derivative of Shafer's mathematical theory of evidence
[Shafer 1976]. It is more general than either a Boolean or Bayesian
approach, providing for Boolean and Bayesian inferencing when the
appropriate information is available. In this formalism, the likelihood
of a proposition A is represented as a subinterval, [s(A),p(A)], of
the unit interval [0,1]. The evidential support for the proposition A
is represented by s(A), while p(A) represents its degree of
plausibility; p(A) can also be interpreted as the degree to which one
fails to doubt A, p(A) being equal to one minus the evidential support
for ~A. This paper describes how evidential information, furnished by
a knowledge source in the form of a probability ``mass'' distribution,
can be converted to this interval representation; how, through a set
of inference rules for computing intervals of dependent propositions,
this information can be extrapolated from those propositions it
directly bears upon, to those it indirectly bears upon; and how
multiple bodies of evidential information can be pooled. A sample
application of this approach, modeling the operation of a collection
of sensors (a particular type of knowledge source), illustrates these
techniques."}

@techreport{ESM-FINAL,
	author = "Thomas D. Garvey and Martin A. Fischler",
	title = "Machine Intelligence Based Multi-Sensor ESM System",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Final Report",
	number = "SRI Contract 6804",
	month = "October",
	year = "1979",
        WINDEXKEY="sri aic project report reports"}

@techreport{ESM-INTERIM,
	author = "T. D. Garvey and M. A. Fischler and R. A. Marth and
		J. W. Sinko",
	title = "Machine Intelligence Based Multi-Sensor ESM System",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Interim Report",
	number = "SRI Contract 6804",
	month = "July",
	year = "1978",
        WINDEXKEY="sri aic project report reports"}

@article{IJAR92,
	author = "Enrique H. Ruspini and John D. Lowrance and Thomas M. Strat",
	title = "Understanding Evidential Reasoning",
	journal = "International Journal of Approximate Reasoning",
	publisher = "North-Holland",
	editor = "James C. Bezdek",
	volume = "6",
	number = "3",
	month = "May",
	year = "1992",
	pages = "401-424",
        WINDEXKEY="sri aic paper papers",
ABSTRACT="We address recent criticisms of evidential reasoning, an
approach to the analysis of imprecise and uncertain information that
is based on the Dempster-Shafer calculus of evidence.

We show that evidential reasoning can be interpreted in terms of
classical probability theory and that the Dempster-Shafer calculus of
evidence may be considered to be a form of generalized probabilistic
reasoning based on the representation of probabilistic ignorance by
intervals of possible values. In particular, we emphasize that it is
not necessary to resort to nonprobabilistic or subjectivist
explanations to justify the validity of the approach.

We answer conceptual criticisms of evidential reasoning primarily on
the basis of the criticism's confusion between the current state of
development of the theory---mainly theoretical limitations in the
treatment of conditional information---and it potential usefulness in
treating a wide variety of uncertainty analysis problems. Similarly, we
indicate that the supposed lack of decision-support schemes  of
generalized probability approaches is not a theoretical handicap but
rather an indication of basic informational shortcoming that is a
desirable asset of any formal approximate reasoning approach. We also
point to potential shortcomings of the underlying representation
scheme to treat general probabilistic reasoning problems.

We also consider methodological criticisms of the approach, focusing
primarily on the alleged counterintuitive nature of Dempster's
combination formula, showing that such results are the result of its
misapplication. We also address issues of complexity and validity of
scope of the calculus of evidence."}


@techreport{TN501,
	author = "Enrique H. Ruspini and John D. Lowrance and Thomas M. Strat",
	title = "Understanding Evidential Reasoning",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "501",
	month = "December",
	year = "1990",
        WINDEXKEY="sri aic technical note notes",
ABSTRACT="We address recent criticisms of evidential reasoning, an
approach to the analysis of imprecise and uncertain information that
is based on the Dempster-Shafer calculus of evidence.

We show that evidential reasoning can be interpreted in terms of
classical probability theory and that the Dempster-Shafer calculus of
evidence may be considered to be a form of generalized probabilistic
reasoning based on the representation of probabilistic ignorance by
intervals of possible values. In particular, we emphasize that it is
not necessary to resort to nonprobabilistic or subjectivist
explanations to justify the validity of the approach.

We answer conceptual criticisms of evidential reasoning primarily on
the basis of the criticism's confusion between the current state of
development of the theory---mainly theoretical limitations in the
treatment of conditional information---and it potential usefulness in
treating a wide variety of uncertainty analysis problems. Similarly, we
indicate that the supposed lack of decision-support schemes  of
generalized probability approaches is not a theoretical handicap but,
rather, an indication of basic informational shortcoming that is a
desirable asset of any formal approximate reasoning approach. We also
point to potential shortcomings of the underlying representation
scheme to treat general probabilistic reasoning problems.

We also consider methodological criticisms of the approach, focusing
primarily on the alleged counterintuitive nature of Dempster's
combination formula, showing that such results are the result of its
misapplication. We also address issues of complexity and validity of
scope of the calculus of evidence."}


%-----------------------------------------------------------------------------
% Other authors in AIC
%-----------------------------------------------------------------------------


@article{IJAR90,
	author = "Thomas M. Strat",
	title = "Decision Analysis Using Belief Functions",
	journal = "International Journal of Approximate Reasoning",
	publisher = "North-Holland",
	editor = "James C. Bezdek",
	volume = "4",
	number = "5",
	month = "September",
	year = "1990",
	pages = "391-418",
        WINDEXKEY="sri aic paper papers"}

@techreport{TN492,
	author = "Thomas M. Strat",
	title = "Decision Analysis Using Belief Functions",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	number = "472",
	month = "September",
	year = "1989",
        WINDEXKEY="sri aic technical note notes"}

@inproceedings{S-IJCAI87,
	author = "Thomas M. Strat",
	title = "The Generation of Explanations within Evidential
		Reasoning Systems",
	booktitle = "Proceedings of the Tenth Joint Conference on Artificial
		Intelligence",
	organization = "American Association for Artificial Intelligence",
	address =  "Menlo Park, CA",
	month = "August",
	year = "1987",
	pages = "1097-1104",
        WINDEXKEY="sri aic paper papers"}

@inproceedings{R-IJCAI87,
	author = "Enrique H. Ruspini",
	title = "Epistemic Logics, Probability, and the Calculus of Evidence",
	booktitle = "Proceedings of the Tenth Joint Conference on Artificial
		Intelligence",
	organization = "American Association for Artificial Intelligence",
	address =  "Menlo Park, CA",
	month = "August",
	year = "1987",
	pages = "924-931",
        WINDEXKEY="sri aic paper papers"}

@techreport{TN405,
	author = "Thomas D. Garvey",
	title = "Evidential Reasoning for Geographic Evaluation for
		Helicopter Route Planning",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Technical Report",
	Number = "405",
	month = "December",
	year = "1986",
        WINDEXKEY="sri aic technical note notes"}

@techreport{HELICOPTER-INTERIM1,
	author = "Thomas D. Garvey and Oscar Firschein and Enrique H.
		Ruspini and Leonard P. Wesley",
	title = "Helicopter Mission Planning and Enroute Navigation Research",
	institution = "Artificial Intelligence Center, SRI International",
	address = "333 Ravenswood Avenue, Menlo Park, CA",
	type = "Interim Report",
	number = "SRI Contract 7845",
	month = "June",
	year = "1986",
        WINDEXKEY="sri aic project report reports"}

@inproceedings{AAAI84,
	author = "Thomas M. Strat",
	title = "Continuous Belief Functions for Evidential Reasoning",
	booktitle = "Proceedings of the National Conference on Artificial
		Intelligence",
	organization = "American Association for Artificial Intelligence",
	address =  "Menlo Park, CA",
	month = "August",
	year = "1984",
	pages = "308-313",
        WINDEXKEY="sri aic paper papers"}


@INCOLLECTION{Kameyama95:Indefeasible,
AUTHOR="Kameyama, Megumi",
TITLE="Indefeasible Semantics and Defeasible Pragmatics",
BOOKTITLE="Quantifiers, Deduction, and Context",
EDITOR="Kanazawa M. and C. Pi\~{n}on and H. de Swart",
YEAR=1995,
PUBLISHER={CSLI, Stanford, CA},
ABSTRACT="An account of utterance interpretation in discourse needs to face the
issue of how the discourse context controls the space of interacting
preferences. 
In the framework of a general discourse processing model that
integrates both the grammar and pragmatics subsystems, I propose
a fine structure of the preferential interpretation in pragmatics in
terms of defeasible rule interactions. The pronoun interpretation
preferences that serve as the empirical ground draw from the survey
data specifically obtained for the present purpose.",
NOTE="a shorter and revised version of the 1994 Tech Note with the
same title",
URL="ftp://ftp.ai.sri.com/pub/papers/kameyama95.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{K&A94:Coping,
AUTHOR="Kameyama, Megumi and Isao Arima",
TITLE="Coping with Aboutness Complexity in
Information Extraction from Spoken Dialogues",
ADDRESS="Yokohama, Japan",
BOOKTITLE="the Proceedings of
the International Conference on Spoken Language Processing (ICSLP-94)",
MONTH=sept,
YEAR=1994,
ABSTRACT="We report on the strategies in automatic summarization of spontaneous
spoken dialogues. Our dialogue summarization system, MIMI, recognizes
key linguisitc patterns and merges information to construct a summary
of conference room scheduling dialogues. Dialogues about single
reservations can be accurately summarized with a simple merging
scheme, but we need several extensions and changes to cope with the
{\it aboutness complexity} in unrestricted dialogues --- knowing
exactly {\it how many} reservations are being discussed and {\it
which} reservation values must be updated by subsequent utterances. A
side effect of these extensions is a new problem of overrecognition
caused by spoken language disfluencies.",
URL="ftp://ftp.ai.sri.com/pub/papers/icslp94.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{K&A93:Minimalist,
AUTHOR="Kameyama, Megumi and Isao Arima",
TITLE="A Minimalist Approach to Information
Extraction from Spoken Dialogues",
ADDRESS="Tokyo, Japan",
ORGANIZATION="Waseda University",
BOOKTITLE="the Proceedings of
the International Symposium on Spoken Dialogue (ISSD-93)",
MONTH=nov,
YEAR=1993,
ABSTRACT="We describe our minimalistic approach to extracting key information from
task-oriented spoken dialogues. We motivate our approach with
linguistic features in our dialogue data in the conference room
scheduling domain. Our dialogue summarization system, MIMI, satisfies the
key architectural requirements of relevance recognition, robustness,
information merging, and information overriding. It applies minimal
linguistic knowledge and information-updating strategies to achieve a
reliable accuracy.",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Appelt+al93:JV-FASTUS,
AUTHOR="Appelt, Douglas and Jerry Hobbs and John Bear and David Israel and Megumi Kameyama
and Mabry Tyson",
TITLE="SRI: Description of the JV-FASTUS System Used for MUC-5",
ADDRESS="Tokyo, Japan",
ORGANIZATION="ARPA",
BOOKTITLE="the Proceedings of the Fifth Message Understanding Conference (MUC-5)",
EDITOR="Sundheim, Beth",
MONTH=aug,
YEAR=1993,
NOTE="Contains Japanese characters",
URL="ftp://ftp.ai.sri.com/pub/papers/muc5.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{KPP93:TCentering,
AUTHOR="Kameyama, Megumi and Rebecca, Passonneau and Massimo Poesio",
TITLE="Temporal Centering",
ADDRESS="Columbus, Ohio",
ORGANIZATION="ACL",
BOOKTITLE="the Proceedings of
the 31st Annual Meeting of the
Association of Computational Linguistics",
MONTH=june,
YEAR=1993,
ABSTRACT="We present a semantic and pragmatic account of the anaphoric
properties of past and perfect that improves on previous work by
integrating discourse structure, aspectual type, surface structure and
commonsense knowledge.  A novel aspect of our account is that we
distinguish between two kinds of temporal intervals in the
interpretation of temporal operators --- discourse reference intervals
and event intervals.  This distinction makes it possible to develop an
analogy between centering and temporal centering, which operates on
discourse reference intervals. Our {\it temporal property-sharing
principle} is a defeasible inference rule on the logical form.  Along
with lexical and causal reasoning, it plays a role in incrementally
resolving underspecified aspects of the event structure representation
of an utterance against the current context.",
URL="ftp://ftp.ai.sri.com/pub/papers/kameyamaACL93.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@TECHREPORT{Kameyama92b:LingInfo,
AUTHOR="Kameyama, Megumi",
TITLE="The Linguistic Information in Dynamic Discourse",
TYPE="Technical Report",
INSTITUTION="CSLI",
ADDRESS="Stanford, CA",
MONTH=nov,
YEAR=1992,
NUMBER=174,
ABSTRACT="As discourse unfolds, the participants keep
track of a shared information state that is dynamically updated in a
chain of transitions.  This shared information state is a bundle of
both explicitly asserted and implicitly assumed pieces of information,
and the role of a linguistic utterance is to make explicit only what
does not follow from the currently shared information.  Discourse
understanding thus combines both linguistic interpretation and
commonsense reasoning. It is essential that a theory of discourse
account for their interactions. These points are illustrated with an
analysis of a piece of discourse --- the AI puzzle of {\it
missionaries and cannibals} --- in both English and Japanese.  The
approach is an information-based dynamic discourse analysis where the
shared information states consist of situation types and information
pieces. The analysis shows that the `linguistic wrapping' of the
puzzle in either language admits of systematic explanation though it
affects neither the core problem nor how it is solved.",
URL="ftp://ftp.ai.sri.com/pub/papers/kameyama92.ps.gz",
WINDEXKEY="sri aic technical note notes"
}

@ARTICLE{Kameyama92:DiscUnd,
AUTHOR="Kameyama, Megumi",
TITLE="Discourse Understanding and World Knowledge",
JOURNAL="Journal of Information Processing",
ADDRESS="Tokyo",
YEAR=1992,
VOLUME=15,
NUMBER=3,
PAGES=377--385,
ABSTRACT="Discourse processing is a sequence of dynamic operations 
on transient 
information states.  As discourse unfolds, the participants keep track 
of a shared information state that is dynamically updated in a chain 
of transitions.  This shared information state is a bundle of both 
explicitly asserted and implicitly assumed pieces of information.  The 
role of a linguistic utterance is to make explicit only what does not 
follow from the currently shared information.  Discourse understanding 
thus combines both linguistic interpretation and commonsense 
reasoning. It is essential that a theory of discourse account for 
their interactions. 

These points are illustrated with an analysis of a piece of discourse 
--- the AI puzzle of `Missionaries and Cannibals'.  The approach is an 
information-based dynamic discourse analysis with the following 
features: (1) an information state consists of salient situation types 
and information pieces, (2) the use of each referring expression type 
has a set of dynamic constraints in terms of pre- and post-conditions 
on the information state. The approach exposes the systematic 
dynamicity in linguistic processing that has tended to be either taken 
for granted without explanation or neglected in the studies of 
commonsense reasoning in AI. The same approach is used to analyze 
equivalent texts in English and Japanese demonstrating its 
cross-linguistic applicability. 
",
NOTE="Reprints available from the author",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{KOP91:Mismatch,
AUTHOR="Kameyama, Megumi and Ryo, Ochitani and Stanley Peters",
TITLE="Resolving Translation Mismatches with Information Flow",
ADDRESS="Berkeley,
California",
ORGANIZATION="ACL",
BOOKTITLE="the Proceedings of
the 29th Annual Meeting of the
Association of Computational Linguistics",
MONTH=june,
YEAR=1991,
PAGES=193--200,
ABSTRACT="Languages differ in the concepts and real-world entities for which
they have words and grammatical constructs. Therefore translation
must sometimes be a matter of approximating the meaning of a source
language text rather than finding an exact counterpart in the target
language. We propose a translation framework based on Situation
Theory. The basic 
ingredients are an information lattice, a representation scheme 
for utterances embedded in contexts, and a mismatch resolution 
scheme defined in terms of information flow. 
We motivate our approach with examples of translation
between English and Japanese.",
NOTE="Contains Japanese characters",
URL="ftp://ftp.ai.sri.com/pub/papers/kameyamaACL91.ps.gz",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Kameyama88:Atom,
AUTHOR="Kameyama, Megumi",
TITLE="Atomization in Grammar Sharing",
ADDRESS="Buffalo, NY",
ORGANIZATION="ACL",
BOOKTITLE="the Proceedings of
the 26th Annual Meeting of the
Association of Computational Linguistics",
MONTH=june,
YEAR=1988,
PAGES=194--203,
ABSTRACT="We describe a prototype Shared Grammar for the syntax of
simple nominal expressions in Arabic, English, French, German, and
Japanese implemented at MCC. In this grammar, a complex inheritance
lattice of shared grammatical templates provides parts that each
language can put together to form language--specific grammatical
templates. We conclude that grammar sharing is not only possible but
also desirable. If forces us to reveal cross--linguistically invariant
grammatical primitives that may otherwise remain conflated with other
primitives if we deal only with a single language or language type. We
call this the process of Grammatical Atomization. The specific
implementation reported here uses categorial unification grammar. The
topics include the mono--level nominal category N, the functional
distinction between ARGUMENT and NON--ARGUMENT of nominals,
grammatical agreement, and word order types.",
WINDEXKEY="sri aic paper papers"
}

@INCOLLECTION{Kameyama88b:Zpro,
AUTHOR="Kameyama, Megumi",
TITLE="Japanese Zero Pronominal Binding: Where Syntax and Discourse Meet",
BOOKTITLE="Papers from the Second International Workshop on
Japanese Syntax",
EDITOR="Poser, William",
PUBLISHER={CSLI, Stanford, CA},
YEAR=1988,
PAGES=47--74,
ABSTRACT="",
NOTE="From a workshop held in 1986",
WINDEXKEY="sri aic paper papers"
}

@INPROCEEDINGS{Kameyama86:Property,
AUTHOR="Kameyama, Megumi",
TITLE="A Property-sharing Constraint in Centering",
ADDRESS="New York, NY",
ORGANIZATION="ACL",
BOOKTITLE="the Proceedings of
the 24th Annual Meeting of the
Association of Computational Linguistics",
MONTH=june,
YEAR=1986,
PAGES=200--206,
ABSTRACT="A constraint is proposed in the centering approach to
pronoun resolution in discourse. This `property--sharing' constraint
requires that two pronominal expressions that retain the same Cb
across adjacent utterances share a certain common grammatical
property. This property is expressed along the dimention of the
grammatical function SUBJECT for both Japanese and English discourses,
where different pronominal forms are primarily used to realize the
Cb. It is the zero pronominal in Japanese, and the (unstressed) overt
pronoun in English. The resulting constraint complements the original
Centering Rule, accounting for its apparent violations and providing a
solution to the interpretation of multi--pronominal utterances. It
also provides an alternative account of anaphora interpretation that
appears to be due to structural parallelism. This reconcilation of
centering/focusing and parallelism is a major advantage. I will then
add another dimension called the `speaker identification' to the
constraint to handle a group of special cases in Japanese
discourse. It indicates a close association between centering and the
speaker's viewpoint, and sheds light on what underlies the effect of
perception reports on pronoun resolution in general. These results, by
drawing on facts in two very different languages, demonstrate the
cross--linguistic applicability of the centering framework.",
WINDEXKEY="sri aic paper papers"
}

@PHDTHESIS{Kameyama85:Zero,
AUTHOR="Kameyama, Megumi",
TITLE="Zero Anaphora: The Case of Japanese",
SCHOOL="Stanford University",
MONTH=aug,
YEAR=1985,
ABSTRACT="Zero pronominals (i.e., unexpressed subjects and objects) are
pervasive in Japanese. I investigate their discourse functions and
syntactic constraints drawing on the centering approach (Sidner 1983;
Grosz, Joshi, & Weinstein 1983) to discourse analysis and the
lexical-functional theory (Bresnan ed. 1982) in syntax. I show that
they encode the Center (i.e., the entity an utterance most centrally
concerns), and posit Center-establishment and Center-retention rules.
These and the Expected Center Order among referring expressions give
rise to preference rules for identifying the Center in Japanese
discourse. I then argue that their essential syntactic properties
simply follow from two factors; (a) their Center-encoding role in
discourse and (b) the mere fact that they are absent from the
constituent structure. These results can be integrated into a zero
pronominal interpretation model where the Center rules crucially
contribute to the control of inferences.",
NOTE="Available from University Microfilms at the University of Michigan.",
WINDEXKEY="sri aic paper papers"
}

@InProceedings{OAA95aizu,
  author =	{Douglas B. Moran and Adam J. Cheyer},
  title =	"Intelligent Agent-based User Interfaces",
  booktitle =	{Proceedings of International Workshop on Human Interface Technology 95 ({IWHIT'95})},
  pages =	"7-10",
  organization =	{The University of Aizu},
  address =	{Aizu-Wakamatsu, Fukushima, Japan},
  month =	{12-13 October},
  year =	1995,
  KEYWORDS =	"OAA, multimodal, multimedia",
  WINDEXKEY =	"sri aic paper papers",
  url =		"ftp://ftp.ai.sri.com/pub/papers/oaa-iwhit95.ps.gz",
  abstract =	{We have developed, and are extending, a multimodal human-computer interface in which the selection of modalities to be used takes into account the available resources and the user's current environment and preferences.  Our current work focuses primarily on interpreting multimodal inputs and adapting to available output modalities.  We anticipate providing more intelligent production of multimodal output in future systems.
We have an agent-based system architecture that we use to allow us to incrementally add functionality, and to substitute alternative handling of individual modalities.}
}

@InProceedings{OAA95maps,
  Key={OAA95maps},
  author =      {Adam Cheyer and Luc Julia},
  title =       "Multimodal Maps: An Agent-based Approach",
  booktitle =   {Proc. of the International Conference on Cooperative Multimodal Communication (CMC/95)},
  year =        "1995",
  month =       May,
  address =     "Eindhoven, The Netherlands",
  KEYWORDS =    "OAA, multimodal, multimedia",
  WINDEXKEY =   "sri aic paper papers",
  url =		"ftp://ftp.ai.sri.com/pub/papers/oaa-cmc95.ps.gz",
  abstract =	{}
}

@InProceedings(MooreEtal95,
  author =	{Robert Moore and Douglas Appelt and John Dowding and J. Mark Gawron and Douglas Moran},
  title =	"Combining Linguistic and Statistical Knowledge Sources in Natural-Language Processing for {ATIS}",
  booktitle =	{Proceedings ARPA Spoken Language Systems Technology Workshop},
  address =	{Austin, Texas},
  month =	{22-25 January},
  year =	1995,
  KEYWORDS =	"Gemini, SLS, ATIS",
  WINDEXKEY =	"sri aic paper papers",
  url =		"ftp://ftp.ai.sri.com/pub/papers/sls-slt95.ps.gz",
  abstract =	{
  During the past year, significant improvements have been made in the
  natural-language processing technology used in the SRI ATIS
  spoken-language understanding system.  The principal developments have
  been (1) the incorporation of information from the natural-language
  grammar and lexicon into a statistical language model that is used in
  both speech recognition and language understanding, (2) implementation
  of a robust interpretation component that constructs queries out of
  grammatical fragments when an utterance cannot be analyzed as a single
  phrase or utterance, and (3) a new context mechanism for air travel
  planning that constructs an explicit model of the user's intended
  itinerary.
  }
)
% pages =	pages not used

@InProceedings(DowdingEtal94,
  author =	{John Dowding and Robert Moore and Francois Andry and Douglas Moran},
  title =	"Interleaving Syntax and Semantics in an Efficient Bottom-Up Parser",
  pages = {110--116},
  booktitle = acl94proc, address = acl94addr, month = acl94month,
  year = 1994,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Gemini, SLS",
  abstract =	{}
)
%  booktitle =	"Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics",
%  address =	"New Mexico State University, Las Cruces, New Mexico",
%  month =	"27 June -- 1 July",

@InProceedings(MooreEtal94,
  author =	{Robert Moore and Michael Cohen and Victor Abrash and Douglas Appelt and Harry Bratt and John Butzberger and Lynn Cherny and John Dowding and Horacio Franco and J. Mark Gawron and Douglas Moran},
  title =	"{SRI}'s Recent Progress on the {ATIS} Task",
  booktitle =	{Proceedings ARPA Spoken Language Systems Technology Workshop},
  address =	{Merrill Lynch Conference Center, Princeton, New Jersey},
  month =	{6--8 March},
  year =	1994,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Gemini, speech, SLS, ATIS",
  abstract =	{}
)
%  pages =	pages not used

@InProceedings(DowdingEtal93,
  author =	{John Dowding and J. Mark Gawron and Douglas Appelt and John Bear and Lynn Cherny and Robert Moore and Douglas Moran},
  title =	"{GEMINI}:  A natural language system for spoken-language understanding",
  pages =	{54-61},
  booktitle = acl93proc, address = acl93addr, month = acl93month,
  year =	1993,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Gemini, SLS",
  abstract =	{}
)
%  booktitle =	"Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics",
%  address =	"Ohio State University, Columbus, Ohio",
%  month =	"22--26 June",

@InProceedings(Murveit91,
  author =	{Hy Murveit and Douglas Appelt and Christopher Barker and John Bear and John Butzberger and John Dowding and Eric Jackson and David Magerman and
Robert Moore and Douglas Moran and Ann Podlozny and Patti Price and Mitchel Weintraub},
  title =	"{SRI}'s Speech and Natural Language Evaluation",
  booktitle =	{Proceedings Fourth DARPA Workshop on Speech and Natural Language},
  address =	{Asilomar, California},
  month =	{19--22 February},
  year =	1991,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Gemini, speech, SLS, ATIS",
  abstract =	{}
)
%  pages =	pages not used

@InProceedings(Alshawietal91,
  author =	{Hiyan Alshawi and David Carter and Manny Rayner and Bjorn Gamback},
  title =	"Translation by Quasi Logical Form Transfer",
  pages =	{161-168},
  booktitle =	acl91proc, address =	acl91addr, month =	acl91month,
  year =	1991
)
%  booktitle =	{Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics},
%  address =	{University of California, Berkeley, California},
%  month =	jun,

@InProceedings(Price90,
  author = 	{Patti Price and Victor Abrash and Doug Appelt and John Bear and Jared Bernstein and Bridget Bly and John Butzberger and Michael Cohen and Eric Jackson and Robert Moore and Doug Moran and Hy Murveit and Mitchel Weintraub},
  title =	"Spoken Language System Integration and Development",
  booktitle =	{Proceedings of the International Conference on Spoken Language Processing (ICSLP)},
  address =	{Kobe, Japan},
  year =	1990,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Gemini, SLS, ATIS",
  abstract =	{}
)
%  pages =	unknown
%  month =	unknown

@InProceedings(MooreEtal90,
  author =	{Robert Moore and Douglas Appelt and John Bear and Mary Dalrymple and Douglas Moran},
  title =	"{SRI}'s Experience with the {ATIS} Evaluation",
  booktitle =	{Proceedings Speech and Natural Language Workshop,
		Hidden Valley, Pennsylvania},
  month =	{24--27 June},
  year =	1990,
  pages =	{147--148},
  publisher =	"{Morgan Kaufman Publishers, Inc}",
  address =	{San Mateo, California}),
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Gemini, SLS, ATIS",
  abstract =	{}
)

@InProceedings(Cohenetal89a,
  Key={Cohenetal89a},
  Author={Philip R. Cohen and Mary Dalrymple and  Douglas B. Moran and Fernando C. N. Pereira and Joseph W. Sullivan and Robert A. Gargan and Jon L. Schlossberg and Sherman W. Tyler},
  Title={Synergistic Use of Direct Manipulation and Natural Language},
  Booktitle={Human Factors in Computing Systems: CHI'89 Conference Proceedings},
  Address={New York, New York},
  Publisher={ACM, Addison-Wesley Publishing Co.},
  pages={227-234},
  Month={April},
  Year=1989,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Shoptalk, multimodal, multimedia",
  abstract =	{}
)

@InProceedings(Cohenetal89b,
  Author={Philip R. Cohen and Mary Dalrymple and  Douglas B. Moran and Fernando C. N. Pereira},
  Title={ShopTalk: An Integrated Interface for Decision Support in Manufacturing},
  pages = {11--15},
  Booktitle={Working Notes of the AAAI Spring Symposium Series},
  Volume = "{AI} in Manufacturing",
  Address = {Stanford University, Stanford, California},
  Month = {28-30 March},
  Year = 1989,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"Shoptalk, multimodal, multimedia",
  abstract =	{}
)
@Inproceedings(Cohenetal91,
   Author={Cohen, P. R. and Moran, D. B. and Oviatt, S. L.},
   title={{SHOPTALK: An} Integrated Interface for Factory Information and Operation},
  Booktitle={Proceedings of IPC'91},
  Publisher={Engineering Society of Detroit},
  Address={Ann Arbor, Michigan},
  Year={1991},
  Month={April},
  Pages={811-822},
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"Shoptalk, multimodal, multimedia"
)

@InProceedings(Cohen91a,
  author =      "Cohen, P. R.",
  title =       "Integrated Interfaces for Decision Support with Simulation",
  booktitle =   "Proceedings of the Winter Simulation Conference",
  year =        "1991",
  editor =      "Nelson, B. and Kelton, W. D. and Clark, G. M.",
  pages =       "1066-1072",
  publisher =   "Association for Computing Machinery",
  month =       "December",
  note =        "invited paper",
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"Shoptalk, multimodal, multimedia"
)

@InProceedings(Cohen91b,
  author =      "Cohen, P. R.",
 year =         "1991",
   title =      "The Role of Natural Language in a Multimodal Interface",
  booktitle =   "The 2nd  FRIEND21 International Symposium on
                 Next Generation Human Interface Technologies",
   organization = "Institute for Personalized Information Environment",
  address =     "Tokyo, Japan",
  month =       "November",
  note = {Also appears in Proceedings of UIST'92, ACM Press, New York, 1992, 143-149.},
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"Shoptalk, multimodal, multimedia"
)

@Book(Alshawi91,
  editor =	{Hiyan Alshawi},
  title =	"The {C}ore {L}anguage {E}ngine",
  year =	1991,
  publisher =	{A Bradford Book, The MIT Press},
  address =	{Cambridge, Massachusetts},
  KEYWORDS =	"CLE"
)

@InCollection(Moran91,
  editor =	{Hiyan Alshawi},
  booktitle =	{The Core Language Engine},
  author =	{Douglas B. Moran and Fernando C. N. Pereira},
  title =	"Quantifier Scoping",
  chapter =	8,
  pages =	{149--172}, 
  publisher =	{A Bradford Book, The MIT Press},
  address =	{Cambridge, Massachusetts},
  year =	1991,
  KEYWORDS =	"quantifier scoping, CLE"
)

@InProceedings(Alshawi88,
  author =	{Hiyan Alshawi and Douglas B. Moran},
  title =	"The {D}elphi Model and some Preliminary Experiments",
  pages =	{1578--1589},
  booktitle =	{Proceedings of the Fifth International Logic Programming Conference and Symposium},
  publisher =	{The MIT Press},
  year =	1988,
  WINDEXKEY =	"sri aic paper papers",
  KEYWORDS =	"delphi, parallel processing, logic programming",
  abstract =	{}
). 

@InProceedings(AlshawiEtal88,
  author =	{Hiyan Alshawi and David M. Carter and Jan van Eijck and Robert C. Moore and Douglas B. Moran and Stephen G. Pulman},
  title =	"Overview of the {C}ore {L}anguage {E}ngine",
  pages =	{1108--1115},
  booktitle =	{Proceedings of the International Conference on Fifth Generation Computer Systems},
  address =	{Tokyo, Japan},
  month =	{28 November -- 2 December},
  year =	1988,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"CLE"
)
% in volume 3 of the proceedings

@InProceedings(Moran88,
  author =	{Douglas B. Moran},
  title =	"Quantifier Scoping in the {SRI} {C}ore {L}anguage {E}ngine",
  pages =	{33--40},
  booktitle =	acl88proc, address = acl88addr, month = acl88month,
  year =	1988,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"quantifier scoping, CLE"
)
%  booktitle =	"Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics",
%  address =	"State University of New York at Buffalo",
%  month =	"7--10 June",

@InProceedings(Craighill87,
  author =	{Earl Craighill and Douglas Moran and Ruth Brungardt},
  title =	"Research in Information Structures and Software Architectures for {C3I} Systems",
  booktitle =	{Joint Defense Laboratories Conference on Command, Control and Communications (C3)},
  address =	{Ft. McNair, Washington, D.C.},
  month =	jun,
  year =	1987,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"CCWS, multimedia, multimodal"
)

@InProceedings(Aguilar86,
  author =	{Lorenzo Aguilar and Jose J. Garcia-Luna and Douglas B. Moran and Earl J. Craighill and Ruth Brungardt},
  title =	"An Architecture for a Multimedia Teleconferencing System",
  booktitle =	{SIGCOMM `86 Symposium: Communications Architectures and Protocols},
  month =	aug,
  year =	1986,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"CCWS, multimedia, multimodal"
)


%@Techreport(Moran85,
%  Key={Moran},
%  Author={ Moran, D. B. and  Garcia-Luna, J. and Aguilar, L. and Craighill,E.},
%  Title={Command and Control Multimedia Workstation Research and Development},
%  Institution={Telecommunications Sciences Center, SRI International},
%  Month={February},
%  Year={1985},
%  Number={ECU 85-019},
%  Address={Menlo Park, California}
%)

@Article(Poggio85,
  author =	{Andrew Poggio and Jose J. Garcia-Luna and Earl J. Craighill and Douglas B. Moran and Lorenzo Aguilar},
  title =	"{CCWS}: A Computer-Based, Multimedia Information System",
  journal = 	{IEEE Computer},
  month =	oct,
  year =	1985,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"CCWS, multimedia, multimodal"
)
%  volume = ???, number = ????,
%  pages =	???

@InProceedings(Moran82,
  author =	{Douglas B. Moran},
  title =	{The representation of inconsistent information in a dynamic model-theoretic semantics},
  booktitle =	"Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics",
  address =	"University of Toronto, Toronto, Ontario, Canada",
  month =	"16--18 June",
  pages =	{16--18},
  year =	 1982,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"Montague, PTQ"
)
%  booktitle =	acl82proc, address = acl82addr, month = acl82month,

@InProceedings(Moran81,
  author =	{Douglas B. Moran},
  title =	{Presupposition and implicature in model-theoretic pragmatics},
  booktitle =	"Proceedings of the 19th Annual Meeting of the Association for Computational Linguistics",
  address =	"Stanford University, Stanford, California",
  month =	"29 June -- 1 July",
  pages =	{107--108},
  year = 1981,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"Montague, PTQ"
)
%  booktitle =	acl81proc, address = acl81addr, month = acl81month,

@phdthesis(Moran80,
  author =	{Douglas B. Moran},
  title =	{Model-Theoretic Pragmatics: Dynamic Models and an Application to Presupposition and Implicature},
  school =	{Dept. of Computer and Communication Sciences, The University of Michigan},
  address =	{Ann Arbor, Michigan},
  month =	oct,
  year =	1980,
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"Montague, PTQ"
)

@InProceedings(StickelWaldCADE94,
  author =	{Mark Stickel and Richard Waldinger and Michael Lowry and Thomas Pressburger and Ian Underwood},
  title =	{The deductive composition of astronomical softwared from subroutine libraries},
  pages =	{341--355},
  booktitle =	{Twelfth International Conference on Automated Deduction ({CADE})},
  address = 	{Nancy, France},
  month = 	June,
  year = 	1994,
  url =	"ftp://ftp.ai.sri.com/pub/papers/stickel-waldinger-cade-12.ps.gz",
  WINDEXKEY =   "sri aic paper papers",
  KEYWORDS =	"amphion, {SNARK}",
  abstract = {
  Automated deduction techniques are being used in a system called
  Amphion to derive, from graphical specifications, programs composed
  from a subroutine library.  The system has been applied to construct
  software for the planning and analysis of interplanetary missions.

  The library for that application is a collection of subroutines
  written in FORTRAN-77 at JPL to perform computations in solar-system
  kinematics.  An application domain theory has been developed that
  describes the procedures in a portion of the library, as well as some
  basic properties of solar-system astronomy, in the form of first-order
  axioms.

  Specifications are elicited from the user through a menu-driven
  graphical user interface; space scientists have found the graphical
  notation congenial.  The specification is translated into a theorem,
  which is proved constructively in the astronomical domain theory by an
  automated theorem prover, SNARK.  An applicative program is
  extracted from the proof and converted to FORTRAN-77.  By the
  method of its construction, the program is guaranteed to meet the
  given specification and requires no further verification, provided, of
  course, that the specification, domain theory, and system itself are
  correct.

  Amphion has successfully constructed more than a hundred programs to
  solve problems, formulated at NASA Ames, JPL, and Stanford, which
  involve typical computations involving the sun, planets, moons, and
  spacecraft.  The system is currently being alpha tested at JPL.
  }
)

@article{Myers:ua-aij,
  author = "K. L. Myers",
  title = "Hybrid Reasoning using Universal Attachment",
  journal = AIJ,
  volume = 67,
  pages="329-375",
  year = 1994,
  WINDEXKEY="sri aic paper papers",
224z  ABSTRACT=" Hybrid representation frameworks provide a powerful basis for
constructing intelligent systems.  {\em Universal attachment} is a
domain-independent mechanism for integrating diverse representation
and reasoning methods into hybrid frameworks that contain a subsystem
based on deduction over logical formulas.  Although based on the same
principles as previous attachment methods, universal attachment
provides a much broader range of connections between general-purpose
deduction and specialized representation and reasoning techniques.
This paper defines a formal inference rule of universal attachment and
discusses the properties of soundness, completeness and correctness
for this rule.  The relationship between universal attachment and
other integration techniques is explored.  Finally, policies based on
experimentation with an implemented universal attachment system are
presented that lend guidance in exploiting the expanded
representational and inferential capabilities that hybrid systems
provide."  }

@manual{act-editor-manual,
 author = "Karen L. Myers",
 title = "The ACT Editor User's Guide",
 organization = SRIAIC,
 address = SRIAD,
 year = "1993",
 WINDEXKEY="sri aic manual manuals"}

@manual{new-prs-manual,
 author = "Karen L. Myers",
 title = "User's Guide for the Procedural Reasoning System",
 organization = SRIAIC,
 address = SRIAD,
 year = "1993",
 WINDEXKEY="sri aic manual manuals"}

@inproceedings{Myers&Konolige:kr92,
  author = "K. L. Myers and K. Konolige",
  title = "Reasoning with Analogical Representations",
  booktitle = "Principles of Knowledge Representation and Reasoning:
Proceedings of the Third International Conference (KR92)",
  editor = "B. Nebel and C. Rich and W. Swartout",
  place  = "San Mateo, CA",
  publisher = MK,
  year = 1992,
  WINDEXKEY="sri aic paper papers",
  ABSTRACT="Analogical representations have long been of interest to the
knowledge representation community.  Such representations provide
compact encodings of information that can be cumbersome to represent
and inefficient to manipulate in sentential languages.  In this
document, we address the problem of using analogical representations
effectively in automated deduction systems.  The primary contribution
is a formal framework for combining analogical and deductive
reasoning.  The framework consists of a set of generic operations on
analogical structures and accompanying inference methods for
integrating analogical and sentential information.  The capabilities
of the framework are demonstrated for the task of reasoning to extend
incomplete maps.  The examples presented here have all been solved
automatically by an implementation of the integration framework."
}

@inproceedings{Myers:hybrid-symp,
  author = "K. L. Myers",
  title = "Attachment  Methods for Integration",
  booktitle = "Proceedings of the AAAI 1991 Fall Symposium on
Principles of  Hybrid Reasoning (KR91)",
  year = 1992,
  WINDEXKEY="sri aic paper papers"}

@inproceedings{Myers&Konolige:fss92,
  author = "K. L. Myers and K. Konolige",
  title = "Semi-autonomous Robots",
  booktitle = "Proceedings of  the AAAI Fall Symposium 
	Applications of Artificial Intelligence
	to Real-World Autonomous Mobile Robots",
  year = 1992,  
  WINDEXKEY="sri aic paper papers"}

@inproceedings{Myers:kr91,
  author = "K. L. Myers",
  title = "Universal Attachment: An Integration Method for Logic Hybrids",
  booktitle = "Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference",
  editor = "J. A. Allen and R. Fikes and E. Sandewall",
  place  = "San Mateo, CA",
  publisher = MK,
  year = 1991,
  pages = "405-416",
  WINDEXKEY="sri aic paper papers"}

@phdthesis{Myers:thesis,
  KEY = "Myers:thesis",
  author = "K. L. Myers",
  title = "Universal Attachment: An Integration Method for Logic Hybrids",
  school = "Stanford University",
  year = 1991,
  WINDEXKEY="sri aic paper papers",
}

@inproceedings{Myers:compile,
  author = "K. L. Myers",
  title = "Automatically Generating Universal Attachments Through Compilation",
  booktitle = AAAI90,
  year = 1990,
  WINDEXKEY="sri aic paper papers",
}

@inproceedings{Myers:Persist,
  author = "K. L. Myers and D. E. Smith",
  title = "The Persistence of Derived Information",
  booktitle = AAAI88,
  year = 1988,
  WINDEXKEY="sri aic paper papers"}
@InProceedings{PaleyK95,
  Author= "Paley, S.M. and Karp, P.D.",
  Title= "Adapting {CLIM} Applications for Use on the World Wide Web",
  Booktitle= "Proceedings of the Association of Lisp Users Meeting
              and Workshop",
  Year= "1995",
  pages="1--9",
Abstract = "The World Wide Web (WWW) offers the potential to deliver specialized
information to an audience of unprecedented size.  Along with this
exciting new opportunity, however, comes a challenge for software
developers: instead of rewriting our software applications to operate
over the WWW, how can we maximize software reuse by retrofitting
existing applications?  We have developed a
Web server tool, written in Common Lisp, that allows any existing
graphical user interface application written using the Common Lisp
Interface Manager (CLIM) to hook easily into the WWW.  This tool ---
CWEST (CLIM-WEb Server Tool, pronounced ``quest'') --- has been
developed to operate with EcoCyc, an electronic encyclopedia of genes
and metabolism of the bacterium {\em E. coli}.  EcoCyc consists of a
database of objects relevant to {\em E. coli} biochemistry and a
sophisticated interface, implemented in CLIM, that runs on the local
host window system and generates graphical displays appropriate to
each type of object.  Each query to our server is passed as a command
to the EcoCyc program, which responds by dynamically generating an
appropriate local drawing.  That drawing, which can be a mixture of
text and graphics, is then translated into the HyperText Markup
Language (HTML) and/or the Graphics Interchange Format (GIF) and
returned to the client.  Sensitive regions embedded in the CLIM
drawing are converted to hyperlinks with Universal Resource Locators
(URLs) that generate further EcoCyc queries.  This tight coupling of
CLIM output with Web output makes CLIM an ideal high-level programming
tool for Web applications.  The flexibility of Common Lisp and CLIM
made implementation of the server tool surprisingly easy, requiring
few changes to the existing EcoCyc program.  The results can be seen
at URL {\tt http://www.ai.sri.com/ecocyc/browser.html}.  We plan to
make CWEST available to the CLIM community at large, with the hope
that it will spur other software developers to make their CLIM
applications available over the WWW.",
windexkey="sri aic paper papers",
URL="ftp://ftp.ai.sri.com/pub/papers/paley-luv95.ps.Z",
}

@Article{KarpMLJ93,
Key="Karp",
Author="Karp, P.D.",
Journal="Machine Learning",
Title="Design methods for scientific hypothesis formation and their
application to molecular biology",
volume="12",
pages="89--116",
Year=1993,
Abstract = "Hypothesis-formation problems occur when the outcome of an
experiment as predicted by a scientific theory does not match the
outcome observed by a scientist.  The problem is to modify the theory,
and/or the scientist's conception of the initial conditions of the
experiment, such that the prediction agrees with the observation.  I
treat hypothesis formation as a design problem. A program called
HypGene designs hypotheses by reasoning backward from its goal of
eliminating the difference between prediction and observation.  This
prediction error is eliminated by design operators that are
applied by a planning system.  The synthetic, goal-directed
application of these operators should prove more efficient than past
generate-and-test approaches to hypothesis generation.  HypGene uses
heuristic search to guide a generator that is focused on the errors in
a prediction.  The advantages of the design approach to
hypothesis-formation over the generate-and-test approach are analogous to
the advantages of dependency-directed backtracking over chronological
backtracking.  These hypothesis-formation methods were developed in
the context of a historical study of a scientific research program in
molecular biology.  This paper describes in detail the results of
applying the HypGene program to several hypothesis-formation
problems identified in the historical study.
HypGene found most of the same solutions as did the biologists,
which demonstrates that it is capable of solving complex, real-world
hypothesis-formation problems.",
windexkey="sri aic paper papers",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-mlj93.ps.Z",
   }

@InProceedings{KarpGFP95,
  Key="Karp",
  author = "Karp, P.D. and Myers, K. and Gruber, T.",
  title = "The Generic Frame Protocol",
  booktitle = "Proceedings of the 1995 International Joint Conference
		 on Artificial Intelligence",
  year = 1995,
  pages="768--774",
  Abstract="The Generic Frame Protocol (GFP) is an application program interface
for accessing knowledge bases stored in frame knowledge representation
systems (FRSs).  GFP provides a uniform model of FRSs based on a
common conceptualization of frames, slots, facets, and inheritance.
GFP consists of a set of Common Lisp functions that provide a generic
interface to underlying FRSs.  This interface isolates an
application from many of the idiosyncrasies of specific FRS software
and enables the development of generic tools (e.g., graphical
browsers, frame editors) that operate on many FRSs.  To date, GFP has
been used as an interface to Loom, Ontolingua, Theo, and Sipe.",
  keywords="knowledge representation",
  windexkey="sri aic paper papers",
  URL="ftp://ftp.ai.sri.com/pub/papers/karp-gfp95.ps.Z",
  }

@InProceedings{KarpPERKOBJ95,
  Key="Karp",
  author = "Karp, P.D. and Paley, S.M.",
  title = "Knowledge Representation in the Large",
  booktitle = "Proceedings of the 1995 International Joint Conference
		 on Artificial Intelligence",
  year = 1995,
  pages="751--758",
Abstract="Frame knowledge representation systems lack two important capabilities
that prevent them from scaling up to large applications: they do not
support fast access to large knowledge bases (KBs), nor do they provide
concurrent multiuser access to shared KBs.  We describe the design and
implementation of a storage subsystem that submerges a database
management system (DBMS) within a knowledge representation system.
The storage subsystem incrementally loads referenced frames from the
DBMS, and can save only those frames that have been updated in a given
session to the DBMS.  We present experimental results that show our
approach to be an improvement over the use of flat files, and that
evaluate several variations of our approach.",
keywords="knowledge representation",
windexkey="sri aic paper papers",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-perkobj95.ps.Z",
}

@InProceedings{KarpCIKM94,
  Key="Karp",
  author = "Karp, P.D. and Paley, S.M. and Greenberg, I.",
  title = "A Storage System for Scalable Knowledge Representation",
  booktitle = "Proceedings of the Third International Conference on
		 Information and Knowledge Management",
  editor = "Adam, N.",
  year = 1994,
Abstract="Twenty years of AI research in knowledge representation has produced
frame knowledge representation systems (FRSs) that incorporate a
number of important advances.  However, FRSs lack two important
capabilities that prevent them from scaling up to realistic
applications: they cannot provide high-speed access to large knowledge
bases (KBs), and they do not support shared, concurrent KB access by
multiple users.  Our research investigates the hypothesis that one can
employ an existing database management system (DBMS) as a storage
subsystem for an FRS, to provide high-speed access to large, shared
KBs.  We describe the design and implementation of a general storage
system that incrementally loads referenced frames from a DBMS, and
saves modified frames back to the DBMS, for two different FRSs: LOOM
and THEO.  We also present experimental results showing that the
performance of our prototype storage subsystem exceeds that of flat
files for simulated applications that reference or update up to one
third of the frames from a large LOOM KB.",
keywords="knowledge representation",
windexkey="sri aic paper papers",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-cikm94.ps.Z",
}

@Article{KarpCabiosThesis,
   Key="Karp",
   Author="Karp, P.D.",
   Journal=CABIOS,
   Title="Artificial intelligence methods for theory representation and
		 hypothesis formation",
   Year="1991",
   Volume="7",
   Number="3",
   Pages="301--308",
windexkey="sri aic paper papers",
keywords="machine learning",
   }

@InCollection{KarpGensim,
  author = 	"Karp, Peter D.",
  title = 	"A Qualitative Biochemistry and its Application to the Regulation of the Tryptophan Operon",
  booktitle = 	"Artificial Intelligence and Molecular Biology",
  publisher = 	"AAAI Press",
  year = 	"1993",
  editor = 	"Hunter, L.",
  address = 	"Menlo Park, CA",
windexkey="sri aic paper papers",
keywords="bioinformatics",
}

@Article{KarpCompoundKB,
   Key="Karp",
   Author="Karp, P.D.",
   Journal=CABIOS,
   Title="A knowledge base of the chemical compounds of intermediary metabolism",
   volume="8",
   number="4",
   pages="347--357",
   Year=1992,
Abstract="This paper describes a publicly available knowledge base of the
chemical compounds involved in intermediary metabolism.  We consider
the motivations for constructing a knowledge base of metabolic
compounds, the methodology by which it was constructed, and the
information that it currently contains.  Currently the knowledge base
describes 952 compounds, listing for each: synonyms for its name, a
systematic name, CAS registry number, chemical formula, molecular
weight, chemical structure, and two-dimensional display coordinates
for the structure.  The Compound Knowledge Base (CompoundKB)
illustrates several methodological principles that should guide the
development of biological knowledge bases.  I argue that biological
datasets should be made available in multiple representations to
increase their accessibility to end users, and I present multiple
representations of the CompoundKB (knowledge base, relational data
base, and ASN.1 representations) I also analyze the general
characteristics of these representations to provide an understanding
of their relative advantages and disadvantages.  Another principle is
that the error rate of biological data bases should be estimated and
documented -- this analysis is performed for the CompoundKB.",
Annote="The online version has been updated to reflect modifications
to the knowledge base.",
windexkey="sri aic paper papers",
keywords="bioinformatics, metabolism",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-ckb.ps.Z",
   }

@InProceedings{KarpISMB94,
  Key="Karp",
  author = 	"Karp, P. and Paley, S.M.",
  title = 	"Representations of Metabolic Knowledge: Pathways",
  booktitle = "Proceedings of the Second International Conference on Intelligent
		 Systems for Molecular Biology",
  editor = "Altman, R. and Brutlag, D. and Karp, P. and Lathrop, R.
		 and Searls, D.",
  publisher = "AAAI Press",
  address = "Menlo Park, CA",
  year = 1994,
  abstract="The automatic generation of drawings of metabolic pathways is a
challenging problem that depends intimately on exactly what
information has been recorded for each pathway, and on how that
information is encoded.  The chief contributions of the paper are a
minimized representation for biochemical pathways called the 
predecessor list, and inference procedures for converting the
predecessor list into a  pathway-graph representation that can
serve as input to a pathway-drawing algorithm. The predecessor list
has several advantages over the pathway graph, including its
compactness and its lack of redundancy.  The conversion between the
two representations can be formulated as both a
constraint-satisfaction problem and a logical inference problem, whose
goal is to assign directions to reactions, and to determine which are
the main chemical compounds in the reaction.  We describe a set of
production rules that solves this inference problem.  We also present
heuristics for inferring whether the exterior compounds that are
substrates of reactions at the periphery of a pathway are side or main
compounds.  These techniques were evaluated on 18 metabolic pathways
from the EcoCyc knowledge base.",
windexkey="sri aic paper papers",
keywords="bioinformatics, metabolism",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-ismb94.ps.Z",
}

@InProceedings{KarpISMB93,
  Key="Karp",
  author = 	"Karp, P. and Riley, M.",
  title = 	"Representations of Metabolic Knowledge",
  booktitle = "Proceedings of the First International Conference on Intelligent
		 Systems for Molecular Biology",
  editor = "Hunter, L. and Searls, D. and Shavlik, J.",
  publisher = "AAAI Press",
  address = "Menlo Park, CA",
  year = 1993,
  Pages="207--215",
Abstract="Construction of electronic repositories of metabolic information
is an increasingly active area of research.  Encoding detailed
knowledge of a complex biological domain requires finely honed
representations.  We survey representations used for several metabolic
databases, including EcoCyc, and reach the following conclusions.
Representation of the metabolism must distinguish enzyme classes from
individual enzymes, because there is not a one-to-one mapping from
enzymes to the reactions they catalyze.  Individual enzymes must be
represented explicitly as proteins, e.g., by encoding their subunit
structure.  The species variation of metabolism must be represented.
So must the substrate specificity of enzymes, which may be treated in
several ways.",
keywords="bioinformatics, metabolism",
windexkey="sri aic paper papers",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-ismb93.ps.Z",
}


@InProceedings{KarpBIGR94,
  Key="Karp",
  author = 	"Karp, P. and Paley, S.M.",
  title = 	"Automated Drawing of Metabolic Pathways",
  booktitle = "Third International Conference on Bioinformatics and
		 Genome Research",
  editor = "Lim, H. and Cantor, C. and Robbins, R.",
  year = 1994,
  abstract="The EcoCyc system consists of a knowledge base that describes the
genes and intermediary metabolism of E. coli, and a graphical user
interface (GUI) for accessing that knowledge.  This paper presents
algorithms for drawing metabolic pathways by dynamically querying the
underlying knowledge base.  These algorithms provide a foundation for
building graphical user interfaces to metabolic databases.  Pathway
drawing is a graph-layout problem.  Our algorithms draw pathways of
several different topologies, including linear, cyclic, and branching
pathways, as well as larger groupings of such pathways.  The
algorithms provide several visual presentations of metabolic pathways,
for example, compounds can be drawn as names and/or chemical
structures, and enzyme names and side compounds can be drawn or
omitted.  The GUI also provides several facilities for navigating in
the space of biochemical pathways, such as traversing connections
between pathways, and exploding or collapsing a pathway to include or
exclude neighboring pathways.",
windexkey="sri aic paper papers",
keywords="bioinformatics, metabolism",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-bigr94.ps.Z",
}


@Article{KarpM94,
  author = 	"Karp, P. and Mavrovouniotis, M.",
  title = 	"Representing, Analyzing, and Synthesizing Biochemical Pathways",
  journal = 	"{IEEE} Expert",
  year = 	1994,
  volume = 9,
  number = 2,
  pages = "11--21",
Abstract="Living cells are complex systems whose growth and existence depends on
thousands of biochemical reactions.  A subset of these reactions --
the metabolism -- interconverts small molecules.  A
variety of computational problems arise in representing knowledge of
the metabolism in electronic form, in analyzing that knowledge to gain
deeper insights into complexities of the metabolism, and in using such
knowledge in biology, biotechnology and health applications.  These
problems provide a rich set of opportunities for exploiting existing
AI techniques, and challenges for developing new and improved
techniques.  This article describes challenges and opportunities for
addressing computational problems in the metabolism with techniques
from knowledge representation, planning, integration of heterogeneous
databases, qualitative reasoning, knowledge acquisition, and machine
learning.  The computational problems include construction of large
shared knowledge bases of biochemical pathways, knowledge acquisition
from the biochemical literature, qualitative simulation of metabolic
pathways, thermodynamic estimation, synthesis of metabolic pathways,
and scientific hypothesis formation.",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-pathway-overview.ps.Z",
Annote="This online version was edited heavily to produce
the version published in IEEE Expert.",
windexkey="sri aic paper papers",
}

@TechReport{KarpFreview,
  author = 	"Karp, P.D.",
  title = 	"The design space of frame knowledge
		 representation systems",
  institution = 	SRIAIC,
  year = 	"1992",
  number = 	"520",
Abstract="In the past 20 years, AI researchers in knowledge representation (KR)
have implemented over 50 frame knowledge representation systems
(FRSs).  KR researchers have explored a large and surprisingly diverse
space of alternative FRS designs.  This paper surveys the FRS design
space in search of design principles for FRSs.  The FRS design space
is defined by the set of alternative features and capabilities --
such as the representational constructs and inheritance mechanisms --
that an FRS designer might choose to include in a particular FRS, as
well as the alternative implementations that might exist for a
particular feature.  The paper surveys the architectural variations
explored by different system designers for the frame, the slot, the
knowledge base, for the inheritance operation, and for access-oriented
programming and object-oriented programming.  We also discuss the
classification operation in detail.  We find that few design
principles exist to guide an FRS designer as to how particular design
decisions will affect qualities of the resulting FRS, such as its
worst-case and average-case theoretical complexity, its actual
performance on real-world problems, the expressiveness and
succinctness of the representation language, the runtime flexibility
of the FRS, the modularity of the FRS, and the effort required to
implement the FRS.",
keywords="knowledge representation",
windexkey="sri aic technical note notes",
URL="ftp://ftp.ai.sri.com/pub/papers/karp-freview.ps.Z",
}}

@article{GRASPER-CL,
  author = 	"Karp, P.D. and Lowrance, J.D. and Strat, T.M. and
		 Wilkins, D.E.",
  title = 	"The {Grasper-CL} Graph Management System",
 journal = 	"{LISP} and Symbolic Computation",
 volume = 7,
 pages = "245--282",
 year = 1994,
 keywords = "graphs",
 windexkey="sri aic",
 URL="ftp://ftp.ai.sri.com/pub/papers/karp-grasper-tr.ps.Z",
 Abstract="Graphs are virtually ubiquitous in programming applications.
Moreover, graph-structured information is especially prevalent in AI
applications.  We can enhance programs that manipulate
graph-structured information by providing these programs with
graphical user interfaces that draw graphs, and that allow users to
interact with drawings of graph nodes and edges.  Grasper-CL is a
Common Lisp system for manipulating and displaying graphs.

Grasper-CL defines a graph abstract datatype and an extensive set of
associated operations for creating, modifying and interrogating
graphs, and for saving them persistently.  The system draws graphs
using CLIM (the Common Lisp Interface Manager), and can create
postscript renditions of its drawings.  Grasper-CL supports a wide
variety of graphic styles for drawing graph nodes and edges.
The system includes several different automatic graph layout
algorithms, such as for circular and tree layout; it also supports
full interactive manipulation of graph drawings.  Finally, the system
provides facilities for building graph-based user interfaces for
application programs, which have been used in conjunction with the
Sipe planner, the Gister evidential reasoner, a scheduler for the
Hubble Space Telescope, and the EcoCyc encyclopedia of biochemical
pathways.

A number of groups within the AIC and SRI are using the Grasper-CL
system in a variety of projects.  This talk will describe the system
in detail for people who wish to understand its capabilities better or
who are thinking of using it for other projects.  This talk is also an
opportunity for the audience to shape the future directions of the
system: What additional capabilities should be added?  Would users
like more direct input in how the system evolves?  Should we attempt
to find funding for further development of the system and research on
such issues as graph layout algorithms?",
 }

@string{AI="Artificial Intelligence"}
@string{CIJ="Computational Intelligence"}
@string{CogSci="Cognitive Science"}
@string{JACM="Journal of the ACM"}
@string{CACM="Communications of the Association for Computing Machinery"}
@string{ML="Machine Learning"}
@string{IEEEcomputer="IEEE Computer"}
@string{AAAI="American Association for Artificial Intelligence"}
@string{AAAIAD= "American Association for Artificial Intelligence, Menlo Park, CA"}
@string{ACM="Association for Computing Machinery"}
@string{IEEE="IEEE"}
@string{MK="Morgan Kaufmann Publishers Inc., San Mateo, CA"}

%Proceedings
@string{KAKBS="Knowledge Acquisition for Knowledge-Based Systems Workshop"}
@string{Timberline="Reasoning about Actions and Plans: Proceedings of the 1986 Workshop"}
@string{ACL="Proceedings of the Association for Computational Linguistics"}
@string{IU= "Proceedings of the Image Understanding Workshop"}
@string{AAAI80="Proceedings of the 1980 National Conference on Artificial Intelligence"}
@string{AAAI82="Proceedings of the 1982 National Conference on Artificial Intelligence"}
@string{AAAI83="Proceedings of the 1983 National Conference on Artificial Intelligence"}
@string{AAAI84="Proceedings of the 1984 National Conference on Artificial Intelligence"}
@string{AAAI86="Proceedings of the 1986 National Conference on Artificial Intelligence"}
@string{AAAI87="Proceedings of the 1987 National Conference on Artificial Intelligence"}
@string{AAAI88="Proceedings of the 1988 National Conference on Artificial Intelligence"}
@string{AAAI90="Proceedings of the 1990 National Conference on Artificial Intelligence"}
@string{AAAI91="Proceedings of the 1991 National Conference on Artificial Intelligence"}
@string{AAAI92="Proceedings of the 1992 National Conference on Artificial Intelligence"}
@string{AAAI93="Proceedings of the 1993 National Conference on Artificial Intelligence"}
@string{AAAI94="Proceedings of the 1994 National Conference on Artificial Intelligence"}

@string{IJCAI="International Joint Conference on Artificial Intelligence"}
@string{IJCAI75="Proceedings of the 1975 International Joint Conference on Artificial Intelligence"}
@string{IJCAI77="Proceedings of the 1977 International Joint Conference on Artificial Intelligence"}
@string{IJCAI79="Proceedings of the 1979 International Joint Conference on Artificial Intelligence"}
@string{IJCAI81="Proceedings of the 1981 International Joint Conference on Artificial Intelligence"}
@string{IJCAI83="Proceedings of the 1983 International Joint Conference on Artificial Intelligence"}
@string{IJCAI85="Proceedings of the 1985 International Joint Conference on Artificial Intelligence"}
@string{IJCAI87="Proceedings of the 1987 International Joint Conference on Artificial Intelligence"}
@string{IJCAI89="Proceedings of the 1989 International Joint Conference on Artificial Intelligence"}
@string{IJCAI91="Proceedings of the 1991 International Joint Conference on Artificial Intelligence"}
@string{IJCAI93="Proceedings of the 1993 International Joint Conference on Artificial Intelligence"}
%reports
@string{HPPreport="Heuristic Programming Project Report"}
@string{KSLreport="Knowledge Systems Laboratory Report"}
@string{AImemo="Artificial Intelligence Laboratory Memo"}
@string{WP="Working Paper"}
@string{AInote="Artificial Intelligence Center Technical Note"}
@string{DAIreport="D. A. I. Research Report"}

%places
@string{SU="Stanford University"}
@string{SUCSD="Stanford University Computer Science Department"}
@string{SUKSL="Stanford University Knowledge Systems Laboratory"}

@string{SRI="SRI International"}
@string{AIC="SRI International Artificial Intelligence Center"}
@string{CSL="SRI International Computer Science Laboratory"}
@string{SRIAD="Menlo Park, CA"}

@string{CMU="Carnegie-Mellon University"}
@string{CMUR="Carnegie-Mellon University Robotics Institute"}
@string{MIT="Massachusetts Institute of Technology"}
@string{MITAI="Massachusetts Institute of Technology AI Laboratory"}
@string{MITLCS="Massachusetts Institute of Technology Laboratory for Computer Science"}
@string{USC/ISI="University of Southern California Information Sciences Institute"}
@string{DARPA="Defense Advanced Research Project Agency"}
@string{UMassCS="Department of Computer and Information Science, University of Massachusetts"}


%% chess, reverse chronological


@inproceedings{Chess-IJCAI91,
author =  "David E. Wilkins",
title =  "Chess Was Good for AI Research",  
booktitle = "Proceedings of the 1991 International Joint Conference on Artificial Intelligence",
address =  "Sydney, Australia",
year = "1991",
pages = "551--552",
WINDEXKEY="sri aic paper papers"}

@incollection{PARADISE,
author = "David E. Wilkins",
title = "Using Chess Knowledge to Reduce Search",
booktitle = "Chess Skill in Man and Machine",
editor = "P. Frey",
publisher = "Springer-Verlag",
year = "1983",
chapter = 10,
WINDEXKEY="sri aic paper papers"}

@article{Chess-AIJ82,
author = "David E. Wilkins",
title = "Using Knowledge to Control Tree Searching", 
journal = "Artificial Intelligence",
pages = "1--51",
volume = "18",
year = "1982",
WINDEXKEY="sri aic paper papers"}

@incollection{Chess-Nils,
author = "David E. Wilkins",
title = "Using Patterns and Plans in Chess", 
booktitle = "Readings in Artificial Intelligence",
editor = "Bonnie Weber and Nils Nilsson",
publisher = "Tioga Publishing",
year = "1981",
pages = "390--409",
WINDEXKEY="sri aic paper papers"}

@article{Chess-AIJ80,
author = "David E. Wilkins",
title = "Using Patterns and Plans in Chess", 
journal = "Artificial Intelligence",
pages = "165--203",
volume = "14",
year = "1980",
WINDEXKEY="sri aic paper papers"}

@inproceedings{Chess-causality,
author =  "David E. Wilkins",
title =  "Causality Analysis in Chess",
booktitle = "CSCSI Proceedings",
address =  "Victoria, BC",
year = "1980",
WINDEXKEY="sri aic paper papers"}

@inproceedings{Chess-IJCAI79,
author =  "David E. Wilkins",
title =  "Using Plans in Chess",
booktitle = IJCAI79,
address =  "Tokyo, Japan",
year = "1979",
pages = "960-967",
WINDEXKEY="sri aic paper papers"}




@article{SIPE-AIJ84,
author = "David E. Wilkins",
title = "Domain-Independent Planning: Representation and Plan Generation",
journal = "Artificial Intelligence",
pages = "269-301",
volume = "22",
number = "3",
year = "1984",
WINDEXKEY="sri aic paper papers",
ABSTRACT = "A domain-independent planning program that supports both automatic and
interactive generation of hierarchical, partially ordered plans is described.
An improved formalism makes extensive use of constraints and 
resources to represent domains and actions more powerfully. The formalism
also offers efficient methods for representing properties of objects that do
not change over time, allows specification of the plan rationale (which
includes scoping of conditions and appropriately relating different levels in
the hierarchy), and provides the ability to express deductive rules for
deducing the effects of actions.  The implications of allowing parallel
actions in a plan or problem solution are discussed, and new techniques for
efficiently detecting and remedying harmful parallel interactions are
presented.  The most important of these techniques, reasoning about
resources, is emphasized and explained.  The system supports concurrent
exploration of different branches in the search, making best-first search
easy to implement."}

@article{SIPE-CIJ85,
author = "David E. Wilkins",
title = "Recovering from Execution Erors in SIPE",
journal = CIJ,
volume = "1",
number = "1",
year = "1985",
pages = "33-45",
WINDEXKEY="sri aic paper papers",
ABSTRACT = "In real-world domains (e.g., a mobile robot environment), things do not
always proceed as planned, so it is important to develop better
execution-monitoring techniques and replanning capabilities.  This paper
describes these capabilities in the SIPE planning system.  The motivation
behind SIPE is to place enough limitations on the representation so that
planning can be done efficiently, while retaining sufficient power to still
be useful.  This work assumes that new information given to the execution
monitor is in the form of predicates, thus avoiding the difficult problem of
how to generate these predicates from information provided by sensors.

The replanning module presented here takes advantage of the rich structure of
SIPE plans and is intimately connected with the planner, which can be called
as a subroutine.  This allows the use of SIPE's capabilities to determine
efficiently how unexpected events affect the plan being executed and, in
many cases, to retain most of the original plan by making changes in it to
avoid problems caused by these unexpected events.  SIPE is also capable of
shortening the original plan when serendipitous events occur.  A general set
of replanning actions is presented along with a general replanning capability
that has been implemented by using these actions."}


@incollection{hierarchical,
author = "David E. Wilkins",
title = "Hierarchical Planning: Definition and Implementation",
booktitle = " Advances in Artificial Intelligence II",
editor = "B. Boulay and D. Hogg and L. Steels",
publisher = "North-Holland",
year = "1987",
pages = "659-671",
WINDEXKEY="sri aic paper papers",
ABSTRACT = "There is considerable ambiguity involved in hierarchical planning.  We
present a definition of the latter, and examine several of the reasons for
this confusion.  An explication of hierarchical-planning implementations 
entails two distinct notions: {\it abstraction level} and {\it planning
level}.  A problem in currently implemented planners that is caused by mixing these
two levels is presented and various remedies suggested.  Three solutions
that have been implemented in the current SIPE planning system are described."}

@article{TN410,
author = "David E. Wilkins",
title = "Causal Reasoning in Planning",
journal = CIJ,
volume = "4",
number = "4",
year = "1988",
pages = "373-380",
WINDEXKEY="sri aic paper papers",
ABSTRACT = "Reasoning about actions necessarily involves tracking the truth of assertions about the
world over time.  The SIPE planning system retains the efficiency of the STRIPS assumption
for this while enhancing expressive power by allowing the specification of a causal
theory.   Separation of knowledge about causality from knowledge about actions relieves
operators of much of their representational burden and allows them to be applicable in a
wide range of contexts.  The implementation of causal theories is described, together with
examples and evaluations of the system's expressive power and efficiency."}

@techreport{SIPE-388,
author = "David E. Wilkins",
title = "High-Level Planning in a Mobile Robot Domain",
institution = AIC,
address = SRIAD,
type = "Technical Report",
number = "388",
month = "July",
year = "1986",
WINDEXKEY="sri aic technical note notes"}

@book{SIPE-BOOK,
author = "David E. Wilkins",
title = "Practical Planning: Extending the Classical {AI} Planning Paradigm",
publisher = MK,
year = "1988",
WINDEXKEY="sri aic paper papers"}


@article{SIPE-BEER,
author = "David E. Wilkins",
title = "Can {AI} Planners Solve Practical Problems?",
journal = CIJ,
pages = "232-246",
volume = "6",
number = "4",
year = "1990",
WINDEXKEY="sri aic paper papers",
ABSTRACT= "While there has been recent interest in research on planning and reasoning
about actions, nearly all research results have been theoretical.  We know of
no previous examples of a planning system that has made a significant impact on
a problem of practical importance.  One of the primary goals during the
development of the SIPE-2 planning system has been the balancing of efficiency
with expressiveness and flexibility.  With a major new extension, SIPE-2 has
begun to address practical problems.  This paper describes this new extension
and the new applications of the planner.  One of these applications is the
problem of producing products from raw materials on process lines under
production and resource constraints.  This is a problem of commercial
importance and SIPE-2's application to it is described in some
detail."}


@article{Kartam-eval,
author = "Nabil Kartam and David E. Wilkins",
title = "Toward a Foundation for Evaluating {AI} Planners",
journal = "Artificial Intelligence in Engineering Design, Analysis, and Manufacturing",
volume = "4",
number="1",
year = "1990",
WINDEXKEY="sri aic paper papers"}

@inproceedings{Kartam-hier,
author = "Nabil Kartam and Raymond Levitt and David E. Wilkins",
title = "A Centralized Approach for Representing and Resolving Interactions
 Among Multi-agent Tasks while Planning Hierarchically",
booktitle = "Proceedings of the IEEE CAIA-90 Conference",
year = "1990",
pages = "??",
WINDEXKEY="sri aic paper papers"}

@article{Kartam-ASCE,
author = "Nabil Kartam and Raymond Levitt and David E. Wilkins",
title = "Artificial Intelligence Techniques for Construction Planning",
journal = "ASCE Journal of Computing in Civil Engineering",
volume = 5,
number = 4,
pages = "464--477",
month = October,
year =  1991,
WINDEXKEY="sri aic paper papers"}



@incollection{plan-eval,
author = "John D. Lowrance and David E. Wilkins",
title = "Plan Evaluation under Uncertainity",
booktitle = "Proceedings of the Workshop on Innovative Approaches to Planning,
		Scheduling and Control",
editor = "Katia P. Sycara",
publisher = MK,
month = "November",
year = "1990",
pages = "439-449",
WINDEXKEY="sri aic paper papers",
URL="http://www.ai.sri.com/~wilkins/papers/san-diego-workshop-90.ps"}



@techreport{ACT-TN,
author = "David E. Wilkins",
title = "A Common Knowledge Representation for Plan Generation and Reactive Execution",
institution = AIC,
address = SRIAD,
type = "Technical Report",
number = "532",
month = "June",
year = "1993",
WINDEXKEY="sri aic technical note notes"}


@manual{SIPE-MANUAL,
author = "David E. Wilkins",
title = "Using the SIPE-2 Planning System: A Manual for Version 4.3",
organization = AIC,
address = SRIAD,
month = ``August'',
year = "1993",
WINDEXKEY="sri aic paper papers"}

@article{GRASPER-CL,
  author = 	"Karp, P.D. and Lowrance, J.D. and Strat, T.M. and
		 Wilkins, D.E.",
  title = 	"The {Grasper-CL} Graph Management System",
 journal = 	"{LISP} and Symbolic Computation",
 volume = 7,
 pages = "245--282",
 year = 1994,
WINDEXKEY="sri aic paper papers",
URL = "ftp://ftp.ai.sri.com/pub/papers/karp-grasper-tr.ps.Z",
ABSTRACT = "Grasper-CL is a system for manipulating
and displaying graphs, and for building graph-based user interfaces
for application programs.  It is implemented in Common Lisp and CLIM, and
has been proven by use in a number of applications.  Grasper-CL
includes several advances in graph drawing.  It contains a graph
abstract datatype plus a comprehensive and novel language of
operations on that datatype.  The appearance of Grasper-CL can
be tailored by a wide variety of shape parameters that allow the
application to customize the display of nodes and edges for different
domains.  Default values for shape parameters can be established at
several levels.  Grasper-CL a toolbox approach to graph
layout: the system contains a suite of graph layout algorithms that
can be applied individually, or in combination to produce hierarchical
graph layouts.  The system also contains an interactive graph browser."}
% note = "see also SRI Artificial Intelligence Center Technical Report 521",



%
% "Reasoning about Locations and Movement in Theory and Practice",
%  by Karen L. Myers  and David E. Wilkins, submitted to Artificial Intelligence Journal 
%  in June, 1993.
%

@techreport{UP-FINAL,
	author = "David E. Wilkins and Karen L. Myers and Leonard P. Wesley
and John D. Lowrance",
	title = "Planning in Dynamic and Uncertain Environments",
	institution = AIC,
	address = SRIAD,
	type = "Final Report",
	number = "SRI Contract 1520",
	month = "7 January",
	year = "1994",
WINDEXKEY="sri aic technical note notes"}


@incollection{Cypress-Tucson,
author = "David E. Wilkins and Karen L. Myers and Leonard P. Wesley",
title = "CYPRESS: Planning and Reacting under Uncertainity",
booktitle = "ARPA/Rome Laboratory Planning and Scheduling Initiative Workshop Proceedings",
editor = "Mark H. Burstein",
publisher = MK,
month = "February",
year = "1994",
pages = "111-120",
URL = "http://www.ai.sri.com/~cypress/report/tucson/tucson.html",
WINDEXKEY="sri aic paper papers"}


@incollection{SOCAP,
author = "David E. Wilkins and Roberto V. Desimone",
title = "Applying an {AI} Planner to Military Operations Planning",
booktitle = "Intelligent Scheduling",
editor = "M. Fox and M. Zweben",
publisher = MK,
year = "1994",
pages = "685-709",
WINDEXKEY="sri aic paper papers",
URL = "http://www.ai.sri.com/~wilkins/papers/tn534.ps",
ABSTRACT"This paper describes a prototype system for quickly developing joint military courses of action.  The
system, SOCAP (System for Operations Crisis Action Planning), combines a newly extended version of
an AI planning system, SIPE-2 (System for Interactive Planning and Execution), with a color map
display and applies this technology to military operations planning.  This paper describes the Socap
problem domain, how SIPE-2 was used to address this problem, and the strengths and weaknesses of our
approach."}

@inproceedings{Cypress-nasa,
author =  "David E. Wilkins and Karen L. Myers",
title =  "Integrating Planning and Reactive Control",
booktitle = "Third International Symposium on Artificial Intelligence, Robotics, and
Automation for Space",
address =  "Jet Propulsion Laboratory, Pasadena, CA",
year = "1994",
WINDEXKEY="sri aic paper papers",
URL="http://www.ai.sri.com/~wilkins/papers/isairas-94.ps"}

@article{Cypress-jetai,
author = "David E. Wilkins and Karen L. Myers and John D. Lowrance and Leonard P. Wesley",
title = "Planning and Reacting in Uncertain and Dynamic Environments",
journal = "Journal of Experimental and Theoretical AI",
volume = "7",
publisher = ``Taylor & Francis'',
number = "1",
pages = "197-227",
year = "1995",
WINDEXKEY="sri aic paper papers",
URL= "http://www.ai.sri.com/~wilkins/papers/jetai.ps",
ABSTRACT="Agents situated in dynamic and uncertain environments require several capabilities for
successful operation.  Such agents must monitor the world and respond appropriately to
important events.  The agents should be able to accept goals, synthesize complex plans
for achieving those goals, and execute the plans while continuing
to be responsive to changes in the world.  As events render some current
activities obsolete, the agents should be able to modify their plans while continuing
activities unaffected by those events.
The CYPRESS system is a domain-independent framework for defining
persistent agents with this full range of behavior.  CYPRESS has been used for several
demanding applications, including military operations, real-time tracking, and
fault diagnosis."}

@article{ACT,
author = "David E. Wilkins and Karen L. Myers",
title = "A Common Knowledge Representation for Plan Generation and Reactive Execution",
journal = "Journal of Logic and Computation",
year = "in press",
WINDEXKEY="sri aic paper papers",
URL="http://www.ai.sri.com/~wilkins/papers/jlc-www.ps",
ABSTRACT="The ability to integrate sophisticated planning techniques with reactive execution
systems is critical for nontrivial applications.  Merging these two 
technologies is difficult because the forms of knowledge and reasoning that they employ
differ substantially.  The ACT formalism is a language for representing the knowledge
required to support both the generation of complex plans and reactive execution of those
plans in dynamic environments.  A design goal of ACT was its adequacy for practical
applications.  ACT has been used as the interlingua in an implemented system that links a
previously implemented planner with a previously implemented executor.  This system has
been used in several applications, including robot control and military operations, thus
attesting to its expressive and computational adequacy."}
%SRI International AI Tech Note 532R
